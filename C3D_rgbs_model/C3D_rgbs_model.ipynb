{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "C3D_rgbs_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/perfectism13/learning_colab/blob/master/C3D_rgbs_model/C3D_rgbs_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36_-2SxJ136G",
        "colab_type": "code",
        "outputId": "5bccb428-fec2-46e8-bac0-cb92ac26517e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 812
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os\n",
        "os.chdir(r'/content/drive/My Drive/state-farm-distracted-driver-detection/imgs/')\n",
        "print(os.getcwd())\n",
        "!ls\n",
        "!pip install keras==2.1.5\n",
        "import keras\n",
        "print(keras.__version__)\n",
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/My Drive/state-farm-distracted-driver-detection/imgs\n",
            "'(1-726)clean.mp4'\t\t my_model11.h5\n",
            "'(1-726).mp4'\t\t\t my_model12.h5\n",
            "'（726-800)clean.mp4'\t\t my_model13.h5\n",
            " （726-800）.mp4\t\t my_model1.h5\n",
            "'(726-966)clean.mp4'\t\t my_model9.h5\n",
            "'(726-966).mp4'\t\t\t sample_submission.csv\n",
            " driver_imgs_list_class_2.csv\t test\n",
            " driver_imgs_list_class.csv\t train\n",
            " driver_imgs_list_class.gsheet\t valid\n",
            " driver_imgs_list.csv\t\t vect\n",
            " driver_imgs_list_right.csv\t video_model_change_vd_data_aug.h5\n",
            " flow_xception_lock50.h5\t video_model_change_vd_data_aug_modified.h5\n",
            " flow_xception_lock70.h5\t video_model_change_vd.h5\n",
            " I3D_rgbs_model.h5\t\t video_model.h5\n",
            " my_model10.h5\n",
            "Requirement already satisfied: keras==2.1.5 in /usr/local/lib/python3.6/dist-packages (2.1.5)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.1.5) (1.17.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.1.5) (1.12.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.1.5) (1.4.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.1.5) (3.13)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "2.1.5\n",
            "Mon Feb 10 12:11:56 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.48.02    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   48C    P8    10W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ol7ZZo2I6QyI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "4bf1385b-ad69-469a-e758-ed26ec3d02bd"
      },
      "source": [
        "!pip install sk-video"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sk-video in /usr/local/lib/python3.6/dist-packages (1.1.10)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from sk-video) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from sk-video) (1.17.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwdUnNY5BNc_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.environ['KERAS_BACKEND']='tensorflow'\n",
        "import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHt6FC_zBNdG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "np.random.seed(2017)\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import cv2\n",
        "import math\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.pooling import MaxPooling2D\n",
        "from keras.optimizers import SGD, Adam, Nadam\n",
        "from keras.utils import np_utils\n",
        "from keras.models import model_from_json\n",
        "from sklearn.metrics import log_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0HN1f67t8wa",
        "colab_type": "text"
      },
      "source": [
        "##构建模型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSq1VYdu3vGh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"C3D model for Keras\n",
        "# Reference:\n",
        "- [Learning Spatiotemporal Features with 3D Convolutional Networks](https://arxiv.org/abs/1412.0767)\n",
        "Based on code from @albertomontesg\n",
        "\"\"\"\n",
        "\n",
        "import skvideo.io\n",
        "import keras.backend as K\n",
        "from keras.models import Sequential\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.layers.core import Dense, Dropout, Flatten\n",
        "# from sports1M_utils import preprocess_input, decode_predictions\n",
        "from keras.layers.convolutional import Conv3D, MaxPooling3D, ZeroPadding3D\n",
        "\n",
        "WEIGHTS_PATH = 'https://github.com/adamcasson/c3d/releases/download/v0.1/sports1M_weights_tf.h5'\n",
        "\n",
        "def C3D(weights='sports1M'):\n",
        "    \"\"\"Instantiates a C3D Kerasl model\n",
        "    \n",
        "    Keyword arguments:\n",
        "    weights -- weights to load into model. (default is sports1M)\n",
        "    \n",
        "    Returns:\n",
        "    A Keras model.\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    if weights not in {'sports1M', None}:\n",
        "        raise ValueError('weights should be either be sports1M or None')\n",
        "    \n",
        "    if K.image_data_format() == 'channels_last':\n",
        "        shape = (16,112,112,3)\n",
        "    else:\n",
        "        shape = (3,16,112,112)\n",
        "        \n",
        "    model = Sequential()\n",
        "    model.add(Conv3D(64, 3, activation='relu', padding='same', name='conv1', input_shape=shape))\n",
        "    model.add(MaxPooling3D(pool_size=(1,2,2), strides=(1,2,2), padding='same', name='pool1'))\n",
        "    \n",
        "    model.add(Conv3D(128, 3, activation='relu', padding='same', name='conv2'))\n",
        "    model.add(MaxPooling3D(pool_size=(2,2,2), strides=(2,2,2), padding='valid', name='pool2'))\n",
        "    \n",
        "    model.add(Conv3D(256, 3, activation='relu', padding='same', name='conv3a'))\n",
        "    model.add(Conv3D(256, 3, activation='relu', padding='same', name='conv3b'))\n",
        "    model.add(MaxPooling3D(pool_size=(2,2,2), strides=(2,2,2), padding='valid', name='pool3'))\n",
        "    \n",
        "    model.add(Conv3D(512, 3, activation='relu', padding='same', name='conv4a'))\n",
        "    model.add(Conv3D(512, 3, activation='relu', padding='same', name='conv4b'))\n",
        "    model.add(MaxPooling3D(pool_size=(2,2,2), strides=(2,2,2), padding='valid', name='pool4'))\n",
        "    \n",
        "    model.add(Conv3D(512, 3, activation='relu', padding='same', name='conv5a'))\n",
        "    model.add(Conv3D(512, 3, activation='relu', padding='same', name='conv5b'))\n",
        "    model.add(ZeroPadding3D(padding=(0,1,1)))\n",
        "    model.add(MaxPooling3D(pool_size=(2,2,2), strides=(2,2,2), padding='valid', name='pool5'))\n",
        "    \n",
        "    model.add(Flatten())\n",
        "    \n",
        "    model.add(Dense(4096, activation='relu', name='fc6'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(4096, activation='relu', name='fc7'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(487, activation='softmax', name='fc8'))\n",
        "\n",
        "    if weights == 'sports1M':\n",
        "        weights_path = get_file('sports1M_weights_tf.h5',\n",
        "                                WEIGHTS_PATH,\n",
        "                                cache_subdir='models',\n",
        "                                md5_hash='b7a93b2f9156ccbebe3ca24b41fc5402')\n",
        "        \n",
        "        model.load_weights(weights_path)\n",
        "    \n",
        "    return model\n",
        "    \n",
        "# if __name__ == '__main__':\n",
        "#     model = C3D(weights='sports1M')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p8n03j0S7gKk",
        "colab_type": "text"
      },
      "source": [
        "##构建模型，设定可训练的层数"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Odj6vyytBNeS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "55ba5f92-7ba2-45ba-a4ec-0dbd8de280be"
      },
      "source": [
        "from keras import backend as K\n",
        "K.clear_session()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:88: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:91: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:95: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qwwh8P-vMwHP",
        "colab_type": "code",
        "outputId": "6052aad9-0a02-4336-85ac-49e9d4fe4ff2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.models import load_model\n",
        "import h5py\n",
        "import os\n",
        "from keras.layers import regularizers, GlobalAveragePooling2D, Flatten,Input\n",
        "from keras.models import Model\n",
        "# x = Input((16,112,112,3))\n",
        "base_model = C3D(weights='sports1M')\n",
        "model = Model(inputs=base_model.input, outputs=base_model.get_layer('fc6').output)\n",
        "x = Dropout(0.5)(model.output)\n",
        "# x = Dropout(0.5)(x)\n",
        "x = Dense(10, activation='softmax', kernel_regularizer=regularizers.l2(0.01))(x)\n",
        "# x = Flatten()(x)\n",
        "model = Model(base_model.input,x)\n",
        "for i in range(6):\n",
        "     model.layers[i].trainable = False\n",
        "model.summary()\n",
        "len(model.layers)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:507: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3831: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3138: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:167: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:179: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:183: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:192: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:199: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1_input (InputLayer)     (None, 16, 112, 112, 3)   0         \n",
            "_________________________________________________________________\n",
            "conv1 (Conv3D)               (None, 16, 112, 112, 64)  5248      \n",
            "_________________________________________________________________\n",
            "pool1 (MaxPooling3D)         (None, 16, 56, 56, 64)    0         \n",
            "_________________________________________________________________\n",
            "conv2 (Conv3D)               (None, 16, 56, 56, 128)   221312    \n",
            "_________________________________________________________________\n",
            "pool2 (MaxPooling3D)         (None, 8, 28, 28, 128)    0         \n",
            "_________________________________________________________________\n",
            "conv3a (Conv3D)              (None, 8, 28, 28, 256)    884992    \n",
            "_________________________________________________________________\n",
            "conv3b (Conv3D)              (None, 8, 28, 28, 256)    1769728   \n",
            "_________________________________________________________________\n",
            "pool3 (MaxPooling3D)         (None, 4, 14, 14, 256)    0         \n",
            "_________________________________________________________________\n",
            "conv4a (Conv3D)              (None, 4, 14, 14, 512)    3539456   \n",
            "_________________________________________________________________\n",
            "conv4b (Conv3D)              (None, 4, 14, 14, 512)    7078400   \n",
            "_________________________________________________________________\n",
            "pool4 (MaxPooling3D)         (None, 2, 7, 7, 512)      0         \n",
            "_________________________________________________________________\n",
            "conv5a (Conv3D)              (None, 2, 7, 7, 512)      7078400   \n",
            "_________________________________________________________________\n",
            "conv5b (Conv3D)              (None, 2, 7, 7, 512)      7078400   \n",
            "_________________________________________________________________\n",
            "zero_padding3d_1 (ZeroPaddin (None, 2, 9, 9, 512)      0         \n",
            "_________________________________________________________________\n",
            "pool5 (MaxPooling3D)         (None, 1, 4, 4, 512)      0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 8192)              0         \n",
            "_________________________________________________________________\n",
            "fc6 (Dense)                  (None, 4096)              33558528  \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                40970     \n",
            "=================================================================\n",
            "Total params: 61,255,434\n",
            "Trainable params: 60,143,882\n",
            "Non-trainable params: 1,111,552\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1ERE9ZgDily",
        "colab_type": "text"
      },
      "source": [
        "#切分数据"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "96175ea0-0a3c-4273-9135-2627a8f93df7",
        "id": "00hmsz50kOZE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# divide drivers\n",
        "# unique_list_train = ['p002', 'p012', 'p014', 'p015', 'p026', 'p035', 'p039', 'p041', 'p042', 'p045', 'p047', 'p049', 'p050', 'p051', 'p052', 'p056', 'p061', 'p064', 'p066', 'p072', 'p075']\n",
        "# unique_list_valid = ['p016', 'p021', 'p022', 'p024']\n",
        "unique_list_train = ['p016', 'p021', 'p022', 'p024', 'p026', 'p035', 'p039', 'p041', 'p042', 'p045', 'p047', 'p049', 'p050', 'p051', 'p052', 'p056', 'p061', 'p064', 'p066', 'p072', 'p075']\n",
        "unique_list_valid = ['p002', 'p012', 'p014', 'p015']\n",
        "#print (unique_list_train, unique_list_valid)\n",
        "\n",
        "# get index: driver_id, class, image name\n",
        "index = os.path.join('.', 'driver_imgs_list_class.csv')\n",
        "\n",
        "# build the driver id dictionary and class dictionary\n",
        "f = open(index, 'r')\n",
        "id_dict = dict()\n",
        "class_dict = dict()\n",
        "lines = f.readlines()\n",
        "# for line in lines[1:]:\n",
        "#     arr = line.strip().split(',')\n",
        "#     if arr[0] not in id_dict.keys():\n",
        "#         id_dict[arr[0]] = [line]\n",
        "#     else:\n",
        "#         id_dict[arr[0]].append(line)\n",
        "#     if arr[1] not in class_dict.keys():\n",
        "#         class_dict[arr[1]] = [line]\n",
        "#     else:\n",
        "#         class_dict[arr[1]].append(line)\n",
        "# f.close()\n",
        "\n",
        "# split the train list and valid list by id\n",
        "train_list = []\n",
        "valid_list = []\n",
        "# for id in id_dict.keys():\n",
        "#     if id in unique_list_train:\n",
        "#         train_list.extend(id_dict[id])\n",
        "#     elif id in unique_list_valid:\n",
        "#         valid_list.extend(id_dict[id])\n",
        "\n",
        "# for cla in class_dict.keys():\n",
        "#   for id in id_dict.keys():\n",
        "#     if id in unique_list_train:\n",
        "#         train_list.extend(class_dict[cla])\n",
        "#     elif id in unique_list_valid:\n",
        "#         valid_list.extend(class_dict[cla])\n",
        "# for line in lines[1:]:\n",
        "#     arr = line.strip().split(',')\n",
        "#     if arr[0]  in unique_list_train:\n",
        "#         train_list.append(line)\n",
        "#     elif arr[0]  in unique_list_valid:\n",
        "#       valid_list.append(line)\n",
        "\n",
        "for i in range(22426):\n",
        "  if(i+17>=22425):\n",
        "    break\n",
        "  arr = lines[i+1].strip().split(',')\n",
        "  for j in range(16) :\n",
        "    flags = 0\n",
        "    arr1 = lines[i+1+j].strip().split(',')\n",
        "    arr2 = lines[i+2+j].strip().split(',')\n",
        "    if(arr1[1]==arr2[1]):\n",
        "        flags = 1\n",
        "    elif(arr1[1]!=arr2[1]):\n",
        "        flags = 0\n",
        "  if(flags == 1):\n",
        "    meta = []\n",
        "    for k in range(16):\n",
        "        meta.append(lines[i+1+k].strip().split(','))\n",
        "    if arr[0] in unique_list_train:\n",
        "      train_list.append(meta)\n",
        "    elif arr[0] in unique_list_valid:\n",
        "      valid_list.append(meta)\n",
        "f.close()\n",
        "\n",
        "random.shuffle(train_list)\n",
        "random.shuffle(valid_list)\n",
        "print (len(train_list), len(valid_list))\n",
        "print(len(train_list[1]))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18302 3299\n",
            "16\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nl_N2noABNeB",
        "colab_type": "text"
      },
      "source": [
        "# 转换为One Hot Encode标签\n",
        "\n",
        "对分类标签进行One Hot Encode的函数如下。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18IjONecBNeC",
        "colab_type": "code",
        "outputId": "268b58ad-d96b-43c8-8d78-3ee7365d3964",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# one hot encode the class label\n",
        "\n",
        "from sklearn import preprocessing\n",
        "lb = preprocessing.LabelBinarizer()\n",
        "lb.fit(['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9'])   \n",
        "def one_hot_encode(x):\n",
        "    return lb.transform(x)\n",
        "t = one_hot_encode(['c1', 'c2'])\n",
        "print(t)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 1 0 0 0 0 0 0 0 0]\n",
            " [0 0 1 0 0 0 0 0 0 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tGkV0DVD2Jn",
        "colab_type": "text"
      },
      "source": [
        "#获取rgbs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8PFfA43bJs1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import cv2\n",
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "from random import choice\n",
        "# global num_frames\n",
        "# num_frames = 16\n",
        "# image rotation\n",
        "def rotate(frame, num_frames,degree, row_axis=0, col_axis=1, channel_axis=2, fill_mode='wrap', cval=0.):\n",
        "    theta = np.pi / 180 * degree\n",
        "    rotation_matrix = np.array([[np.cos(theta), -np.sin(theta), 0],\n",
        "    [np.sin(theta), np.cos(theta), 0],\n",
        "    [0, 0, 1]])\n",
        "    h, w = frame[0].shape[row_axis], frame[0].shape[col_axis]\n",
        "    transform_matrix = image.transform_matrix_offset_center(rotation_matrix, h, w)\n",
        "    for i in range(num_frames):\n",
        "      frame[i] = image.apply_transform(frame[i], transform_matrix, channel_axis, fill_mode, cval)\n",
        "    return frame\n",
        "\n",
        "# image shift\n",
        "def shift(frame,num_frames, wshift, hshift, row_axis=0, col_axis=1, channel_axis=2, fill_mode='wrap', cval=0.):\n",
        "    h, w = frame[0].shape[row_axis], frame[0].shape[col_axis] #读取图片的高和宽\n",
        "    tx = hshift * h #高偏移大小，若不偏移可设为0，若向上偏移设为正数\n",
        "    ty = wshift * w #宽偏移大小，若不偏移可设为0，若向左偏移设为正数\n",
        "    translation_matrix = np.array([[1, 0, tx],\n",
        "                                  [0, 1, ty],\n",
        "                                  [0, 0, 1]])\n",
        "    transform_matrix = translation_matrix  \n",
        "    for i in range(num_frames):\n",
        "      frame[i] = image.apply_transform(frame[i], transform_matrix, channel_axis, fill_mode, cval)\n",
        "    return frame\n",
        "\n",
        "#左右或者上下翻转\n",
        "def flip(frame,num_frames,tar):\n",
        "  for i in range(num_frames):\n",
        "    frame[i] = cv2.flip(frame[i],tar)\n",
        "  return frame\n",
        "#水平翻转90°\n",
        "def transpose(frame,num_frames,tar):\n",
        "  if(tar==1):\n",
        "    for i in range(num_frames):\n",
        "      frame[i] = cv2.transpose(frame[i])\n",
        "  return frame\n",
        "\n",
        "def get_rgbs_aug(path):\n",
        "  num_frames = 16\n",
        "  frame = []\n",
        "  for i in range(num_frames):\n",
        "    image = cv2.imread(path[i])\n",
        "    image = np.array(image, dtype=np.float32)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    # image = cv2.resize(image, (224, 224))\n",
        "    frame.append(image)\n",
        "  #random rotate\n",
        "  deg = random.uniform(-10, 10) #random rotate limit\n",
        "  frame = rotate(frame,num_frames, deg)\n",
        "  #random shift\n",
        "  wshift = random.uniform(-0.1, 0.1)\n",
        "  hshift = random.uniform(-0.1, 0.1)\n",
        "  frame = shift(frame,num_frames, wshift, hshift)\n",
        "  #random transpose\n",
        "  foo = [0,1]\n",
        "  tar = choice(foo)\n",
        "  frame = transpose(frame,num_frames,tar)\n",
        "  #random flip\n",
        "  foo = [0,-1,1]\n",
        "  tar = choice(foo)\n",
        "  frame = flip(frame,num_frames,tar)\n",
        "  # reduce size\n",
        "  for i in range(num_frames):\n",
        "    frame[i] = cv2.resize(frame[i], (112, 112))\n",
        "  # normalization\n",
        "  frame = np.array(frame, dtype=np.float32)  \n",
        "  frame /= 127.5\n",
        "  frame -= 1.\n",
        "  return frame\n",
        "\n",
        "def get_rgbs(path):\n",
        "  num_frames = 16\n",
        "  frame = []\n",
        "  for i in range(num_frames):\n",
        "    image = cv2.imread(path[i])\n",
        "    image = cv2.resize(image, (112, 112))\n",
        "    image = np.array(image, dtype=np.float32)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    frame.append(image)\n",
        "  # normalization\n",
        "  frame = np.array(frame, dtype=np.float32)  \n",
        "  frame /= 127.5\n",
        "  frame -= 1.\n",
        "  return frame\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jirSzPK5Hb57",
        "colab_type": "code",
        "outputId": "b3b71787-ff75-4da9-ecf7-4b9bb2016364",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "foo = [0,1,-1]\n",
        "from random import choice\n",
        "print (choice(foo))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09kuBGecDnPh",
        "colab_type": "text"
      },
      "source": [
        "#训练数据生成器"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbJeF3pDBNeJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define my train data generator\n",
        "# global num_frames\n",
        "# num_frames = 16\n",
        "def train_gen(batch_size):\n",
        "    #random.shuffle(train_list) # 每一代都随机shuffle训练集\n",
        "    current = 0\n",
        "    num_frames = 16\n",
        "    while 1:\n",
        "        x = []\n",
        "        y = []\n",
        "        path = []\n",
        "        while len(y) < batch_size:\n",
        "            for i in range(num_frames):\n",
        "              # line=train_list[current+i]\n",
        "              # arr=line.strip().split(',')\n",
        "              # mpath=os.path.join('.', 'train', str(arr[1]), str(arr[2]))\n",
        "              # path.append(mpath)\n",
        "              line=train_list[current][i]\n",
        "              # arr=line.strip().split(',')\n",
        "              mpath=os.path.join('.', 'train', str(line[1]), str(line[2]))\n",
        "              path.append(mpath)\n",
        "            rgbs = get_rgbs_aug(path)\n",
        "            # if random.random()>0.5:\n",
        "            #     line2 = random.choice(class_dict[arr[1]])\n",
        "            #     bname = line2.strip().split(',')[2]\n",
        "            #     path2 = os.path.join('.', 'train', str(arr[1]), str(bname))\n",
        "            #     img2 = get_im_cv2_aug(path2, 299)\n",
        "            #     left = img[:, :150, :]\n",
        "            #     right = img2[:, 150:, :]\n",
        "            #     img = np.concatenate((left, right), axis=1)\n",
        "            x.append(rgbs)\n",
        "            label = one_hot_encode([str(line[1])])[0]\n",
        "            y.append(label)\n",
        "            current += 1\n",
        "            if current >= len(train_list):\n",
        "                current = 0\n",
        "        x = np.array(x)\n",
        "        # print(x.shape,y.shape)\n",
        "        img_size = 112\n",
        "        # num_frames = 16\n",
        "        x = x.reshape(batch_size,num_frames, img_size, img_size, 3) \n",
        "        y = np.array(y, dtype = np.uint8)\n",
        "        y = y.reshape(batch_size, 10)\n",
        "        yield (x, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kaKE9QluDv6v",
        "colab_type": "text"
      },
      "source": [
        "#验证数据生成器"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tp4U8pKTBNeO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define my validation data generator\n",
        "# global num_frames\n",
        "# num_frames = 16\n",
        "def valid_gen(batch_size):\n",
        "    #random.shuffle(train_list) # 每一代都随机shuffle训练集\n",
        "    current = 0\n",
        "    num_frames = 16\n",
        "    while 1:\n",
        "        x = []\n",
        "        y = []\n",
        "        path = []\n",
        "        while len(y) < batch_size:\n",
        "            for i in range(num_frames):\n",
        "              # line=valid_list[current+i]\n",
        "              # arr=line.strip().split(',')\n",
        "              # mpath=os.path.join('.', 'train', str(arr[1]), str(arr[2]))\n",
        "              # path.append(mpath)\n",
        "              line=valid_list[current][i]\n",
        "              # arr=line.strip().split(',')\n",
        "              mpath=os.path.join('.', 'train', str(line[1]), str(line[2]))\n",
        "              path.append(mpath)\n",
        "            rgbs = get_rgbs(path)\n",
        "            x.append(rgbs)\n",
        "            label = one_hot_encode([str(line[1])])[0]\n",
        "            y.append(label)\n",
        "            current += 1\n",
        "            if current >= len(valid_list):\n",
        "                current = 0\n",
        "        x = np.array(x)\n",
        "        # print(x.shape,y.shape)\n",
        "        img_size = 112\n",
        "        # num_frames = 16\n",
        "        x = x.reshape(batch_size,num_frames, img_size, img_size, 3) \n",
        "        y = np.array(y, dtype = np.uint8)\n",
        "        y = y.reshape(batch_size, 10)\n",
        "        yield (x, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ubmQAMO4Drd",
        "colab_type": "text"
      },
      "source": [
        "#验证数据类型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5x8HDZLIL2oT",
        "colab_type": "code",
        "outputId": "688ce284-36aa-427f-b4a7-58f8eadd8a64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        }
      },
      "source": [
        "current = 0\n",
        "path = []\n",
        "num_frames=16\n",
        "for i in range(num_frames):\n",
        "  line=train_list[current][i]\n",
        "  print(line)\n",
        "  # arr=line.strip().split(',')\n",
        "  mpath=os.path.join('.', 'train', str(line[1]), str(line[2]))\n",
        "  path.append(mpath)\n",
        "for i in range(num_frames):\n",
        "  line=valid_list[current][i]\n",
        "  print(line)\n",
        "  # arr=line.strip().split(',')\n",
        "  mpath=os.path.join('.', 'train', str(line[1]), str(line[2]))\n",
        "  path.append(mpath)\n",
        "\n",
        "rgbs_aug = get_rgbs_aug(path)\n",
        "rgbs = get_rgbs(path)\n",
        "print(rgbs_aug.shape)\n",
        "print(rgbs.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['p035', 'c4', 'img_62615.jpg']\n",
            "['p035', 'c4', 'img_22165.jpg']\n",
            "['p035', 'c4', 'img_32465.jpg']\n",
            "['p035', 'c4', 'img_101957.jpg']\n",
            "['p035', 'c4', 'img_30451.jpg']\n",
            "['p035', 'c4', 'img_9086.jpg']\n",
            "['p035', 'c4', 'img_28423.jpg']\n",
            "['p035', 'c4', 'img_31570.jpg']\n",
            "['p035', 'c4', 'img_12719.jpg']\n",
            "['p035', 'c4', 'img_72376.jpg']\n",
            "['p035', 'c4', 'img_64670.jpg']\n",
            "['p035', 'c4', 'img_84456.jpg']\n",
            "['p035', 'c4', 'img_8574.jpg']\n",
            "['p035', 'c4', 'img_39421.jpg']\n",
            "['p035', 'c4', 'img_8119.jpg']\n",
            "['p035', 'c4', 'img_52001.jpg']\n",
            "['p014', 'c4', 'img_71169.jpg']\n",
            "['p014', 'c4', 'img_82074.jpg']\n",
            "['p015', 'c4', 'img_73258.jpg']\n",
            "['p015', 'c4', 'img_50429.jpg']\n",
            "['p015', 'c4', 'img_51146.jpg']\n",
            "['p015', 'c4', 'img_24154.jpg']\n",
            "['p015', 'c4', 'img_31684.jpg']\n",
            "['p015', 'c4', 'img_100778.jpg']\n",
            "['p015', 'c4', 'img_2071.jpg']\n",
            "['p015', 'c4', 'img_36357.jpg']\n",
            "['p015', 'c4', 'img_12333.jpg']\n",
            "['p015', 'c4', 'img_41379.jpg']\n",
            "['p015', 'c4', 'img_12476.jpg']\n",
            "['p015', 'c4', 'img_58436.jpg']\n",
            "['p015', 'c4', 'img_53991.jpg']\n",
            "['p015', 'c4', 'img_68963.jpg']\n",
            "(16, 112, 112, 3)\n",
            "(16, 112, 112, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6WESOs6tDzwY",
        "colab_type": "text"
      },
      "source": [
        "#训练"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cw7pUr7tBNec",
        "colab_type": "code",
        "outputId": "62e4133a-1de6-457f-b7bb-b57d5af203b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        }
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler\n",
        "model.compile(optimizer=Nadam(),loss='categorical_crossentropy',metrics=['categorical_accuracy'])\n",
        "# global num_frames\n",
        "# num_frames =16\n",
        "def learning_rate(epoch):\n",
        "    ini_lr = 0.002\n",
        "    lr = ini_lr * pow(10, -epoch)  \n",
        "    return lr\n",
        "\n",
        "cp = ModelCheckpoint(filepath=\"C3D_rgbs_model.h5\", save_best_only=True)\n",
        "es = EarlyStopping()\n",
        "lrs = LearningRateScheduler(learning_rate)\n",
        "hist = model.fit_generator(train_gen(32), steps_per_epoch = 572, epochs = 5, workers=4, max_q_size=20, use_multiprocessing=True, validation_data = valid_gen(32), validation_steps = 104, callbacks=[cp, es, lrs])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:757: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3008: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., steps_per_epoch=572, epochs=5, workers=4, use_multiprocessing=True, validation_data=<generator..., validation_steps=104, callbacks=[<keras.ca..., max_queue_size=20)`\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:976: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:963: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:2087: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
            "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            " 28/572 [>.............................] - ETA: 9:13:13 - loss: 14.1362 - categorical_accuracy: 0.1060"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zp4STyTKD8_1",
        "colab_type": "text"
      },
      "source": [
        "#模型结果"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ninxLSeRbGz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "print (hist.history)\n",
        "plt.figure(1)\n",
        "plt.plot (hist.history['loss'],label='loss')\n",
        "plt.plot (hist.history['val_loss'], label='val_loss')\n",
        "plt.legend(bbox_to_anchor=(1,1),#图例边界框起始位置\n",
        "                 loc=\"upper right\",#图例的位置\n",
        "                 ncol=1,#列数\n",
        "                 mode=\"None\",#当值设置为“expend”时，图例会水平扩展至整个坐标轴区域\n",
        "                 borderaxespad=0,#坐标轴和图例边界之间的间距\n",
        "                 shadow=False,#是否为线框添加阴影\n",
        "                 fancybox=True)#线框圆角处理参数\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BEbJHCwLpxg9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(2)\n",
        "plt.plot (hist.history['categorical_accuracy'], label='categorical_accuracy')\n",
        "plt.plot (hist.history['val_categorical_accuracy'], label='val_categorical_accuracy')\n",
        "plt.legend(bbox_to_anchor=(1,0),#图例边界框起始位置\n",
        "                 loc=\"lower right\",#图例的位置\n",
        "                 ncol=1,#列数\n",
        "                 mode=\"expend\",#当值设置为“expend”时，图例会水平扩展至整个坐标轴区域\n",
        "                 borderaxespad=0,#坐标轴和图例边界之间的间距\n",
        "                 shadow=False,#是否为线框添加阴影\n",
        "                 fancybox=True)#线框圆角处理参数\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
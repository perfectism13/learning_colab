{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "video_model2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/perfectism13/learning_colab/blob/master/video_model2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36_-2SxJ136G",
        "colab_type": "code",
        "outputId": "5bedddd1-460c-4966-dd54-150b0e05aef2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os\n",
        "os.chdir(r'/content/drive/My Drive/')\n",
        "print(os.getcwd())\n",
        "!ls\n",
        "!pip install keras==2.1.5\n",
        "import keras\n",
        "print(keras.__version__)\n",
        "!nvidia-smi"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/My Drive\n",
            " backup\t\t\t\t kinect_color\n",
            " data\t\t\t\t kinect_color.zip\n",
            "'!Distracted-Driver-Detection'\t skateboard_trick_classification\n",
            " git.ipynb\t\t\t test.ipynb\n",
            "Collecting keras==2.1.5\n",
            "  Using cached https://files.pythonhosted.org/packages/ba/65/e4aff762b8696ec0626a6654b1e73b396fcc8b7cc6b98d78a1bc53b85b48/Keras-2.1.5-py2.py3-none-any.whl\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.1.5) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.1.5) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.1.5) (1.17.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.1.5) (1.12.0)\n",
            "Installing collected packages: keras\n",
            "  Found existing installation: Keras 2.0.0\n",
            "    Uninstalling Keras-2.0.0:\n",
            "      Successfully uninstalled Keras-2.0.0\n",
            "Successfully installed keras-2.1.5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "keras"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "2.0.0\n",
            "Wed Feb  5 12:43:57 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.48.02    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   46C    P0    26W /  70W |    481MiB / 15079MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gd50AJGxVmkP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 99
        },
        "outputId": "308ac561-b898-4673-86bf-1595bb5f021b"
      },
      "source": [
        "\"\"\"Inception-v1 Inflated 3D ConvNet used for Kinetics CVPR paper.\n",
        " \n",
        "The model is introduced in:\n",
        " \n",
        "Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset\n",
        "Joao Carreira, Andrew Zisserman\n",
        "https://arxiv.org/abs/1705.07750v1\n",
        "\"\"\"\n",
        "        \n",
        "from __future__ import print_function\n",
        "from __future__ import absolute_import\n",
        "\n",
        "import warnings\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from keras.models import Model\n",
        "from keras import layers\n",
        "from keras.layers import Activation\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Input\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import Conv3D\n",
        "from keras.layers import MaxPooling3D\n",
        "from keras.layers import AveragePooling3D\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Reshape\n",
        "from keras.layers import Lambda\n",
        "from keras.layers import GlobalAveragePooling3D\n",
        "\n",
        "from keras.engine.topology import get_source_inputs\n",
        "from keras.utils import layer_utils\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras import backend as K\n",
        "\n",
        "WEIGHTS_NAME = ['rgb_kinetics_only', 'flow_kinetics_only', 'rgb_imagenet_and_kinetics', 'flow_imagenet_and_kinetics']\n",
        "\n",
        "# path to pretrained models with top (classification layer)\n",
        "WEIGHTS_PATH = {\n",
        "    'rgb_kinetics_only' : 'https://github.com/dlpbc/keras-kinetics-i3d/releases/download/v0.2/rgb_inception_i3d_kinetics_only_tf_dim_ordering_tf_kernels.h5',\n",
        "    'flow_kinetics_only' : 'https://github.com/dlpbc/keras-kinetics-i3d/releases/download/v0.2/flow_inception_i3d_kinetics_only_tf_dim_ordering_tf_kernels.h5',\n",
        "    'rgb_imagenet_and_kinetics' : 'https://github.com/dlpbc/keras-kinetics-i3d/releases/download/v0.2/rgb_inception_i3d_imagenet_and_kinetics_tf_dim_ordering_tf_kernels.h5',\n",
        "    'flow_imagenet_and_kinetics' : 'https://github.com/dlpbc/keras-kinetics-i3d/releases/download/v0.2/flow_inception_i3d_imagenet_and_kinetics_tf_dim_ordering_tf_kernels.h5'\n",
        "}\n",
        "\n",
        "# path to pretrained models with no top (no classification layer)\n",
        "WEIGHTS_PATH_NO_TOP = {\n",
        "    'rgb_kinetics_only' : 'https://github.com/dlpbc/keras-kinetics-i3d/releases/download/v0.2/rgb_inception_i3d_kinetics_only_tf_dim_ordering_tf_kernels_no_top.h5',\n",
        "    'flow_kinetics_only' : 'https://github.com/dlpbc/keras-kinetics-i3d/releases/download/v0.2/flow_inception_i3d_kinetics_only_tf_dim_ordering_tf_kernels_no_top.h5',\n",
        "    'rgb_imagenet_and_kinetics' : 'https://github.com/dlpbc/keras-kinetics-i3d/releases/download/v0.2/rgb_inception_i3d_imagenet_and_kinetics_tf_dim_ordering_tf_kernels_no_top.h5',\n",
        "    'flow_imagenet_and_kinetics' : 'https://github.com/dlpbc/keras-kinetics-i3d/releases/download/v0.2/flow_inception_i3d_imagenet_and_kinetics_tf_dim_ordering_tf_kernels_no_top.h5'\n",
        "}\n",
        "\n",
        "\n",
        "def _obtain_input_shape(input_shape,\n",
        "                        default_frame_size,\n",
        "                        min_frame_size,\n",
        "                        default_num_frames,\n",
        "                        min_num_frames,\n",
        "                        data_format,\n",
        "                        require_flatten,\n",
        "                        weights=None):\n",
        "    \"\"\"Internal utility to compute/validate the model's input shape.\n",
        "    (Adapted from `keras/applications/imagenet_utils.py`)\n",
        "\n",
        "    # Arguments\n",
        "        input_shape: either None (will return the default network input shape),\n",
        "            or a user-provided shape to be validated.\n",
        "        default_frame_size: default input frames(images) width/height for the model.\n",
        "        min_frame_size: minimum input frames(images) width/height accepted by the model.\n",
        "        default_num_frames: default input number of frames(images) for the model.\n",
        "        min_num_frames: minimum input number of frames accepted by the model.\n",
        "        data_format: image data format to use.\n",
        "        require_flatten: whether the model is expected to\n",
        "            be linked to a classifier via a Flatten layer.\n",
        "        weights: one of `None` (random initialization)\n",
        "            or 'kinetics_only' (pre-training on Kinetics dataset).\n",
        "            or 'imagenet_and_kinetics' (pre-training on ImageNet and Kinetics datasets).\n",
        "            If weights='kinetics_only' or weights=='imagenet_and_kinetics' then\n",
        "            input channels must be equal to 3.\n",
        "\n",
        "    # Returns\n",
        "        An integer shape tuple (may include None entries).\n",
        "\n",
        "    # Raises\n",
        "        ValueError: in case of invalid argument values.\n",
        "    \"\"\"\n",
        "    if weights != 'kinetics_only' and weights != 'imagenet_and_kinetics' and input_shape and len(input_shape) == 4:\n",
        "        if data_format == 'channels_first':\n",
        "            if input_shape[0] not in {1, 3}:\n",
        "                warnings.warn(\n",
        "                    'This model usually expects 1 or 3 input channels. '\n",
        "                    'However, it was passed an input_shape with ' +\n",
        "                    str(input_shape[0]) + ' input channels.')\n",
        "            default_shape = (input_shape[0], default_num_frames, default_frame_size, default_frame_size)\n",
        "        else:\n",
        "            if input_shape[-1] not in {1, 3}:\n",
        "                warnings.warn(\n",
        "                    'This model usually expects 1 or 3 input channels. '\n",
        "                    'However, it was passed an input_shape with ' +\n",
        "                    str(input_shape[-1]) + ' input channels.')\n",
        "            default_shape = (default_num_frames, default_frame_size, default_frame_size, input_shape[-1])\n",
        "    else:\n",
        "        if data_format == 'channels_first':\n",
        "            default_shape = (3, default_num_frames, default_frame_size, default_frame_size)\n",
        "        else:\n",
        "            default_shape = (default_num_frames, default_frame_size, default_frame_size, 3)\n",
        "    if (weights == 'kinetics_only' or weights == 'imagenet_and_kinetics') and require_flatten:\n",
        "        if input_shape is not None:\n",
        "            if input_shape != default_shape:\n",
        "                raise ValueError('When setting`include_top=True` '\n",
        "                                 'and loading `imagenet` weights, '\n",
        "                                 '`input_shape` should be ' +\n",
        "                                 str(default_shape) + '.')\n",
        "        return default_shape\n",
        "\n",
        "    if input_shape:\n",
        "        if data_format == 'channels_first':\n",
        "            if input_shape is not None:\n",
        "                if len(input_shape) != 4:\n",
        "                    raise ValueError(\n",
        "                        '`input_shape` must be a tuple of four integers.')\n",
        "                if input_shape[0] != 3 and (weights == 'kinetics_only' or weights == 'imagenet_and_kinetics'):\n",
        "                    raise ValueError('The input must have 3 channels; got '\n",
        "                                     '`input_shape=' + str(input_shape) + '`')\n",
        "\n",
        "                if input_shape[1] is not None and input_shape[1] < min_num_frames:\n",
        "                    raise ValueError('Input number of frames must be at least ' +\n",
        "                                     str(min_num_frames) + '; got '\n",
        "                                     '`input_shape=' + str(input_shape) + '`')\n",
        "\n",
        "                if ((input_shape[2] is not None and input_shape[2] < min_frame_size) or\n",
        "                   (input_shape[3] is not None and input_shape[3] < min_frame_size)):\n",
        "                    raise ValueError('Input size must be at least ' +\n",
        "                                     str(min_frame_size) + 'x' + str(min_frame_size) + '; got '\n",
        "                                     '`input_shape=' + str(input_shape) + '`')\n",
        "        else:\n",
        "            if input_shape is not None:\n",
        "                if len(input_shape) != 4:\n",
        "                    raise ValueError(\n",
        "                        '`input_shape` must be a tuple of four integers.')\n",
        "                if input_shape[-1] != 3 and (weights == 'kinetics_only' or weights == 'imagenet_and_kinetics'):\n",
        "                    raise ValueError('The input must have 3 channels; got '\n",
        "                                     '`input_shape=' + str(input_shape) + '`')\n",
        "\n",
        "                if input_shape[0] is not None and input_shape[0] < min_num_frames:\n",
        "                    raise ValueError('Input number of frames must be at least ' +\n",
        "                                     str(min_num_frames) + '; got '\n",
        "                                     '`input_shape=' + str(input_shape) + '`')\n",
        "\n",
        "                if ((input_shape[1] is not None and input_shape[1] < min_frame_size) or\n",
        "                   (input_shape[2] is not None and input_shape[2] < min_frame_size)):\n",
        "                    raise ValueError('Input size must be at least ' +\n",
        "                                     str(min_frame_size) + 'x' + str(min_frame_size) + '; got '\n",
        "                                     '`input_shape=' + str(input_shape) + '`')\n",
        "    else:\n",
        "        if require_flatten:\n",
        "            input_shape = default_shape\n",
        "        else:\n",
        "            if data_format == 'channels_first':\n",
        "                input_shape = (3, None, None, None)\n",
        "            else:\n",
        "                input_shape = (None, None, None, 3)\n",
        "    if require_flatten:\n",
        "        if None in input_shape:\n",
        "            raise ValueError('If `include_top` is True, '\n",
        "                             'you should specify a static `input_shape`. '\n",
        "                             'Got `input_shape=' + str(input_shape) + '`')\n",
        "    return input_shape\n",
        "\n",
        "\n",
        "def conv3d_bn(x,\n",
        "              filters,\n",
        "              num_frames,\n",
        "              num_row,\n",
        "              num_col,\n",
        "              padding='same',\n",
        "              strides=(1, 1, 1),\n",
        "              use_bias = False,\n",
        "              use_activation_fn = True,\n",
        "              use_bn = True,\n",
        "              name=None):\n",
        "    \"\"\"Utility function to apply conv3d + BN.\n",
        "\n",
        "    # Arguments\n",
        "        x: input tensor.\n",
        "        filters: filters in `Conv3D`.\n",
        "        num_frames: frames (time depth) of the convolution kernel.\n",
        "        num_row: height of the convolution kernel.\n",
        "        num_col: width of the convolution kernel.\n",
        "        padding: padding mode in `Conv3D`.\n",
        "        strides: strides in `Conv3D`.\n",
        "        use_bias: use bias or not  \n",
        "        use_activation_fn: use an activation function or not.\n",
        "        use_bn: use batch normalization or not.\n",
        "        name: name of the ops; will become `name + '_conv'`\n",
        "            for the convolution and `name + '_bn'` for the\n",
        "            batch norm layer.\n",
        "\n",
        "    # Returns\n",
        "        Output tensor after applying `Conv3D` and `BatchNormalization`.\n",
        "    \"\"\"\n",
        "    if name is not None:\n",
        "        bn_name = name + '_bn'\n",
        "        conv_name = name + '_conv'\n",
        "    else:\n",
        "        bn_name = None\n",
        "        conv_name = None\n",
        "\n",
        "    x = Conv3D(\n",
        "        filters, (num_frames, num_row, num_col),\n",
        "        strides=strides,\n",
        "        padding=padding,\n",
        "        use_bias=use_bias,\n",
        "        name=conv_name)(x)\n",
        "\n",
        "    if use_bn:\n",
        "        if K.image_data_format() == 'channels_first':\n",
        "            bn_axis = 1\n",
        "        else:\n",
        "            bn_axis = 4\n",
        "        x = BatchNormalization(axis=bn_axis, scale=False, name=bn_name)(x)\n",
        "\n",
        "    if use_activation_fn:\n",
        "        x = Activation('relu', name=name)(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "def Inception_Inflated3d(include_top=True,\n",
        "                weights=None,\n",
        "                input_tensor=None,\n",
        "                input_shape=None,\n",
        "                dropout_prob=0.0,\n",
        "                endpoint_logit=True,\n",
        "                classes=400):\n",
        "    \"\"\"Instantiates the Inflated 3D Inception v1 architecture.\n",
        "\n",
        "    Optionally loads weights pre-trained\n",
        "    on Kinetics. Note that when using TensorFlow,\n",
        "    for best performance you should set\n",
        "    `image_data_format='channels_last'` in your Keras config\n",
        "    at ~/.keras/keras.json.\n",
        "    The model and the weights are compatible with both\n",
        "    TensorFlow and Theano. The data format\n",
        "    convention used by the model is the one\n",
        "    specified in your Keras config file.\n",
        "    Note that the default input frame(image) size for this model is 224x224.\n",
        "\n",
        "    # Arguments\n",
        "        include_top: whether to include the the classification \n",
        "            layer at the top of the network.\n",
        "        weights: one of `None` (random initialization)\n",
        "            or 'kinetics_only' (pre-training on Kinetics dataset only).\n",
        "            or 'imagenet_and_kinetics' (pre-training on ImageNet and Kinetics datasets).\n",
        "        input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n",
        "            to use as image input for the model.\n",
        "        input_shape: optional shape tuple, only to be specified\n",
        "            if `include_top` is False (otherwise the input shape\n",
        "            has to be `(NUM_FRAMES, 224, 224, 3)` (with `channels_last` data format)\n",
        "            or `(NUM_FRAMES, 3, 224, 224)` (with `channels_first` data format).\n",
        "            It should have exactly 3 inputs channels.\n",
        "            NUM_FRAMES should be no smaller than 8. The authors used 64\n",
        "            frames per example for training and testing on kinetics dataset\n",
        "            Also, Width and height should be no smaller than 32.\n",
        "            E.g. `(64, 150, 150, 3)` would be one valid value.\n",
        "        dropout_prob: optional, dropout probability applied in dropout layer\n",
        "            after global average pooling layer. \n",
        "            0.0 means no dropout is applied, 1.0 means dropout is applied to all features.\n",
        "            Note: Since Dropout is applied just before the classification\n",
        "            layer, it is only useful when `include_top` is set to True.\n",
        "        endpoint_logit: (boolean) optional. If True, the model's forward pass\n",
        "            will end at producing logits. Otherwise, softmax is applied after producing\n",
        "            the logits to produce the class probabilities prediction. Setting this parameter \n",
        "            to True is particularly useful when you want to combine results of rgb model\n",
        "            and optical flow model.\n",
        "            - `True` end model forward pass at logit output\n",
        "            - `False` go further after logit to produce softmax predictions\n",
        "            Note: This parameter is only useful when `include_top` is set to True.\n",
        "        classes: optional number of classes to classify images\n",
        "            into, only to be specified if `include_top` is True, and\n",
        "            if no `weights` argument is specified.\n",
        "\n",
        "    # Returns\n",
        "        A Keras model instance.\n",
        "\n",
        "    # Raises\n",
        "        ValueError: in case of invalid argument for `weights`,\n",
        "            or invalid input shape.\n",
        "    \"\"\"\n",
        "    # if not (weights in WEIGHTS_NAME or weights is None or os.path.exists(weights)):\n",
        "    if not (weights in WEIGHTS_NAME or weights is None ):\n",
        "        raise ValueError('The `weights` argument should be either '\n",
        "                         '`None` (random initialization) or %s' % \n",
        "                         str(WEIGHTS_NAME) + ' ' \n",
        "                         'or a valid path to a file containing `weights` values')\n",
        "\n",
        "    if weights in WEIGHTS_NAME and include_top and classes != 400:\n",
        "        raise ValueError('If using `weights` as one of these %s, with `include_top`'\n",
        "                         ' as true, `classes` should be 400' % str(WEIGHTS_NAME))\n",
        "\n",
        "    # Determine proper input shape\n",
        "    input_shape = _obtain_input_shape(\n",
        "        input_shape,\n",
        "        default_frame_size=224, \n",
        "        min_frame_size=32, \n",
        "        default_num_frames=64,\n",
        "        min_num_frames=8,\n",
        "        data_format=K.image_data_format(),\n",
        "        require_flatten=include_top,\n",
        "        weights=weights)\n",
        "\n",
        "    if input_tensor is None:\n",
        "        img_input = Input(shape=input_shape)\n",
        "    else:\n",
        "        if not K.is_keras_tensor(input_tensor):\n",
        "            img_input = Input(tensor=input_tensor, shape=input_shape)\n",
        "        else:\n",
        "            img_input = input_tensor\n",
        "\n",
        "    if K.image_data_format() == 'channels_first':\n",
        "        channel_axis = 1\n",
        "    else:\n",
        "        channel_axis = 4\n",
        "\n",
        "    # Downsampling via convolution (spatial and temporal)\n",
        "    x = conv3d_bn(img_input, 64, 7, 7, 7, strides=(2, 2, 2), padding='same', name='Conv3d_1a_7x7')\n",
        "\n",
        "    # Downsampling (spatial only)\n",
        "    x = MaxPooling3D((1, 3, 3), strides=(1, 2, 2), padding='same', name='MaxPool2d_2a_3x3')(x)\n",
        "    x = conv3d_bn(x, 64, 1, 1, 1, strides=(1, 1, 1), padding='same', name='Conv3d_2b_1x1')\n",
        "    x = conv3d_bn(x, 192, 3, 3, 3, strides=(1, 1, 1), padding='same', name='Conv3d_2c_3x3')\n",
        "\n",
        "    # Downsampling (spatial only)\n",
        "    x = MaxPooling3D((1, 3, 3), strides=(1, 2, 2), padding='same', name='MaxPool2d_3a_3x3')(x)\n",
        "\n",
        "    # Mixed 3b\n",
        "    branch_0 = conv3d_bn(x, 64, 1, 1, 1, padding='same', name='Conv3d_3b_0a_1x1')\n",
        "\n",
        "    branch_1 = conv3d_bn(x, 96, 1, 1, 1, padding='same', name='Conv3d_3b_1a_1x1')\n",
        "    branch_1 = conv3d_bn(branch_1, 128, 3, 3, 3, padding='same', name='Conv3d_3b_1b_3x3')\n",
        "\n",
        "    branch_2 = conv3d_bn(x, 16, 1, 1, 1, padding='same', name='Conv3d_3b_2a_1x1')\n",
        "    branch_2 = conv3d_bn(branch_2, 32, 3, 3, 3, padding='same', name='Conv3d_3b_2b_3x3')\n",
        "\n",
        "    branch_3 = MaxPooling3D((3, 3, 3), strides=(1, 1, 1), padding='same', name='MaxPool2d_3b_3a_3x3')(x)\n",
        "    branch_3 = conv3d_bn(branch_3, 32, 1, 1, 1, padding='same', name='Conv3d_3b_3b_1x1')\n",
        "\n",
        "    x = layers.concatenate(\n",
        "        [branch_0, branch_1, branch_2, branch_3],\n",
        "        axis=channel_axis,\n",
        "        name='Mixed_3b')\n",
        "\n",
        "    # Mixed 3c\n",
        "    branch_0 = conv3d_bn(x, 128, 1, 1, 1, padding='same', name='Conv3d_3c_0a_1x1')\n",
        "\n",
        "    branch_1 = conv3d_bn(x, 128, 1, 1, 1, padding='same', name='Conv3d_3c_1a_1x1')\n",
        "    branch_1 = conv3d_bn(branch_1, 192, 3, 3, 3, padding='same', name='Conv3d_3c_1b_3x3')\n",
        "\n",
        "    branch_2 = conv3d_bn(x, 32, 1, 1, 1, padding='same', name='Conv3d_3c_2a_1x1')\n",
        "    branch_2 = conv3d_bn(branch_2, 96, 3, 3, 3, padding='same', name='Conv3d_3c_2b_3x3')\n",
        "\n",
        "    branch_3 = MaxPooling3D((3, 3, 3), strides=(1, 1, 1), padding='same', name='MaxPool2d_3c_3a_3x3')(x)\n",
        "    branch_3 = conv3d_bn(branch_3, 64, 1, 1, 1, padding='same', name='Conv3d_3c_3b_1x1')\n",
        "\n",
        "    x = layers.concatenate(\n",
        "        [branch_0, branch_1, branch_2, branch_3],\n",
        "        axis=channel_axis,\n",
        "        name='Mixed_3c')\n",
        "\n",
        "\n",
        "    # Downsampling (spatial and temporal)\n",
        "    x = MaxPooling3D((3, 3, 3), strides=(2, 2, 2), padding='same', name='MaxPool2d_4a_3x3')(x)\n",
        "\n",
        "    # Mixed 4b\n",
        "    branch_0 = conv3d_bn(x, 192, 1, 1, 1, padding='same', name='Conv3d_4b_0a_1x1')\n",
        "\n",
        "    branch_1 = conv3d_bn(x, 96, 1, 1, 1, padding='same', name='Conv3d_4b_1a_1x1')\n",
        "    branch_1 = conv3d_bn(branch_1, 208, 3, 3, 3, padding='same', name='Conv3d_4b_1b_3x3')\n",
        "\n",
        "    branch_2 = conv3d_bn(x, 16, 1, 1, 1, padding='same', name='Conv3d_4b_2a_1x1')\n",
        "    branch_2 = conv3d_bn(branch_2, 48, 3, 3, 3, padding='same', name='Conv3d_4b_2b_3x3')\n",
        "\n",
        "    branch_3 = MaxPooling3D((3, 3, 3), strides=(1, 1, 1), padding='same', name='MaxPool2d_4b_3a_3x3')(x)\n",
        "    branch_3 = conv3d_bn(branch_3, 64, 1, 1, 1, padding='same', name='Conv3d_4b_3b_1x1')\n",
        "\n",
        "    x = layers.concatenate(\n",
        "        [branch_0, branch_1, branch_2, branch_3],\n",
        "        axis=channel_axis,\n",
        "        name='Mixed_4b')\n",
        "\n",
        "    # Mixed 4c\n",
        "    branch_0 = conv3d_bn(x, 160, 1, 1, 1, padding='same', name='Conv3d_4c_0a_1x1')\n",
        "\n",
        "    branch_1 = conv3d_bn(x, 112, 1, 1, 1, padding='same', name='Conv3d_4c_1a_1x1')\n",
        "    branch_1 = conv3d_bn(branch_1, 224, 3, 3, 3, padding='same', name='Conv3d_4c_1b_3x3')\n",
        "\n",
        "    branch_2 = conv3d_bn(x, 24, 1, 1, 1, padding='same', name='Conv3d_4c_2a_1x1')\n",
        "    branch_2 = conv3d_bn(branch_2, 64, 3, 3, 3, padding='same', name='Conv3d_4c_2b_3x3')\n",
        "\n",
        "    branch_3 = MaxPooling3D((3, 3, 3), strides=(1, 1, 1), padding='same', name='MaxPool2d_4c_3a_3x3')(x)\n",
        "    branch_3 = conv3d_bn(branch_3, 64, 1, 1, 1, padding='same', name='Conv3d_4c_3b_1x1')\n",
        "\n",
        "    x = layers.concatenate(\n",
        "        [branch_0, branch_1, branch_2, branch_3],\n",
        "        axis=channel_axis,\n",
        "        name='Mixed_4c')\n",
        "\n",
        "    # Mixed 4d\n",
        "    branch_0 = conv3d_bn(x, 128, 1, 1, 1, padding='same', name='Conv3d_4d_0a_1x1')\n",
        "\n",
        "    branch_1 = conv3d_bn(x, 128, 1, 1, 1, padding='same', name='Conv3d_4d_1a_1x1')\n",
        "    branch_1 = conv3d_bn(branch_1, 256, 3, 3, 3, padding='same', name='Conv3d_4d_1b_3x3')\n",
        "\n",
        "    branch_2 = conv3d_bn(x, 24, 1, 1, 1, padding='same', name='Conv3d_4d_2a_1x1')\n",
        "    branch_2 = conv3d_bn(branch_2, 64, 3, 3, 3, padding='same', name='Conv3d_4d_2b_3x3')\n",
        "\n",
        "    branch_3 = MaxPooling3D((3, 3, 3), strides=(1, 1, 1), padding='same', name='MaxPool2d_4d_3a_3x3')(x)\n",
        "    branch_3 = conv3d_bn(branch_3, 64, 1, 1, 1, padding='same', name='Conv3d_4d_3b_1x1')\n",
        "\n",
        "    x = layers.concatenate(\n",
        "        [branch_0, branch_1, branch_2, branch_3],\n",
        "        axis=channel_axis,\n",
        "        name='Mixed_4d')\n",
        "\n",
        "    # Mixed 4e\n",
        "    branch_0 = conv3d_bn(x, 112, 1, 1, 1, padding='same', name='Conv3d_4e_0a_1x1')\n",
        "\n",
        "    branch_1 = conv3d_bn(x, 144, 1, 1, 1, padding='same', name='Conv3d_4e_1a_1x1')\n",
        "    branch_1 = conv3d_bn(branch_1, 288, 3, 3, 3, padding='same', name='Conv3d_4e_1b_3x3')\n",
        "\n",
        "    branch_2 = conv3d_bn(x, 32, 1, 1, 1, padding='same', name='Conv3d_4e_2a_1x1')\n",
        "    branch_2 = conv3d_bn(branch_2, 64, 3, 3, 3, padding='same', name='Conv3d_4e_2b_3x3')\n",
        "\n",
        "    branch_3 = MaxPooling3D((3, 3, 3), strides=(1, 1, 1), padding='same', name='MaxPool2d_4e_3a_3x3')(x)\n",
        "    branch_3 = conv3d_bn(branch_3, 64, 1, 1, 1, padding='same', name='Conv3d_4e_3b_1x1')\n",
        "\n",
        "    x = layers.concatenate(\n",
        "        [branch_0, branch_1, branch_2, branch_3],\n",
        "        axis=channel_axis,\n",
        "        name='Mixed_4e')\n",
        "\n",
        "    # Mixed 4f\n",
        "    branch_0 = conv3d_bn(x, 256, 1, 1, 1, padding='same', name='Conv3d_4f_0a_1x1')\n",
        "\n",
        "    branch_1 = conv3d_bn(x, 160, 1, 1, 1, padding='same', name='Conv3d_4f_1a_1x1')\n",
        "    branch_1 = conv3d_bn(branch_1, 320, 3, 3, 3, padding='same', name='Conv3d_4f_1b_3x3')\n",
        "\n",
        "    branch_2 = conv3d_bn(x, 32, 1, 1, 1, padding='same', name='Conv3d_4f_2a_1x1')\n",
        "    branch_2 = conv3d_bn(branch_2, 128, 3, 3, 3, padding='same', name='Conv3d_4f_2b_3x3')\n",
        "\n",
        "    branch_3 = MaxPooling3D((3, 3, 3), strides=(1, 1, 1), padding='same', name='MaxPool2d_4f_3a_3x3')(x)\n",
        "    branch_3 = conv3d_bn(branch_3, 128, 1, 1, 1, padding='same', name='Conv3d_4f_3b_1x1')\n",
        "\n",
        "    x = layers.concatenate(\n",
        "        [branch_0, branch_1, branch_2, branch_3],\n",
        "        axis=channel_axis,\n",
        "        name='Mixed_4f')\n",
        "\n",
        "\n",
        "    # Downsampling (spatial and temporal)\n",
        "    x = MaxPooling3D((2, 2, 2), strides=(2, 2, 2), padding='same', name='MaxPool2d_5a_2x2')(x)\n",
        "\n",
        "    # Mixed 5b\n",
        "    branch_0 = conv3d_bn(x, 256, 1, 1, 1, padding='same', name='Conv3d_5b_0a_1x1')\n",
        "\n",
        "    branch_1 = conv3d_bn(x, 160, 1, 1, 1, padding='same', name='Conv3d_5b_1a_1x1')\n",
        "    branch_1 = conv3d_bn(branch_1, 320, 3, 3, 3, padding='same', name='Conv3d_5b_1b_3x3')\n",
        "\n",
        "    branch_2 = conv3d_bn(x, 32, 1, 1, 1, padding='same', name='Conv3d_5b_2a_1x1')\n",
        "    branch_2 = conv3d_bn(branch_2, 128, 3, 3, 3, padding='same', name='Conv3d_5b_2b_3x3')\n",
        "\n",
        "    branch_3 = MaxPooling3D((3, 3, 3), strides=(1, 1, 1), padding='same', name='MaxPool2d_5b_3a_3x3')(x)\n",
        "    branch_3 = conv3d_bn(branch_3, 128, 1, 1, 1, padding='same', name='Conv3d_5b_3b_1x1')\n",
        "\n",
        "    x = layers.concatenate(\n",
        "        [branch_0, branch_1, branch_2, branch_3],\n",
        "        axis=channel_axis,\n",
        "        name='Mixed_5b')\n",
        "\n",
        "    # Mixed 5c\n",
        "    branch_0 = conv3d_bn(x, 384, 1, 1, 1, padding='same', name='Conv3d_5c_0a_1x1')\n",
        "\n",
        "    branch_1 = conv3d_bn(x, 192, 1, 1, 1, padding='same', name='Conv3d_5c_1a_1x1')\n",
        "    branch_1 = conv3d_bn(branch_1, 384, 3, 3, 3, padding='same', name='Conv3d_5c_1b_3x3')\n",
        "\n",
        "    branch_2 = conv3d_bn(x, 48, 1, 1, 1, padding='same', name='Conv3d_5c_2a_1x1')\n",
        "    branch_2 = conv3d_bn(branch_2, 128, 3, 3, 3, padding='same', name='Conv3d_5c_2b_3x3')\n",
        "\n",
        "    branch_3 = MaxPooling3D((3, 3, 3), strides=(1, 1, 1), padding='same', name='MaxPool2d_5c_3a_3x3')(x)\n",
        "    branch_3 = conv3d_bn(branch_3, 128, 1, 1, 1, padding='same', name='Conv3d_5c_3b_1x1')\n",
        "\n",
        "    x = layers.concatenate(\n",
        "        [branch_0, branch_1, branch_2, branch_3],\n",
        "        axis=channel_axis,\n",
        "        name='Mixed_5c')\n",
        "\n",
        "    if include_top:\n",
        "        # Classification block\n",
        "        x = AveragePooling3D((2, 7, 7), strides=(1, 1, 1), padding='valid', name='global_avg_pool')(x)\n",
        "        x = Dropout(dropout_prob)(x)\n",
        "\n",
        "        x = conv3d_bn(x, classes, 1, 1, 1, padding='same', \n",
        "                use_bias=True, use_activation_fn=False, use_bn=False, name='Conv3d_6a_1x1')\n",
        " \n",
        "        num_frames_remaining = int(x.shape[1])\n",
        "        x = Reshape((num_frames_remaining, classes))(x)\n",
        "\n",
        "        # logits (raw scores for each class)\n",
        "        x = Lambda(lambda x: K.mean(x, axis=1, keepdims=False),\n",
        "                   output_shape=lambda s: (s[0], s[2]))(x)\n",
        "\n",
        "        if not endpoint_logit:\n",
        "            x = Activation('softmax', name='prediction')(x)\n",
        "    else:\n",
        "        h = int(x.shape[2])\n",
        "        w = int(x.shape[3])\n",
        "        x = AveragePooling3D((2, h, w), strides=(1, 1, 1), padding='valid', name='global_avg_pool')(x)\n",
        "\n",
        "\n",
        "\n",
        "    inputs = img_input\n",
        "    # create model\n",
        "    model = Model(inputs, x, name='i3d_inception')\n",
        "\n",
        "    # load weights\n",
        "    if weights in WEIGHTS_NAME:\n",
        "        if weights == WEIGHTS_NAME[0]:   # rgb_kinetics_only\n",
        "            if include_top:\n",
        "                weights_url = WEIGHTS_PATH['rgb_kinetics_only']\n",
        "                model_name = 'i3d_inception_rgb_kinetics_only.h5'\n",
        "            else:\n",
        "                weights_url = WEIGHTS_PATH_NO_TOP['rgb_kinetics_only']\n",
        "                model_name = 'i3d_inception_rgb_kinetics_only_no_top.h5'\n",
        "\n",
        "        elif weights == WEIGHTS_NAME[1]: # flow_kinetics_only\n",
        "            if include_top:\n",
        "                weights_url = WEIGHTS_PATH['flow_kinetics_only']\n",
        "                model_name = 'i3d_inception_flow_kinetics_only.h5'\n",
        "            else:\n",
        "                weights_url = WEIGHTS_PATH_NO_TOP['flow_kinetics_only']\n",
        "                model_name = 'i3d_inception_flow_kinetics_only_no_top.h5'\n",
        "\n",
        "        elif weights == WEIGHTS_NAME[2]: # rgb_imagenet_and_kinetics\n",
        "            if include_top:\n",
        "                weights_url = WEIGHTS_PATH['rgb_imagenet_and_kinetics']\n",
        "                model_name = 'i3d_inception_rgb_imagenet_and_kinetics.h5'\n",
        "            else:\n",
        "                weights_url = WEIGHTS_PATH_NO_TOP['rgb_imagenet_and_kinetics']\n",
        "                model_name = 'i3d_inception_rgb_imagenet_and_kinetics_no_top.h5'\n",
        "\n",
        "        elif weights == WEIGHTS_NAME[3]: # flow_imagenet_and_kinetics\n",
        "            if include_top:\n",
        "                weights_url = WEIGHTS_PATH['flow_imagenet_and_kinetics']\n",
        "                model_name = 'i3d_inception_flow_imagenet_and_kinetics.h5'\n",
        "            else:\n",
        "                weights_url = WEIGHTS_PATH_NO_TOP['flow_imagenet_and_kinetics']\n",
        "                model_name = 'i3d_inception_flow_imagenet_and_kinetics_no_top.h5'\n",
        "\n",
        "        downloaded_weights_path = get_file(model_name, weights_url, cache_subdir='models')\n",
        "        model.load_weights(downloaded_weights_path)\n",
        "\n",
        "        if K.backend() == 'theano':\n",
        "            layer_utils.convert_all_kernels_in_model(model)\n",
        "\n",
        "        if K.image_data_format() == 'channels_first' and K.backend() == 'tensorflow':\n",
        "            warnings.warn('You are using the TensorFlow backend, yet you '\n",
        "                          'are using the Theano '\n",
        "                          'image data format convention '\n",
        "                          '(`image_data_format=\"channels_first\"`). '\n",
        "                          'For best performance, set '\n",
        "                          '`image_data_format=\"channels_last\"` in '\n",
        "                          'your keras config '\n",
        "                          'at ~/.keras/keras.json.')\n",
        "\n",
        "    elif weights is not None:\n",
        "        model.load_weights(weights)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qwwh8P-vMwHP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "eaf7ee4d-3560-4361-95d1-c1854a4fe0f0"
      },
      "source": [
        "from keras.models import load_model\n",
        "import h5py\n",
        "import os\n",
        "from keras.layers import regularizers, GlobalAveragePooling2D, Flatten\n",
        "os.chdir(r'/content/drive/My Drive/backup/keras-kinetics-i3d/')\n",
        "# from i3d_inception import Inception_Inflated3d\n",
        "# model = load_model('rgb_inception_i3d_imagenet_and_kinetics_tf_dim_ordering_tf_kernels_no_top.h5')\n",
        "base_model = Inception_Inflated3d(include_top=False,\n",
        "                weights='flow_imagenet_and_kinetics',\n",
        "                input_shape= (10, 224, 224, 2),\n",
        "                dropout_prob=0.0,\n",
        "                endpoint_logit=True,\n",
        "                classes=10)\n",
        "# model.save('model.h5')\n",
        "# x = GlobalAveragePooling2D()(base_model.output)\n",
        "x = Dropout(0.5)(base_model.output)\n",
        "# x = Dropout(0.5)(x)\n",
        "x = Dense(10, activation='softmax', kernel_regularizer=regularizers.l2(0.01))(x)\n",
        "x = Flatten()(x)\n",
        "model = Model(base_model.input,x)\n",
        "model.summary()\n",
        "len(model.layers)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:101: UserWarning: This model usually expects 1 or 3 input channels. However, it was passed an input_shape with 2 input channels.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_14 (InputLayer)           (None, 10, 224, 224, 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_1a_7x7_conv (Conv3D)     (None, 5, 112, 112,  43904       input_14[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_1a_7x7_bn (BatchNormaliz (None, 5, 112, 112,  192         Conv3d_1a_7x7_conv[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_1a_7x7 (Activation)      (None, 5, 112, 112,  0           Conv3d_1a_7x7_bn[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "MaxPool2d_2a_3x3 (MaxPooling3D) (None, 5, 56, 56, 64 0           Conv3d_1a_7x7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_2b_1x1_conv (Conv3D)     (None, 5, 56, 56, 64 4096        MaxPool2d_2a_3x3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_2b_1x1_bn (BatchNormaliz (None, 5, 56, 56, 64 192         Conv3d_2b_1x1_conv[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_2b_1x1 (Activation)      (None, 5, 56, 56, 64 0           Conv3d_2b_1x1_bn[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_2c_3x3_conv (Conv3D)     (None, 5, 56, 56, 19 331776      Conv3d_2b_1x1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_2c_3x3_bn (BatchNormaliz (None, 5, 56, 56, 19 576         Conv3d_2c_3x3_conv[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_2c_3x3 (Activation)      (None, 5, 56, 56, 19 0           Conv3d_2c_3x3_bn[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "MaxPool2d_3a_3x3 (MaxPooling3D) (None, 5, 28, 28, 19 0           Conv3d_2c_3x3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_3b_1a_1x1_conv (Conv3D)  (None, 5, 28, 28, 96 18432       MaxPool2d_3a_3x3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_3b_2a_1x1_conv (Conv3D)  (None, 5, 28, 28, 16 3072        MaxPool2d_3a_3x3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_3b_1a_1x1_bn (BatchNorma (None, 5, 28, 28, 96 288         Conv3d_3b_1a_1x1_conv[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_3b_2a_1x1_bn (BatchNorma (None, 5, 28, 28, 16 48          Conv3d_3b_2a_1x1_conv[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_3b_1a_1x1 (Activation)   (None, 5, 28, 28, 96 0           Conv3d_3b_1a_1x1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_3b_2a_1x1 (Activation)   (None, 5, 28, 28, 16 0           Conv3d_3b_2a_1x1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "MaxPool2d_3b_3a_3x3 (MaxPooling (None, 5, 28, 28, 19 0           MaxPool2d_3a_3x3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_3b_0a_1x1_conv (Conv3D)  (None, 5, 28, 28, 64 12288       MaxPool2d_3a_3x3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_3b_1b_3x3_conv (Conv3D)  (None, 5, 28, 28, 12 331776      Conv3d_3b_1a_1x1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_3b_2b_3x3_conv (Conv3D)  (None, 5, 28, 28, 32 13824       Conv3d_3b_2a_1x1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_3b_3b_1x1_conv (Conv3D)  (None, 5, 28, 28, 32 6144        MaxPool2d_3b_3a_3x3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_3b_0a_1x1_bn (BatchNorma (None, 5, 28, 28, 64 192         Conv3d_3b_0a_1x1_conv[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_3b_1b_3x3_bn (BatchNorma (None, 5, 28, 28, 12 384         Conv3d_3b_1b_3x3_conv[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_3b_2b_3x3_bn (BatchNorma (None, 5, 28, 28, 32 96          Conv3d_3b_2b_3x3_conv[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_3b_3b_1x1_bn (BatchNorma (None, 5, 28, 28, 32 96          Conv3d_3b_3b_1x1_conv[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_3b_0a_1x1 (Activation)   (None, 5, 28, 28, 64 0           Conv3d_3b_0a_1x1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_3b_1b_3x3 (Activation)   (None, 5, 28, 28, 12 0           Conv3d_3b_1b_3x3_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_3b_2b_3x3 (Activation)   (None, 5, 28, 28, 32 0           Conv3d_3b_2b_3x3_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_3b_3b_1x1 (Activation)   (None, 5, 28, 28, 32 0           Conv3d_3b_3b_1x1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_3b (Concatenate)          (None, 5, 28, 28, 25 0           Conv3d_3b_0a_1x1[0][0]           \n",
            "                                                                 Conv3d_3b_1b_3x3[0][0]           \n",
            "                                                                 Conv3d_3b_2b_3x3[0][0]           \n",
            "                                                                 Conv3d_3b_3b_1x1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_3c_1a_1x1_conv (Conv3D)  (None, 5, 28, 28, 12 32768       Mixed_3b[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_3c_2a_1x1_conv (Conv3D)  (None, 5, 28, 28, 32 8192        Mixed_3b[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_3c_1a_1x1_bn (BatchNorma (None, 5, 28, 28, 12 384         Conv3d_3c_1a_1x1_conv[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_3c_2a_1x1_bn (BatchNorma (None, 5, 28, 28, 32 96          Conv3d_3c_2a_1x1_conv[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_3c_1a_1x1 (Activation)   (None, 5, 28, 28, 12 0           Conv3d_3c_1a_1x1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_3c_2a_1x1 (Activation)   (None, 5, 28, 28, 32 0           Conv3d_3c_2a_1x1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "MaxPool2d_3c_3a_3x3 (MaxPooling (None, 5, 28, 28, 25 0           Mixed_3b[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_3c_0a_1x1_conv (Conv3D)  (None, 5, 28, 28, 12 32768       Mixed_3b[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_3c_1b_3x3_conv (Conv3D)  (None, 5, 28, 28, 19 663552      Conv3d_3c_1a_1x1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_3c_2b_3x3_conv (Conv3D)  (None, 5, 28, 28, 96 82944       Conv3d_3c_2a_1x1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_3c_3b_1x1_conv (Conv3D)  (None, 5, 28, 28, 64 16384       MaxPool2d_3c_3a_3x3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_3c_0a_1x1_bn (BatchNorma (None, 5, 28, 28, 12 384         Conv3d_3c_0a_1x1_conv[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_3c_1b_3x3_bn (BatchNorma (None, 5, 28, 28, 19 576         Conv3d_3c_1b_3x3_conv[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_3c_2b_3x3_bn (BatchNorma (None, 5, 28, 28, 96 288         Conv3d_3c_2b_3x3_conv[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_3c_3b_1x1_bn (BatchNorma (None, 5, 28, 28, 64 192         Conv3d_3c_3b_1x1_conv[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_3c_0a_1x1 (Activation)   (None, 5, 28, 28, 12 0           Conv3d_3c_0a_1x1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_3c_1b_3x3 (Activation)   (None, 5, 28, 28, 19 0           Conv3d_3c_1b_3x3_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_3c_2b_3x3 (Activation)   (None, 5, 28, 28, 96 0           Conv3d_3c_2b_3x3_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_3c_3b_1x1 (Activation)   (None, 5, 28, 28, 64 0           Conv3d_3c_3b_1x1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_3c (Concatenate)          (None, 5, 28, 28, 48 0           Conv3d_3c_0a_1x1[0][0]           \n",
            "                                                                 Conv3d_3c_1b_3x3[0][0]           \n",
            "                                                                 Conv3d_3c_2b_3x3[0][0]           \n",
            "                                                                 Conv3d_3c_3b_1x1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "MaxPool2d_4a_3x3 (MaxPooling3D) (None, 3, 14, 14, 48 0           Mixed_3c[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_4b_1a_1x1_conv (Conv3D)  (None, 3, 14, 14, 96 46080       MaxPool2d_4a_3x3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_4b_2a_1x1_conv (Conv3D)  (None, 3, 14, 14, 16 7680        MaxPool2d_4a_3x3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_4b_1a_1x1_bn (BatchNorma (None, 3, 14, 14, 96 288         Conv3d_4b_1a_1x1_conv[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_4b_2a_1x1_bn (BatchNorma (None, 3, 14, 14, 16 48          Conv3d_4b_2a_1x1_conv[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_4b_1a_1x1 (Activation)   (None, 3, 14, 14, 96 0           Conv3d_4b_1a_1x1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_4b_2a_1x1 (Activation)   (None, 3, 14, 14, 16 0           Conv3d_4b_2a_1x1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "MaxPool2d_4b_3a_3x3 (MaxPooling (None, 3, 14, 14, 48 0           MaxPool2d_4a_3x3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_4b_0a_1x1_conv (Conv3D)  (None, 3, 14, 14, 19 92160       MaxPool2d_4a_3x3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_4b_1b_3x3_conv (Conv3D)  (None, 3, 14, 14, 20 539136      Conv3d_4b_1a_1x1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_4b_2b_3x3_conv (Conv3D)  (None, 3, 14, 14, 48 20736       Conv3d_4b_2a_1x1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_4b_3b_1x1_conv (Conv3D)  (None, 3, 14, 14, 64 30720       MaxPool2d_4b_3a_3x3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_4b_0a_1x1_bn (BatchNorma (None, 3, 14, 14, 19 576         Conv3d_4b_0a_1x1_conv[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_4b_1b_3x3_bn (BatchNorma (None, 3, 14, 14, 20 624         Conv3d_4b_1b_3x3_conv[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_4b_2b_3x3_bn (BatchNorma (None, 3, 14, 14, 48 144         Conv3d_4b_2b_3x3_conv[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_4b_3b_1x1_bn (BatchNorma (None, 3, 14, 14, 64 192         Conv3d_4b_3b_1x1_conv[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_4b_0a_1x1 (Activation)   (None, 3, 14, 14, 19 0           Conv3d_4b_0a_1x1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_4b_1b_3x3 (Activation)   (None, 3, 14, 14, 20 0           Conv3d_4b_1b_3x3_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_4b_2b_3x3 (Activation)   (None, 3, 14, 14, 48 0           Conv3d_4b_2b_3x3_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_4b_3b_1x1 (Activation)   (None, 3, 14, 14, 64 0           Conv3d_4b_3b_1x1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_4b (Concatenate)          (None, 3, 14, 14, 51 0           Conv3d_4b_0a_1x1[0][0]           \n",
            "                                                                 Conv3d_4b_1b_3x3[0][0]           \n",
            "                                                                 Conv3d_4b_2b_3x3[0][0]           \n",
            "                                                                 Conv3d_4b_3b_1x1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_4c_1a_1x1_conv (Conv3D)  (None, 3, 14, 14, 11 57344       Mixed_4b[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_4c_2a_1x1_conv (Conv3D)  (None, 3, 14, 14, 24 12288       Mixed_4b[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_4c_1a_1x1_bn (BatchNorma (None, 3, 14, 14, 11 336         Conv3d_4c_1a_1x1_conv[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_4c_2a_1x1_bn (BatchNorma (None, 3, 14, 14, 24 72          Conv3d_4c_2a_1x1_conv[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_4c_1a_1x1 (Activation)   (None, 3, 14, 14, 11 0           Conv3d_4c_1a_1x1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_4c_2a_1x1 (Activation)   (None, 3, 14, 14, 24 0           Conv3d_4c_2a_1x1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "MaxPool2d_4c_3a_3x3 (MaxPooling (None, 3, 14, 14, 51 0           Mixed_4b[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_4c_0a_1x1_conv (Conv3D)  (None, 3, 14, 14, 16 81920       Mixed_4b[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_4c_1b_3x3_conv (Conv3D)  (None, 3, 14, 14, 22 677376      Conv3d_4c_1a_1x1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_4c_2b_3x3_conv (Conv3D)  (None, 3, 14, 14, 64 41472       Conv3d_4c_2a_1x1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_4c_3b_1x1_conv (Conv3D)  (None, 3, 14, 14, 64 32768       MaxPool2d_4c_3a_3x3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_4c_0a_1x1_bn (BatchNorma (None, 3, 14, 14, 16 480         Conv3d_4c_0a_1x1_conv[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_4c_1b_3x3_bn (BatchNorma (None, 3, 14, 14, 22 672         Conv3d_4c_1b_3x3_conv[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_4c_2b_3x3_bn (BatchNorma (None, 3, 14, 14, 64 192         Conv3d_4c_2b_3x3_conv[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_4c_3b_1x1_bn (BatchNorma (None, 3, 14, 14, 64 192         Conv3d_4c_3b_1x1_conv[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_4c_0a_1x1 (Activation)   (None, 3, 14, 14, 16 0           Conv3d_4c_0a_1x1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_4c_1b_3x3 (Activation)   (None, 3, 14, 14, 22 0           Conv3d_4c_1b_3x3_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_4c_2b_3x3 (Activation)   (None, 3, 14, 14, 64 0           Conv3d_4c_2b_3x3_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_4c_3b_1x1 (Activation)   (None, 3, 14, 14, 64 0           Conv3d_4c_3b_1x1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_4c (Concatenate)          (None, 3, 14, 14, 51 0           Conv3d_4c_0a_1x1[0][0]           \n",
            "                                                                 Conv3d_4c_1b_3x3[0][0]           \n",
            "                                                                 Conv3d_4c_2b_3x3[0][0]           \n",
            "                                                                 Conv3d_4c_3b_1x1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_4d_1a_1x1_conv (Conv3D)  (None, 3, 14, 14, 12 65536       Mixed_4c[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_4d_2a_1x1_conv (Conv3D)  (None, 3, 14, 14, 24 12288       Mixed_4c[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_4d_1a_1x1_bn (BatchNorma (None, 3, 14, 14, 12 384         Conv3d_4d_1a_1x1_conv[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_4d_2a_1x1_bn (BatchNorma (None, 3, 14, 14, 24 72          Conv3d_4d_2a_1x1_conv[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_4d_1a_1x1 (Activation)   (None, 3, 14, 14, 12 0           Conv3d_4d_1a_1x1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_4d_2a_1x1 (Activation)   (None, 3, 14, 14, 24 0           Conv3d_4d_2a_1x1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "MaxPool2d_4d_3a_3x3 (MaxPooling (None, 3, 14, 14, 51 0           Mixed_4c[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_4d_0a_1x1_conv (Conv3D)  (None, 3, 14, 14, 12 65536       Mixed_4c[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_4d_1b_3x3_conv (Conv3D)  (None, 3, 14, 14, 25 884736      Conv3d_4d_1a_1x1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_4d_2b_3x3_conv (Conv3D)  (None, 3, 14, 14, 64 41472       Conv3d_4d_2a_1x1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_4d_3b_1x1_conv (Conv3D)  (None, 3, 14, 14, 64 32768       MaxPool2d_4d_3a_3x3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_4d_0a_1x1_bn (BatchNorma (None, 3, 14, 14, 12 384         Conv3d_4d_0a_1x1_conv[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_4d_1b_3x3_bn (BatchNorma (None, 3, 14, 14, 25 768         Conv3d_4d_1b_3x3_conv[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_4d_2b_3x3_bn (BatchNorma (None, 3, 14, 14, 64 192         Conv3d_4d_2b_3x3_conv[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_4d_3b_1x1_bn (BatchNorma (None, 3, 14, 14, 64 192         Conv3d_4d_3b_1x1_conv[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_4d_0a_1x1 (Activation)   (None, 3, 14, 14, 12 0           Conv3d_4d_0a_1x1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_4d_1b_3x3 (Activation)   (None, 3, 14, 14, 25 0           Conv3d_4d_1b_3x3_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_4d_2b_3x3 (Activation)   (None, 3, 14, 14, 64 0           Conv3d_4d_2b_3x3_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_4d_3b_1x1 (Activation)   (None, 3, 14, 14, 64 0           Conv3d_4d_3b_1x1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_4d (Concatenate)          (None, 3, 14, 14, 51 0           Conv3d_4d_0a_1x1[0][0]           \n",
            "                                                                 Conv3d_4d_1b_3x3[0][0]           \n",
            "                                                                 Conv3d_4d_2b_3x3[0][0]           \n",
            "                                                                 Conv3d_4d_3b_1x1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_4e_1a_1x1_conv (Conv3D)  (None, 3, 14, 14, 14 73728       Mixed_4d[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_4e_2a_1x1_conv (Conv3D)  (None, 3, 14, 14, 32 16384       Mixed_4d[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_4e_1a_1x1_bn (BatchNorma (None, 3, 14, 14, 14 432         Conv3d_4e_1a_1x1_conv[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_4e_2a_1x1_bn (BatchNorma (None, 3, 14, 14, 32 96          Conv3d_4e_2a_1x1_conv[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_4e_1a_1x1 (Activation)   (None, 3, 14, 14, 14 0           Conv3d_4e_1a_1x1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_4e_2a_1x1 (Activation)   (None, 3, 14, 14, 32 0           Conv3d_4e_2a_1x1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "MaxPool2d_4e_3a_3x3 (MaxPooling (None, 3, 14, 14, 51 0           Mixed_4d[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_4e_0a_1x1_conv (Conv3D)  (None, 3, 14, 14, 11 57344       Mixed_4d[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_4e_1b_3x3_conv (Conv3D)  (None, 3, 14, 14, 28 1119744     Conv3d_4e_1a_1x1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_4e_2b_3x3_conv (Conv3D)  (None, 3, 14, 14, 64 55296       Conv3d_4e_2a_1x1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_4e_3b_1x1_conv (Conv3D)  (None, 3, 14, 14, 64 32768       MaxPool2d_4e_3a_3x3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_4e_0a_1x1_bn (BatchNorma (None, 3, 14, 14, 11 336         Conv3d_4e_0a_1x1_conv[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_4e_1b_3x3_bn (BatchNorma (None, 3, 14, 14, 28 864         Conv3d_4e_1b_3x3_conv[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_4e_2b_3x3_bn (BatchNorma (None, 3, 14, 14, 64 192         Conv3d_4e_2b_3x3_conv[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_4e_3b_1x1_bn (BatchNorma (None, 3, 14, 14, 64 192         Conv3d_4e_3b_1x1_conv[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_4e_0a_1x1 (Activation)   (None, 3, 14, 14, 11 0           Conv3d_4e_0a_1x1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_4e_1b_3x3 (Activation)   (None, 3, 14, 14, 28 0           Conv3d_4e_1b_3x3_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_4e_2b_3x3 (Activation)   (None, 3, 14, 14, 64 0           Conv3d_4e_2b_3x3_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_4e_3b_1x1 (Activation)   (None, 3, 14, 14, 64 0           Conv3d_4e_3b_1x1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_4e (Concatenate)          (None, 3, 14, 14, 52 0           Conv3d_4e_0a_1x1[0][0]           \n",
            "                                                                 Conv3d_4e_1b_3x3[0][0]           \n",
            "                                                                 Conv3d_4e_2b_3x3[0][0]           \n",
            "                                                                 Conv3d_4e_3b_1x1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_4f_1a_1x1_conv (Conv3D)  (None, 3, 14, 14, 16 84480       Mixed_4e[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_4f_2a_1x1_conv (Conv3D)  (None, 3, 14, 14, 32 16896       Mixed_4e[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_4f_1a_1x1_bn (BatchNorma (None, 3, 14, 14, 16 480         Conv3d_4f_1a_1x1_conv[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_4f_2a_1x1_bn (BatchNorma (None, 3, 14, 14, 32 96          Conv3d_4f_2a_1x1_conv[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_4f_1a_1x1 (Activation)   (None, 3, 14, 14, 16 0           Conv3d_4f_1a_1x1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_4f_2a_1x1 (Activation)   (None, 3, 14, 14, 32 0           Conv3d_4f_2a_1x1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "MaxPool2d_4f_3a_3x3 (MaxPooling (None, 3, 14, 14, 52 0           Mixed_4e[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_4f_0a_1x1_conv (Conv3D)  (None, 3, 14, 14, 25 135168      Mixed_4e[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_4f_1b_3x3_conv (Conv3D)  (None, 3, 14, 14, 32 1382400     Conv3d_4f_1a_1x1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_4f_2b_3x3_conv (Conv3D)  (None, 3, 14, 14, 12 110592      Conv3d_4f_2a_1x1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_4f_3b_1x1_conv (Conv3D)  (None, 3, 14, 14, 12 67584       MaxPool2d_4f_3a_3x3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_4f_0a_1x1_bn (BatchNorma (None, 3, 14, 14, 25 768         Conv3d_4f_0a_1x1_conv[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_4f_1b_3x3_bn (BatchNorma (None, 3, 14, 14, 32 960         Conv3d_4f_1b_3x3_conv[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_4f_2b_3x3_bn (BatchNorma (None, 3, 14, 14, 12 384         Conv3d_4f_2b_3x3_conv[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_4f_3b_1x1_bn (BatchNorma (None, 3, 14, 14, 12 384         Conv3d_4f_3b_1x1_conv[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_4f_0a_1x1 (Activation)   (None, 3, 14, 14, 25 0           Conv3d_4f_0a_1x1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_4f_1b_3x3 (Activation)   (None, 3, 14, 14, 32 0           Conv3d_4f_1b_3x3_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_4f_2b_3x3 (Activation)   (None, 3, 14, 14, 12 0           Conv3d_4f_2b_3x3_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_4f_3b_1x1 (Activation)   (None, 3, 14, 14, 12 0           Conv3d_4f_3b_1x1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_4f (Concatenate)          (None, 3, 14, 14, 83 0           Conv3d_4f_0a_1x1[0][0]           \n",
            "                                                                 Conv3d_4f_1b_3x3[0][0]           \n",
            "                                                                 Conv3d_4f_2b_3x3[0][0]           \n",
            "                                                                 Conv3d_4f_3b_1x1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "MaxPool2d_5a_2x2 (MaxPooling3D) (None, 2, 7, 7, 832) 0           Mixed_4f[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_5b_1a_1x1_conv (Conv3D)  (None, 2, 7, 7, 160) 133120      MaxPool2d_5a_2x2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_5b_2a_1x1_conv (Conv3D)  (None, 2, 7, 7, 32)  26624       MaxPool2d_5a_2x2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_5b_1a_1x1_bn (BatchNorma (None, 2, 7, 7, 160) 480         Conv3d_5b_1a_1x1_conv[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_5b_2a_1x1_bn (BatchNorma (None, 2, 7, 7, 32)  96          Conv3d_5b_2a_1x1_conv[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_5b_1a_1x1 (Activation)   (None, 2, 7, 7, 160) 0           Conv3d_5b_1a_1x1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_5b_2a_1x1 (Activation)   (None, 2, 7, 7, 32)  0           Conv3d_5b_2a_1x1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "MaxPool2d_5b_3a_3x3 (MaxPooling (None, 2, 7, 7, 832) 0           MaxPool2d_5a_2x2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_5b_0a_1x1_conv (Conv3D)  (None, 2, 7, 7, 256) 212992      MaxPool2d_5a_2x2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_5b_1b_3x3_conv (Conv3D)  (None, 2, 7, 7, 320) 1382400     Conv3d_5b_1a_1x1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_5b_2b_3x3_conv (Conv3D)  (None, 2, 7, 7, 128) 110592      Conv3d_5b_2a_1x1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_5b_3b_1x1_conv (Conv3D)  (None, 2, 7, 7, 128) 106496      MaxPool2d_5b_3a_3x3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_5b_0a_1x1_bn (BatchNorma (None, 2, 7, 7, 256) 768         Conv3d_5b_0a_1x1_conv[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_5b_1b_3x3_bn (BatchNorma (None, 2, 7, 7, 320) 960         Conv3d_5b_1b_3x3_conv[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_5b_2b_3x3_bn (BatchNorma (None, 2, 7, 7, 128) 384         Conv3d_5b_2b_3x3_conv[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_5b_3b_1x1_bn (BatchNorma (None, 2, 7, 7, 128) 384         Conv3d_5b_3b_1x1_conv[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_5b_0a_1x1 (Activation)   (None, 2, 7, 7, 256) 0           Conv3d_5b_0a_1x1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_5b_1b_3x3 (Activation)   (None, 2, 7, 7, 320) 0           Conv3d_5b_1b_3x3_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_5b_2b_3x3 (Activation)   (None, 2, 7, 7, 128) 0           Conv3d_5b_2b_3x3_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_5b_3b_1x1 (Activation)   (None, 2, 7, 7, 128) 0           Conv3d_5b_3b_1x1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_5b (Concatenate)          (None, 2, 7, 7, 832) 0           Conv3d_5b_0a_1x1[0][0]           \n",
            "                                                                 Conv3d_5b_1b_3x3[0][0]           \n",
            "                                                                 Conv3d_5b_2b_3x3[0][0]           \n",
            "                                                                 Conv3d_5b_3b_1x1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_5c_1a_1x1_conv (Conv3D)  (None, 2, 7, 7, 192) 159744      Mixed_5b[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_5c_2a_1x1_conv (Conv3D)  (None, 2, 7, 7, 48)  39936       Mixed_5b[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_5c_1a_1x1_bn (BatchNorma (None, 2, 7, 7, 192) 576         Conv3d_5c_1a_1x1_conv[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_5c_2a_1x1_bn (BatchNorma (None, 2, 7, 7, 48)  144         Conv3d_5c_2a_1x1_conv[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_5c_1a_1x1 (Activation)   (None, 2, 7, 7, 192) 0           Conv3d_5c_1a_1x1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_5c_2a_1x1 (Activation)   (None, 2, 7, 7, 48)  0           Conv3d_5c_2a_1x1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "MaxPool2d_5c_3a_3x3 (MaxPooling (None, 2, 7, 7, 832) 0           Mixed_5b[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_5c_0a_1x1_conv (Conv3D)  (None, 2, 7, 7, 384) 319488      Mixed_5b[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_5c_1b_3x3_conv (Conv3D)  (None, 2, 7, 7, 384) 1990656     Conv3d_5c_1a_1x1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_5c_2b_3x3_conv (Conv3D)  (None, 2, 7, 7, 128) 165888      Conv3d_5c_2a_1x1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_5c_3b_1x1_conv (Conv3D)  (None, 2, 7, 7, 128) 106496      MaxPool2d_5c_3a_3x3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_5c_0a_1x1_bn (BatchNorma (None, 2, 7, 7, 384) 1152        Conv3d_5c_0a_1x1_conv[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_5c_1b_3x3_bn (BatchNorma (None, 2, 7, 7, 384) 1152        Conv3d_5c_1b_3x3_conv[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_5c_2b_3x3_bn (BatchNorma (None, 2, 7, 7, 128) 384         Conv3d_5c_2b_3x3_conv[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_5c_3b_1x1_bn (BatchNorma (None, 2, 7, 7, 128) 384         Conv3d_5c_3b_1x1_conv[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_5c_0a_1x1 (Activation)   (None, 2, 7, 7, 384) 0           Conv3d_5c_0a_1x1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_5c_1b_3x3 (Activation)   (None, 2, 7, 7, 384) 0           Conv3d_5c_1b_3x3_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_5c_2b_3x3 (Activation)   (None, 2, 7, 7, 128) 0           Conv3d_5c_2b_3x3_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Conv3d_5c_3b_1x1 (Activation)   (None, 2, 7, 7, 128) 0           Conv3d_5c_3b_1x1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_5c (Concatenate)          (None, 2, 7, 7, 1024 0           Conv3d_5c_0a_1x1[0][0]           \n",
            "                                                                 Conv3d_5c_1b_3x3[0][0]           \n",
            "                                                                 Conv3d_5c_2b_3x3[0][0]           \n",
            "                                                                 Conv3d_5c_3b_1x1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "global_avg_pool (AveragePooling (None, 1, 1, 1, 1024 0           Mixed_5c[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 1, 1, 1, 1024 0           global_avg_pool[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 1, 1, 1, 10)  10250       dropout_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 10)           0           dense_4[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 12,282,842\n",
            "Trainable params: 12,268,282\n",
            "Non-trainable params: 14,560\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "198"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    }
  ]
}
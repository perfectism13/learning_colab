{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "keras-video-classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/perfectism13/learning_colab/blob/master/keras_video_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6BdIlTBdcz7",
        "colab_type": "text"
      },
      "source": [
        "#用keras实现动作分类"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ok4hrBM5dUOL",
        "colab_type": "text"
      },
      "source": [
        "##前期准备"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nv2cZL9RXLuw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6WjipZvXc8x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir(r'/content/drive/My Drive/colab/keras-video-classification/keras-video-classification')\n",
        "print(os.getcwd())\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PjEirPJZBVf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!apt-get install p7zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BN1hQqAOXwS4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!7z x sports-type-classifier-data.7z"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RfLOVCuZ7oV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls\n",
        "!tree --dirsfirst --filelimit 50"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dh_Vl3stdjtl",
        "colab_type": "text"
      },
      "source": [
        "##开始"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTfGb80fdwiM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# USAGE\n",
        "# python train.py --dataset Sports-Type-Classifier/data --model model/activity.model --label-bin model/lb.pickle --epochs 50\n",
        "\n",
        "# set the matplotlib backend so figures can be saved in the background\n",
        "import matplotlib\n",
        "matplotlib.use(\"Agg\")\n",
        "\n",
        "# import the necessary packages\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers.pooling import AveragePooling2D\n",
        "from keras.applications import ResNet50\n",
        "from keras.layers.core import Dropout\n",
        "from keras.layers.core import Flatten\n",
        "from keras.layers.core import Dense\n",
        "from keras.layers import Input\n",
        "from keras.models import Model\n",
        "from keras.optimizers import SGD\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from imutils import paths\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import argparse\n",
        "import pickle\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "# construct the argument parser and parse the arguments\n",
        "# 构建python文件运行时的命令行输入\n",
        "ap = argparse.ArgumentParser()\n",
        "ap.add_argument(\"-d\", \"--dataset\", required=True,\n",
        "\thelp=\"path to input dataset\")\n",
        "ap.add_argument(\"-m\", \"--model\", required=True,\n",
        "\thelp=\"path to output serialized model\")\n",
        "ap.add_argument(\"-l\", \"--label-bin\", required=True,\n",
        "\thelp=\"path to output label binarizer\")\n",
        "ap.add_argument(\"-e\", \"--epochs\", type=int, default=25,\n",
        "\thelp=\"# of epochs to train our network for\")\n",
        "ap.add_argument(\"-p\", \"--plot\", type=str, default=\"plot.png\",\n",
        "\thelp=\"path to output loss/accuracy plot\")\n",
        "args = vars(ap.parse_args())\n",
        "\n",
        "# initialize the set of labels from the spots activity dataset we are\n",
        "# going to train our network on\n",
        "LABELS = set([\"weight_lifting\", \"tennis\", \"football\"])\n",
        "\n",
        "# grab the list of images in our dataset directory, then initialize\n",
        "# the list of data (i.e., images) and class images\n",
        "print(\"[INFO] loading images...\")\n",
        "# 通过imtuils的paths类获取dataset对应路径下所有图片的路径\n",
        "imagePaths = list(paths.list_images(args[\"dataset\"])) \n",
        "data = []\n",
        "labels = []\n",
        "\n",
        "# loop over the image paths\n",
        "for imagePath in imagePaths:\n",
        "\t# extract the class label from the filename\n",
        "\tlabel = imagePath.split(os.path.sep)[-2]\n",
        "\n",
        "\t# if the label of the current image is not part of of the labels\n",
        "\t# are interested in, then ignore the image\n",
        "\t# 跳过不参与训练的标签对应的图片\n",
        "\tif label not in LABELS:\n",
        "\t\tcontinue\n",
        "\n",
        "\t# load the image, convert it to RGB channel ordering, and resize\n",
        "\t# it to be a fixed 224x224 pixels, ignoring aspect ratio\n",
        "\timage = cv2.imread(imagePath)\n",
        "\timage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\timage = cv2.resize(image, (224, 224))\n",
        "\n",
        "\t# update the data and labels lists, respectively\n",
        "\t# 储存训练标签和图片\n",
        "\tdata.append(image)\n",
        "\tlabels.append(label)\n",
        "\n",
        "# convert the data and labels to NumPy arrays\n",
        "# 将数据和标签转换成numpy数组\n",
        "data = np.array(data)\n",
        "labels = np.array(labels)\n",
        "\n",
        "# perform one-hot encoding on the labels\n",
        "# 通过二值元素数组来对标签进行一键编码\n",
        "lb = LabelBinarizer()\n",
        "labels = lb.fit_transform(labels)\n",
        "\n",
        "# partition the data into training and testing splits using 75% of\n",
        "# the data for training and the remaining 25% for testing\n",
        "# 将整个数据的%75用来训练剩下的用来检验\n",
        "(trainX, testX, trainY, testY) = train_test_split(data, labels,\n",
        "\ttest_size=0.25, stratify=labels, random_state=42)\n",
        "\n",
        "# initialize the training data augmentation object\n",
        "# 声明训练时的数据增强操作\n",
        "trainAug = ImageDataGenerator(\n",
        "\trotation_range=30,\n",
        "\tzoom_range=0.15,\n",
        "\twidth_shift_range=0.2,\n",
        "\theight_shift_range=0.2,\n",
        "\tshear_range=0.15,\n",
        "\thorizontal_flip=True,\n",
        "\tfill_mode=\"nearest\")\n",
        "\n",
        "# initialize the validation/testing data augmentation object (which\n",
        "# we'll be adding mean subtraction to)\n",
        "# 测验时无数据增强操作\n",
        "valAug = ImageDataGenerator()\n",
        "\n",
        "# define the ImageNet mean subtraction (in RGB order) and set the\n",
        "# the mean subtraction value for each of the data augmentation\n",
        "# objects\n",
        "# 设置训练和测试时用来归一化的图片每个通道的均值\n",
        "mean = np.array([123.68, 116.779, 103.939], dtype=\"float32\")\n",
        "trainAug.mean = mean\n",
        "valAug.mean = mean\n",
        "\n",
        "# load the ResNet-50 network, ensuring the head FC layer sets are left\n",
        "# off\n",
        "# 通过keras.applications来获取预训练的resnet50模型\n",
        "baseModel = ResNet50(weights=\"imagenet\", include_top=False,\n",
        "\tinput_tensor=Input(shape=(224, 224, 3)))\n",
        "\n",
        "# construct the head of the model that will be placed on top of the\n",
        "# the base model\n",
        "# 定义basemodel前的全连接层\n",
        "headModel = baseModel.output\n",
        "headModel = AveragePooling2D(pool_size=(7, 7))(headModel)\n",
        "headModel = Flatten(name=\"flatten\")(headModel)\n",
        "headModel = Dense(512, activation=\"relu\")(headModel)\n",
        "headModel = Dropout(0.5)(headModel)\n",
        "headModel = Dense(len(lb.classes_), activation=\"softmax\")(headModel)\n",
        "\n",
        "# place the head FC model on top of the base model (this will become\n",
        "# the actual model we will train)\n",
        "# 在basemodel前加上一个全连接层来微调\n",
        "model = Model(inputs=baseModel.input, outputs=headModel)\n",
        "\n",
        "# loop over all layers in the base model and freeze them so they will\n",
        "# *not* be updated during the training process\n",
        "# 训练时将basemodel里的全部参数冻结\n",
        "for layer in baseModel.layers:\n",
        "\tlayer.trainable = False\n",
        "\n",
        "# compile our model (this needs to be done after our setting our\n",
        "# layers to being non-trainable)\n",
        "# 定义初始学习率和优化方法来编译模型\n",
        "print(\"[INFO] compiling model...\")\n",
        "opt = SGD(lr=1e-4, momentum=0.9, decay=1e-4 / args[\"epochs\"])\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
        "\tmetrics=[\"accuracy\"])\n",
        "\n",
        "# train the head of the network for a few epochs (all other layers\n",
        "# are frozen) -- this will allow the new FC layers to start to become\n",
        "# initialized with actual \"learned\" values versus pure random\n",
        "# 使用fit_generator类来对逐批生成的数据进行训练\n",
        "print(\"[INFO] training head...\")\n",
        "H = model.fit_generator(\n",
        "\ttrainAug.flow(trainX, trainY, batch_size=32),\n",
        "\tsteps_per_epoch=len(trainX) // 32,\n",
        "\tvalidation_data=valAug.flow(testX, testY),\n",
        "\tvalidation_steps=len(testX) // 32,\n",
        "\tepochs=args[\"epochs\"])\n",
        "\n",
        "# evaluate the network\n",
        "# 使用sklearn的classification_report类查看预测效果\n",
        "print(\"[INFO] evaluating network...\")\n",
        "predictions = model.predict(testX, batch_size=32)\n",
        "print(classification_report(testY.argmax(axis=1), \n",
        "\tpredictions.argmax(axis=1), target_names=lb.classes_))\n",
        "\n",
        "# plot the training loss and accuracy\n",
        "# 打印训练loss和准确性等\n",
        "N = args[\"epochs\"]\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.plot(np.arange(0, N), H.history[\"acc\"], label=\"train_acc\")\n",
        "plt.plot(np.arange(0, N), H.history[\"val_acc\"], label=\"val_acc\")\n",
        "plt.title(\"Training Loss and Accuracy on Dataset\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss/Accuracy\")\n",
        "plt.legend(loc=\"lower left\") # 标签说明放在左下角\n",
        "plt.savefig(args[\"plot\"])\n",
        "\n",
        "# serialize the model to disk\n",
        "# 讲训练好的模型保存\n",
        "print(\"[INFO] serializing network...\")\n",
        "model.save(args[\"model\"])\n",
        "\n",
        "# serialize the label binarizer to disk\n",
        "# 保存标签二值化器\n",
        "f = open(args[\"label_bin\"], \"wb\")\n",
        "f.write(pickle.dumps(lb))\n",
        "f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIz7IJINfuXn",
        "colab_type": "code",
        "outputId": "6be709b0-4ea1-4829-e149-4176d98a13d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python train.py --dataset data --model output/activity.model \\\n",
        "\t--label-bin output/lb.pickle --epochs 50"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "[INFO] loading images...\n",
            "libpng warning: iCCP: known incorrect sRGB profile\n",
            "libpng warning: iCCP: known incorrect sRGB profile\n",
            "libpng warning: iCCP: known incorrect sRGB profile\n",
            "libpng warning: iCCP: known incorrect sRGB profile\n",
            "libpng warning: iCCP: known incorrect sRGB profile\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4479: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2019-12-14 08:24:02.011318: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2019-12-14 08:24:02.013846: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2306840 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2019-12-14 08:24:02.013885: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2019-12-14 08:24:02.018815: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2019-12-14 08:24:02.152830: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-14 08:24:02.153830: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2306bc0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2019-12-14 08:24:02.153865: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
            "2019-12-14 08:24:02.155504: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-14 08:24:02.156205: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-12-14 08:24:02.176292: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2019-12-14 08:24:02.394209: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2019-12-14 08:24:02.508460: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2019-12-14 08:24:02.530840: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2019-12-14 08:24:02.748284: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2019-12-14 08:24:02.770949: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2019-12-14 08:24:03.213586: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-12-14 08:24:03.213829: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-14 08:24:03.214779: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-14 08:24:03.215576: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2019-12-14 08:24:03.220635: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2019-12-14 08:24:03.222331: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-12-14 08:24:03.222385: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2019-12-14 08:24:03.222418: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2019-12-14 08:24:03.223491: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-14 08:24:03.224341: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-14 08:24:03.225215: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2019-12-14 08:24:03.225289: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10805 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
            "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n",
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94658560/94653016 [==============================] - 7s 0us/step\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4271: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "[INFO] compiling model...\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "[INFO] training head...\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Epoch 1/50\n",
            "2019-12-14 08:24:25.840365: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2019-12-14 08:24:26.891772: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "48/48 [==============================] - 29s 597ms/step - loss: 1.2660 - acc: 0.3822 - val_loss: 0.9862 - val_acc: 0.5332\n",
            "Epoch 2/50\n",
            "48/48 [==============================] - 24s 504ms/step - loss: 1.0399 - acc: 0.4962 - val_loss: 0.8028 - val_acc: 0.6337\n",
            "Epoch 3/50\n",
            "48/48 [==============================] - 24s 496ms/step - loss: 0.8882 - acc: 0.5950 - val_loss: 0.6543 - val_acc: 0.7119\n",
            "Epoch 4/50\n",
            "48/48 [==============================] - 23s 478ms/step - loss: 0.8053 - acc: 0.6517 - val_loss: 0.5938 - val_acc: 0.7510\n",
            "Epoch 5/50\n",
            "48/48 [==============================] - 23s 479ms/step - loss: 0.7165 - acc: 0.6940 - val_loss: 0.4964 - val_acc: 0.8045\n",
            "Epoch 6/50\n",
            "48/48 [==============================] - 24s 490ms/step - loss: 0.6342 - acc: 0.7500 - val_loss: 0.4970 - val_acc: 0.8148\n",
            "Epoch 7/50\n",
            "48/48 [==============================] - 23s 471ms/step - loss: 0.6217 - acc: 0.7526 - val_loss: 0.4313 - val_acc: 0.8313\n",
            "Epoch 8/50\n",
            "48/48 [==============================] - 22s 464ms/step - loss: 0.5881 - acc: 0.7832 - val_loss: 0.3984 - val_acc: 0.8683\n",
            "Epoch 9/50\n",
            "48/48 [==============================] - 23s 475ms/step - loss: 0.5611 - acc: 0.7741 - val_loss: 0.4083 - val_acc: 0.8498\n",
            "Epoch 10/50\n",
            "48/48 [==============================] - 23s 471ms/step - loss: 0.5241 - acc: 0.8073 - val_loss: 0.3564 - val_acc: 0.8807\n",
            "Epoch 11/50\n",
            "48/48 [==============================] - 22s 459ms/step - loss: 0.4947 - acc: 0.8171 - val_loss: 0.3755 - val_acc: 0.8642\n",
            "Epoch 12/50\n",
            "48/48 [==============================] - 22s 467ms/step - loss: 0.4841 - acc: 0.8190 - val_loss: 0.3499 - val_acc: 0.8704\n",
            "Epoch 13/50\n",
            "48/48 [==============================] - 22s 463ms/step - loss: 0.4801 - acc: 0.8196 - val_loss: 0.3397 - val_acc: 0.8704\n",
            "Epoch 14/50\n",
            "48/48 [==============================] - 22s 455ms/step - loss: 0.4430 - acc: 0.8242 - val_loss: 0.3491 - val_acc: 0.8786\n",
            "Epoch 15/50\n",
            "48/48 [==============================] - 22s 456ms/step - loss: 0.4179 - acc: 0.8477 - val_loss: 0.2985 - val_acc: 0.8909\n",
            "Epoch 16/50\n",
            "48/48 [==============================] - 22s 448ms/step - loss: 0.4189 - acc: 0.8379 - val_loss: 0.3302 - val_acc: 0.8807\n",
            "Epoch 17/50\n",
            "48/48 [==============================] - 22s 454ms/step - loss: 0.4167 - acc: 0.8425 - val_loss: 0.3139 - val_acc: 0.8868\n",
            "Epoch 18/50\n",
            "48/48 [==============================] - 22s 464ms/step - loss: 0.3985 - acc: 0.8444 - val_loss: 0.3067 - val_acc: 0.8926\n",
            "Epoch 19/50\n",
            "48/48 [==============================] - 21s 447ms/step - loss: 0.3881 - acc: 0.8587 - val_loss: 0.3024 - val_acc: 0.8951\n",
            "Epoch 20/50\n",
            "48/48 [==============================] - 22s 459ms/step - loss: 0.3944 - acc: 0.8548 - val_loss: 0.2902 - val_acc: 0.8992\n",
            "Epoch 21/50\n",
            "48/48 [==============================] - 21s 446ms/step - loss: 0.3782 - acc: 0.8620 - val_loss: 0.2824 - val_acc: 0.9115\n",
            "Epoch 22/50\n",
            "48/48 [==============================] - 21s 440ms/step - loss: 0.4034 - acc: 0.8412 - val_loss: 0.3105 - val_acc: 0.9012\n",
            "Epoch 23/50\n",
            "48/48 [==============================] - 22s 461ms/step - loss: 0.3600 - acc: 0.8691 - val_loss: 0.2667 - val_acc: 0.9012\n",
            "Epoch 24/50\n",
            "48/48 [==============================] - 22s 456ms/step - loss: 0.3357 - acc: 0.8750 - val_loss: 0.2630 - val_acc: 0.9177\n",
            "Epoch 25/50\n",
            "48/48 [==============================] - 21s 440ms/step - loss: 0.3411 - acc: 0.8737 - val_loss: 0.3130 - val_acc: 0.8951\n",
            "Epoch 26/50\n",
            "48/48 [==============================] - 22s 460ms/step - loss: 0.3312 - acc: 0.8848 - val_loss: 0.2747 - val_acc: 0.9198\n",
            "Epoch 27/50\n",
            "48/48 [==============================] - 22s 448ms/step - loss: 0.3401 - acc: 0.8691 - val_loss: 0.2811 - val_acc: 0.9033\n",
            "Epoch 28/50\n",
            "48/48 [==============================] - 21s 445ms/step - loss: 0.3326 - acc: 0.8776 - val_loss: 0.2546 - val_acc: 0.9280\n",
            "Epoch 29/50\n",
            "48/48 [==============================] - 21s 442ms/step - loss: 0.3445 - acc: 0.8692 - val_loss: 0.2683 - val_acc: 0.9156\n",
            "Epoch 30/50\n",
            "48/48 [==============================] - 22s 454ms/step - loss: 0.3072 - acc: 0.8854 - val_loss: 0.2658 - val_acc: 0.9095\n",
            "Epoch 31/50\n",
            "48/48 [==============================] - 22s 449ms/step - loss: 0.3029 - acc: 0.8978 - val_loss: 0.2819 - val_acc: 0.9033\n",
            "Epoch 32/50\n",
            "48/48 [==============================] - 22s 457ms/step - loss: 0.3123 - acc: 0.8900 - val_loss: 0.2680 - val_acc: 0.9198\n",
            "Epoch 33/50\n",
            "48/48 [==============================] - 22s 450ms/step - loss: 0.3020 - acc: 0.8867 - val_loss: 0.2422 - val_acc: 0.9198\n",
            "Epoch 34/50\n",
            "48/48 [==============================] - 22s 463ms/step - loss: 0.3244 - acc: 0.8802 - val_loss: 0.2712 - val_acc: 0.9115\n",
            "Epoch 35/50\n",
            "48/48 [==============================] - 22s 462ms/step - loss: 0.2898 - acc: 0.8952 - val_loss: 0.2588 - val_acc: 0.9160\n",
            "Epoch 36/50\n",
            "48/48 [==============================] - 22s 454ms/step - loss: 0.3157 - acc: 0.8854 - val_loss: 0.2807 - val_acc: 0.9095\n",
            "Epoch 37/50\n",
            "48/48 [==============================] - 22s 465ms/step - loss: 0.3021 - acc: 0.8848 - val_loss: 0.2514 - val_acc: 0.9218\n",
            "Epoch 38/50\n",
            "48/48 [==============================] - 22s 453ms/step - loss: 0.3053 - acc: 0.8731 - val_loss: 0.2646 - val_acc: 0.9053\n",
            "Epoch 39/50\n",
            "48/48 [==============================] - 22s 454ms/step - loss: 0.2845 - acc: 0.8874 - val_loss: 0.2502 - val_acc: 0.9177\n",
            "Epoch 40/50\n",
            "48/48 [==============================] - 21s 443ms/step - loss: 0.2850 - acc: 0.8972 - val_loss: 0.2571 - val_acc: 0.9136\n",
            "Epoch 41/50\n",
            "48/48 [==============================] - 22s 461ms/step - loss: 0.2892 - acc: 0.8997 - val_loss: 0.2667 - val_acc: 0.9156\n",
            "Epoch 42/50\n",
            "48/48 [==============================] - 22s 450ms/step - loss: 0.2804 - acc: 0.8971 - val_loss: 0.2466 - val_acc: 0.9115\n",
            "Epoch 43/50\n",
            "48/48 [==============================] - 21s 436ms/step - loss: 0.2756 - acc: 0.8978 - val_loss: 0.2548 - val_acc: 0.9177\n",
            "Epoch 44/50\n",
            "48/48 [==============================] - 21s 445ms/step - loss: 0.2730 - acc: 0.9010 - val_loss: 0.2562 - val_acc: 0.9239\n",
            "Epoch 45/50\n",
            "48/48 [==============================] - 21s 443ms/step - loss: 0.2724 - acc: 0.9017 - val_loss: 0.2561 - val_acc: 0.9259\n",
            "Epoch 46/50\n",
            "48/48 [==============================] - 22s 455ms/step - loss: 0.2871 - acc: 0.8906 - val_loss: 0.2700 - val_acc: 0.9239\n",
            "Epoch 47/50\n",
            "48/48 [==============================] - 22s 456ms/step - loss: 0.2734 - acc: 0.9017 - val_loss: 0.2244 - val_acc: 0.9259\n",
            "Epoch 48/50\n",
            "48/48 [==============================] - 22s 453ms/step - loss: 0.2570 - acc: 0.9062 - val_loss: 0.2566 - val_acc: 0.9156\n",
            "Epoch 49/50\n",
            "48/48 [==============================] - 22s 450ms/step - loss: 0.2457 - acc: 0.9069 - val_loss: 0.2649 - val_acc: 0.9177\n",
            "Epoch 50/50\n",
            "48/48 [==============================] - 21s 446ms/step - loss: 0.2753 - acc: 0.8997 - val_loss: 0.2346 - val_acc: 0.9300\n",
            "[INFO] evaluating network...\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "      football       0.92      0.95      0.93       196\n",
            "        tennis       0.92      0.91      0.92       179\n",
            "weight_lifting       0.94      0.91      0.92       143\n",
            "\n",
            "      accuracy                           0.92       518\n",
            "     macro avg       0.93      0.92      0.92       518\n",
            "  weighted avg       0.92      0.92      0.92       518\n",
            "\n",
            "[INFO] serializing network...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3ksAhtCmIvf",
        "colab_type": "text"
      },
      "source": [
        "##用滚动预测平均的方式应用模型到视频分类中"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9CxK70Vl3-K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# USAGE\n",
        "# python predict_video.py --model model/activity.model --label-bin model/lb.pickle --input example_clips/lifting.mp4 --output output/lifting_128avg.avi --size 128\n",
        "\n",
        "# import the necessary packages\n",
        "from keras.models import load_model\n",
        "from collections import deque #用来实现滑动平均\n",
        "import numpy as np\n",
        "import argparse\n",
        "import pickle\n",
        "import cv2\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# construct the argument parser and parse the arguments\n",
        "ap = argparse.ArgumentParser()\n",
        "ap.add_argument(\"-m\", \"--model\", required=True,\n",
        "\thelp=\"path to trained serialized model\")\n",
        "ap.add_argument(\"-l\", \"--label-bin\", required=True,\n",
        "\thelp=\"path to  label binarizer\")\n",
        "ap.add_argument(\"-i\", \"--input\", required=True,\n",
        "\thelp=\"path to our input video\")\n",
        "ap.add_argument(\"-o\", \"--output\", required=True,\n",
        "\thelp=\"path to our output video\")\n",
        "ap.add_argument(\"-s\", \"--size\", type=int, default=128,\n",
        "\thelp=\"size of queue for averaging\")\n",
        "args = vars(ap.parse_args())\n",
        "\n",
        "# load the trained model and label binarizer from disk\n",
        "# 从命令行的声明载入训练好的模型以及二值化\n",
        "print(\"[INFO] loading model and label binarizer...\")\n",
        "model = load_model(args[\"model\"])\n",
        "lb = pickle.loads(open(args[\"label_bin\"], \"rb\").read())\n",
        "\n",
        "# initialize the image mean for mean subtraction along with the\n",
        "# predictions queue\n",
        "mean = np.array([123.68, 116.779, 103.939][::1], dtype=\"float32\")\n",
        "# 初始化Q为一个双向序列，deque的尺寸由size决定\n",
        "Q = deque(maxlen=args[\"size\"])\n",
        "\n",
        "# initialize the video stream, pointer to output video file, and\n",
        "# frame dimensions\n",
        "# 使用opencv的VideoCapture类读取视频流，并初始化视频写入类\n",
        "vs = cv2.VideoCapture(args[\"input\"])\n",
        "writer = None\n",
        "(W, H) = (None, None)\n",
        "\n",
        "# loop over frames from the video file stream\n",
        "# 循环抓取被测试视频的帧\n",
        "while True:\n",
        "\t# read the next frame from the file\n",
        "\t(grabbed, frame) = vs.read()\n",
        "\n",
        "\t# if the frame was not grabbed, then we have reached the end\n",
        "\t# of the stream\n",
        "\t# 如果没有抓取到视频帧，则退出\n",
        "\tif not grabbed:\n",
        "\t\tbreak\n",
        "\n",
        "\t# if the frame dimensions are empty, grab them\n",
        "\tif W is None or H is None:\n",
        "\t\t(H, W) = frame.shape[:2]\n",
        "\n",
        "\t# clone the output frame, then convert it from BGR to RGB\n",
        "\t# ordering, resize the frame to a fixed 224x224, and then\n",
        "\t# perform mean subtraction 归一化操作\n",
        "\toutput = frame.copy()\n",
        "\tframe = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\tframe = cv2.resize(frame, (224, 224)).astype(\"float32\")\n",
        "\tframe -= mean\n",
        "\n",
        "\t# make predictions on the frame and then update the predictions\n",
        "\t# queue\n",
        "\t# 新建一维用来储存每一帧对应的分类结果\n",
        "\tpreds = model.predict(np.expand_dims(frame, axis=0))[0]\n",
        "\t# 将预测值加载Q后面\n",
        "\tQ.append(preds)\n",
        "\n",
        "\t# perform prediction averaging over the current history of\n",
        "\t# previous predictions\n",
        "\t# 先平均到K个概率输出值，在取最大\n",
        "\tresults = np.array(Q).mean(axis=0)\n",
        "\ti = np.argmax(results)\n",
        "\tlabel = lb.classes_[i]\n",
        "\n",
        "\t# draw the activity on the output frame\n",
        "\ttext = \"activity: {}\".format(label)\n",
        "\tcv2.putText(output, text, (35, 50), cv2.FONT_HERSHEY_SIMPLEX,\n",
        "\t\t1.25, (0, 255, 0), 5)\n",
        "\n",
        "\t# check if the video writer is None\n",
        "\tif writer is None:\n",
        "\t\t# initialize our video writer\n",
        "\t\tfourcc = cv2.VideoWriter_fourcc(*\"MJPG\")\n",
        "\t\twriter = cv2.VideoWriter(args[\"output\"], fourcc, 30,\n",
        "\t\t\t(W, H), True)\n",
        "\n",
        "\t# write the output frame to disk\n",
        "\twriter.write(output)\n",
        "\n",
        "\t# show the output image\n",
        "\t# 避免cannot connect to X server，此处使用matplotlib\n",
        "\t# cv2.imshow(\"Output\", output)\n",
        "  plt.imshow(output)\n",
        "\tkey = cv2.waitKey(1) & 0xFF\n",
        "\n",
        "\t# if the `q` key was pressed, break from the loop\n",
        "\tif key == ord(\"q\"):\n",
        "\t\tbreak\n",
        "\n",
        "# release the file pointers\n",
        "print(\"[INFO] cleaning up...\")\n",
        "writer.release()\n",
        "vs.release()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khIB0zDvA-xw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!sudo apt-get install tree"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "revfB14NFrzU",
        "colab_type": "code",
        "outputId": "81e11aa5-c9ec-4e3f-9299-15276bc76ecb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!tree --dirsfirst --filelimit 50"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".\n",
            "├── data\n",
            "│   ├── badminton [938 entries exceeds filelimit, not opening dir]\n",
            "│   ├── baseball [746 entries exceeds filelimit, not opening dir]\n",
            "│   ├── basketball [495 entries exceeds filelimit, not opening dir]\n",
            "│   ├── boxing [705 entries exceeds filelimit, not opening dir]\n",
            "│   ├── chess [481 entries exceeds filelimit, not opening dir]\n",
            "│   ├── cricket [715 entries exceeds filelimit, not opening dir]\n",
            "│   ├── fencing [635 entries exceeds filelimit, not opening dir]\n",
            "│   ├── football [799 entries exceeds filelimit, not opening dir]\n",
            "│   ├── formula1 [687 entries exceeds filelimit, not opening dir]\n",
            "│   ├── gymnastics [719 entries exceeds filelimit, not opening dir]\n",
            "│   ├── hockey [572 entries exceeds filelimit, not opening dir]\n",
            "│   ├── ice_hockey [715 entries exceeds filelimit, not opening dir]\n",
            "│   ├── kabaddi [454 entries exceeds filelimit, not opening dir]\n",
            "│   ├── models\n",
            "│   │   ├── res50-stage-1.pth\n",
            "│   │   ├── res50-stage-2.pth\n",
            "│   │   ├── res50-stage-3.pth\n",
            "│   │   ├── stage-1.pth\n",
            "│   │   ├── tmp.pth\n",
            "│   │   └── unfreeze-stage-1.pth\n",
            "│   ├── motogp [679 entries exceeds filelimit, not opening dir]\n",
            "│   ├── shooting [536 entries exceeds filelimit, not opening dir]\n",
            "│   ├── swimming [689 entries exceeds filelimit, not opening dir]\n",
            "│   ├── table_tennis [713 entries exceeds filelimit, not opening dir]\n",
            "│   ├── tennis [718 entries exceeds filelimit, not opening dir]\n",
            "│   ├── volleyball [713 entries exceeds filelimit, not opening dir]\n",
            "│   ├── weight_lifting [577 entries exceeds filelimit, not opening dir]\n",
            "│   ├── wrestling [611 entries exceeds filelimit, not opening dir]\n",
            "│   ├── wwe [671 entries exceeds filelimit, not opening dir]\n",
            "│   ├── badminton_urls.txt\n",
            "│   ├── baseball_urls.txt\n",
            "│   ├── basketball_urls.txt\n",
            "│   ├── boxing_urls.txt\n",
            "│   ├── chess_urls.txt\n",
            "│   ├── cleaned.csv\n",
            "│   ├── cricket_urls.txt\n",
            "│   ├── export.pkl\n",
            "│   ├── fencing_urls.txt\n",
            "│   ├── football_urls.txt\n",
            "│   ├── formula1_urls.txt\n",
            "│   ├── gymnastics_urls.txt\n",
            "│   ├── hockey_urls.txt\n",
            "│   ├── ice_hockey_urls.txt\n",
            "│   ├── kabaddi_urls.txt\n",
            "│   ├── motogp_urls.txt\n",
            "│   ├── shooting_urls.txt\n",
            "│   ├── swimming_urls.txt\n",
            "│   ├── table_tennis_urls.txt\n",
            "│   ├── tennis_urls.txt\n",
            "│   ├── volleyball_urls.txt\n",
            "│   ├── weight_lifting_urls.txt\n",
            "│   ├── wrestling_urls.txt\n",
            "│   └── wwe_urls.txt\n",
            "├── example_clips\n",
            "│   ├── lifting.mp4\n",
            "│   ├── soccer.mp4\n",
            "│   └── tennis.mp4\n",
            "├── model\n",
            "├── output\n",
            "│   ├── activity.model\n",
            "│   ├── lb.pickle\n",
            "│   ├── tennis_128frames_smoothened.avi\n",
            "│   ├── tennis_128frames_smoothened (convert-video-online.com).mp4\n",
            "│   └── tennis_1frame.avi\n",
            "├── Sports-Type-Classifier\n",
            "│   ├── readme_images\n",
            "│   │   ├── acc_sports.png\n",
            "│   │   ├── cric.png\n",
            "│   │   ├── heat_cric.png\n",
            "│   │   ├── si_sports.png\n",
            "│   │   ├── sports_confusion_matrix.png\n",
            "│   │   ├── sports_data_aug.png\n",
            "│   │   └── sports.png\n",
            "│   ├── README.md\n",
            "│   └── sports_classifier.ipynb\n",
            "├── plot.png\n",
            "├── predict_video.py\n",
            "├── sports_classifier.ipynb\n",
            "├── sports-type-classifier-data.7z\n",
            "├── sports-type-classifier-data.zip\n",
            "└── train.py\n",
            "\n",
            "29 directories, 53 files\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAXPZyxrmcoX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python predict_video.py --model output/activity.model \\\n",
        "\t--label-bin output/lb.pickle \\\n",
        "\t--input example_clips/lifting.mp4 \\\n",
        "\t--output output/lifting_128frame.avi \\\n",
        "\t--size 128  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUYCF7nqohB2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python predict_video.py --model output/activity.model \\\n",
        "\t--label-bin output/lb.pickle \\\n",
        "\t--input example_clips/tennis.mp4 \\\n",
        "\t--output output/tennis_128frames_smoothened.avi \\\n",
        "\t--size 128"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
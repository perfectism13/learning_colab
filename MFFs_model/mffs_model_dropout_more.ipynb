{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.4"
    },
    "colab": {
      "name": "mffs_model_dropout_more.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/perfectism13/learning_colab/blob/master/MFFs_model/mffs_model_dropout_more.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5npKCNyvhnF",
        "colab_type": "code",
        "outputId": "3341e595-0afd-46a6-a4eb-1f137b28ca5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os\n",
        "# os.chdir(r'/content/drive/My Drive/colab/mlnd_distracted_driver_detection/state-farm-distracted-driver-detection/imgs/')\n",
        "os.chdir(r'/content/drive/My Drive/state-farm-distracted-driver-detection/imgs/')\n",
        "# os.chdir(r'/content/drive/My Drive/data/imgs/')\n",
        "print(os.getcwd())\n",
        "!ls\n",
        "!pip install keras==2.1.5\n",
        "import keras\n",
        "print(keras.__version__)\n",
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "/content/drive/My Drive/state-farm-distracted-driver-detection/imgs\n",
            "'(1-726)clean.mp4'\n",
            "'(1-726).mp4'\n",
            " 5-0.15993-0.15993.zip\n",
            "'（726-800)clean.mp4'\n",
            " （726-800）.mp4\n",
            "'(726-966)clean.mp4'\n",
            "'(726-966).mp4'\n",
            " C3D_rgbs_model_backup.h5\n",
            " C3D_Sport1M_weights_keras_2.2.4.h5\n",
            " driver_imgs_list_class_2.csv\n",
            " driver_imgs_list_class.csv\n",
            " driver_imgs_list.csv\n",
            " driver_imgs_list_right.csv\n",
            " flow_xception_lock50.h5\n",
            " flow_xception_lock70.h5\n",
            " get-docker.sh\n",
            " I3D_rgbs_model.h5\n",
            " mffs_model_nolock_dropout_more.h5\n",
            " mffs_model_nolock._dropout_more_lr_down.h5\n",
            " mffs_model_nolock_dropout_more_nostopping.h5\n",
            " mffs_model_nolock_dropout_more_nostopping.h5（副本）\n",
            " motion.h5\n",
            " motion.log\n",
            " motion.preds\n",
            " my_model10.h5\n",
            " my_model11.h5\n",
            " my_model12.h5\n",
            " my_model13.h5\n",
            " my_model1.h5\n",
            " my_model9.h5\n",
            " sample_submission.csv\n",
            " test\n",
            " train\n",
            " valid\n",
            " vect\n",
            " video_model_change_vd_data_aug.h5\n",
            " video_model_change_vd_data_aug_modified.h5\n",
            " video_model_change_vd.h5\n",
            "Collecting keras==2.1.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ba/65/e4aff762b8696ec0626a6654b1e73b396fcc8b7cc6b98d78a1bc53b85b48/Keras-2.1.5-py2.py3-none-any.whl (334kB)\n",
            "\u001b[K     |████████████████████████████████| 337kB 3.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.1.5) (1.12.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.1.5) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.1.5) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.1.5) (1.17.5)\n",
            "Installing collected packages: keras\n",
            "  Found existing installation: Keras 2.2.5\n",
            "    Uninstalling Keras-2.2.5:\n",
            "      Successfully uninstalled Keras-2.2.5\n",
            "Successfully installed keras-2.1.5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "2.1.5\n",
            "Fri Feb 14 09:14:25 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.48.02    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   47C    P8    10W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwdUnNY5BNc_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.environ['KERAS_BACKEND']='tensorflow'\n",
        "import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHt6FC_zBNdG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "np.random.seed(2017)\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import cv2\n",
        "import math\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.pooling import MaxPooling2D\n",
        "from keras.optimizers import SGD, Adam, Nadam\n",
        "from keras.utils import np_utils\n",
        "from keras.models import model_from_json\n",
        "from sklearn.metrics import log_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUSMqWoRBNd4",
        "colab_type": "text"
      },
      "source": [
        "### 切分数据\n",
        "按照司机的id来切分训练数据集。把driver_imgs_list分成两个列表。一个是训练列表，里面是所有训练集司机的图片文件名。另一个是验证列表，里面是所有验证集司机的图片文件名。然后把两个列表都随机打乱。 这里列表里面保存的都只是excel文件里的一行行数据（包括文件名，分类，司机id），而不是图片本身。等训练时通过生成器读取图片，这样节约内存。 另外还保存了一个类别字典，便于以后从同一类中抽取图片进行拼接。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYofeN2LBNd5",
        "colab_type": "code",
        "outputId": "6afe6d8d-11bf-4560-8e24-42793e749be5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# divide drivers\n",
        "# unique_list_train = ['p002', 'p012', 'p014', 'p015', 'p026', 'p035', 'p039', 'p041', 'p042', 'p045', 'p047', 'p049', 'p050', 'p051', 'p052', 'p056', 'p061', 'p064', 'p066', 'p072', 'p075']\n",
        "# unique_list_valid = ['p016', 'p021', 'p022', 'p024']\n",
        "unique_list_train = ['p024', 'p026', 'p035', 'p039', 'p041', 'p042', 'p045', 'p047', 'p049', 'p050', 'p051', 'p052', 'p056', 'p061', 'p064', 'p066', 'p072', 'p075']\n",
        "unique_list_valid = ['p002', 'p012', 'p014', 'p015','p016', 'p021', 'p022']\n",
        "#print (unique_list_train, unique_list_valid)\n",
        "\n",
        "# get index: driver_id, class, image name\n",
        "index = os.path.join('.', 'driver_imgs_list_class_2.csv')\n",
        "\n",
        "# build the driver id dictionary and class dictionary\n",
        "f = open(index, 'r')\n",
        "id_dict = dict()\n",
        "class_dict = dict()\n",
        "lines = f.readlines()\n",
        "\n",
        "\n",
        "# split the train list and valid list by id\n",
        "train_list = []\n",
        "valid_list = []\n",
        "\n",
        "for line in lines[1:]:\n",
        "    arr = line.strip().split(',')\n",
        "    if arr[0]  in unique_list_train:\n",
        "        train_list.append(line)\n",
        "    elif arr[0]  in unique_list_valid:\n",
        "      valid_list.append(line)\n",
        "f.close()\n",
        "\n",
        "random.shuffle(train_list)\n",
        "random.shuffle(valid_list)\n",
        "\n",
        "print (len(train_list), len(valid_list))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14754 6847\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsnPujySBNd8",
        "colab_type": "text"
      },
      "source": [
        "### 获取test set图片的列表\n",
        "获取sample_submission.csv中所有测试图片的文件名，预测test set时使用。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzUKzBnjBNd9",
        "colab_type": "code",
        "outputId": "822af96b-a1d2-4f7b-c102-ecee07aaf092",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "test_index = os.path.join('.', 'sample_submission.csv')\n",
        "f = open(test_index, 'r')\n",
        "lines = f.readlines()\n",
        "test_list = []\n",
        "for line in lines[1:]:\n",
        "    arr = line.strip().split(',')\n",
        "    test_list.append(arr[0])\n",
        "f.close()\n",
        "print (test_list[:5])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['img_1.jpg', 'img_10.jpg', 'img_100.jpg', 'img_1000.jpg', 'img_100000.jpg']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nl_N2noABNeB",
        "colab_type": "text"
      },
      "source": [
        "### 转换为One Hot Encode标签\n",
        "\n",
        "对分类标签进行One Hot Encode的函数如下。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18IjONecBNeC",
        "colab_type": "code",
        "outputId": "cface4a5-8423-4711-bfd6-1206ab5dd3c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# one hot encode the class label\n",
        "\n",
        "from sklearn import preprocessing\n",
        "lb = preprocessing.LabelBinarizer()\n",
        "lb.fit(['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9'])   \n",
        "def one_hot_encode(x):\n",
        "    return lb.transform(x)\n",
        "t = one_hot_encode(['c1', 'c2'])\n",
        "print(t)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 1 0 0 0 0 0 0 0 0]\n",
            " [0 0 1 0 0 0 0 0 0 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsQaZPCZa-Xx",
        "colab_type": "text"
      },
      "source": [
        "###获取两帧图片之间的光流"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8PFfA43bJs1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import cv2\n",
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "from random import choice\n",
        "# image rotation\n",
        "def rotate(x1,x2, degree, row_axis=0, col_axis=1, channel_axis=2, fill_mode='wrap', cval=0.):\n",
        "    theta = np.pi / 180 * degree\n",
        "    rotation_matrix = np.array([[np.cos(theta), -np.sin(theta), 0],\n",
        "    [np.sin(theta), np.cos(theta), 0],\n",
        "    [0, 0, 1]])\n",
        "    h, w = x1.shape[row_axis], x1.shape[col_axis]\n",
        "    transform_matrix = image.transform_matrix_offset_center(rotation_matrix, h, w)\n",
        "    x1 = image.apply_transform(x1, transform_matrix, channel_axis, fill_mode, cval)\n",
        "    x2 = image.apply_transform(x2, transform_matrix, channel_axis, fill_mode, cval)\n",
        "    return x1,x2\n",
        "\n",
        "# image shift\n",
        "def shift(x1,x2, wshift, hshift, row_axis=0, col_axis=1, channel_axis=2, fill_mode='wrap', cval=0.):\n",
        "    h, w = x1.shape[row_axis], x1.shape[col_axis] #读取图片的高和宽\n",
        "    tx = hshift * h #高偏移大小，若不偏移可设为0，若向上偏移设为正数\n",
        "    ty = wshift * w #宽偏移大小，若不偏移可设为0，若向左偏移设为正数\n",
        "    translation_matrix = np.array([[1, 0, tx],\n",
        "                                  [0, 1, ty],\n",
        "                                  [0, 0, 1]])\n",
        "    transform_matrix = translation_matrix  \n",
        "    x1 = image.apply_transform(x1, transform_matrix, channel_axis, fill_mode, cval)\n",
        "    x2 = image.apply_transform(x1, transform_matrix, channel_axis, fill_mode, cval)\n",
        "    return x1,x2\n",
        "\n",
        "#左右或者上下翻转\n",
        "def flip(frame1,frame2,tar):\n",
        "  frame1 = cv2.flip(frame1,tar)\n",
        "  frame2 = cv2.flip(frame2,tar)\n",
        "  return frame1,frame2\n",
        "#水平翻转90°\n",
        "def transpose(frame1,frame2,tar):\n",
        "  if(tar==1):\n",
        "      frame1 = cv2.transpose(frame1)\n",
        "      frame2 = cv2.transpose(frame2)\n",
        "  return frame1,frame2\n",
        "\n",
        "def get_mffs_aug(path1,path2):\n",
        "  frame1 = cv2.imread(path1)\n",
        "  frame1 = cv2.resize(frame1, (299, 299))\n",
        "  prvs = cv2.cvtColor(frame1,cv2.COLOR_BGR2GRAY)\n",
        "  hsv = np.zeros_like(frame1)\n",
        "  hsv[...,1] = 255\n",
        "  frame2 = cv2.imread(path2)\n",
        "  frame2 = cv2.resize(frame2, (299, 299))\n",
        "  #random rotate\n",
        "  deg = random.uniform(-10, 10) #random rotate limit\n",
        "  frame1,frame2 = rotate(frame1,frame2, deg)\n",
        "  #random shift\n",
        "  wshift = random.uniform(-0.1, 0.1)\n",
        "  hshift = random.uniform(-0.1, 0.1)\n",
        "  frame1,frame2 = shift(frame1,frame2, wshift, hshift)\n",
        "  #random flip\n",
        "  foo = [0,-1,1]\n",
        "  tar = choice(foo)\n",
        "  frame1,frame2 = flip(frame1,frame2,tar)\n",
        "  #水平翻转90°\n",
        "  #random transpose\n",
        "  foo = [0,1]\n",
        "  tar = choice(foo)\n",
        "  frame1,frame2 = transpose(frame1,frame2,tar)\n",
        "  next = cv2.cvtColor(frame2,cv2.COLOR_BGR2GRAY)\n",
        "  flow = cv2.calcOpticalFlowFarneback(prvs,next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
        "  mag, ang = cv2.cartToPolar(flow[...,0], flow[...,1])\n",
        "  hsv[...,0] = ang*180/np.pi/2\n",
        "  hsv[...,2] = cv2.normalize(mag,None,0,255,cv2.NORM_MINMAX)\n",
        "  rgb = cv2.cvtColor(hsv,cv2.COLOR_HSV2BGR)\n",
        "  frame1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2RGB)\n",
        "  data = np.zeros((299, 299,5))\n",
        "  data[:, :, 0] = frame1[:, :, 0]\n",
        "  data[:, :, 1] = frame1[:, :, 1]\n",
        "  data[:, :, 2] = frame1[:, :, 2]\n",
        "  data[:, :, 3] = hsv[:, :, 0]\n",
        "  data[:, :, 4] = hsv[:, :, 2]\n",
        "  # normalization\n",
        "  data = np.array(data, dtype=np.float32)  \n",
        "  data /= 127.5\n",
        "  data -= 1.\n",
        "  return data\n",
        "\n",
        "def get_mffs(path1,path2):\n",
        "  frame1 = cv2.imread(path1)\n",
        "  frame1 = cv2.resize(frame1, (299, 299))\n",
        "  prvs = cv2.cvtColor(frame1,cv2.COLOR_BGR2GRAY)\n",
        "  hsv = np.zeros_like(frame1)\n",
        "  hsv[...,1] = 255\n",
        "  frame2 = cv2.imread(path2)\n",
        "  frame2 = cv2.resize(frame2, (299, 299))\n",
        "  next = cv2.cvtColor(frame2,cv2.COLOR_BGR2GRAY)\n",
        "  flow = cv2.calcOpticalFlowFarneback(prvs,next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
        "  mag, ang = cv2.cartToPolar(flow[...,0], flow[...,1])\n",
        "  hsv[...,0] = ang*180/np.pi/2\n",
        "  hsv[...,2] = cv2.normalize(mag,None,0,255,cv2.NORM_MINMAX)\n",
        "  rgb = cv2.cvtColor(hsv,cv2.COLOR_HSV2BGR)\n",
        "  frame1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2RGB)\n",
        "  data = np.zeros((299, 299,5))\n",
        "  data[:, :, 0] = frame1[:, :, 0]\n",
        "  data[:, :, 1] = frame1[:, :, 1]\n",
        "  data[:, :, 2] = frame1[:, :, 2]\n",
        "  data[:, :, 3] = hsv[:, :, 0]\n",
        "  data[:, :, 4] = hsv[:, :, 2]\n",
        "  # normalization\n",
        "  data = np.array(data, dtype=np.float32)  \n",
        "  data /= 127.5\n",
        "  data -= 1.\n",
        "  return data\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vk6Q43cxNnXz",
        "colab_type": "text"
      },
      "source": [
        "###获取光流2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "O2y03D8dNlrG",
        "colab": {}
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import cv2\n",
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "from random import choice\n",
        "# image rotation\n",
        "def rotate(x1,x2, degree, row_axis=0, col_axis=1, channel_axis=2, fill_mode='wrap', cval=0.):\n",
        "    theta = np.pi / 180 * degree\n",
        "    rotation_matrix = np.array([[np.cos(theta), -np.sin(theta), 0],\n",
        "    [np.sin(theta), np.cos(theta), 0],\n",
        "    [0, 0, 1]])\n",
        "    h, w = x1.shape[row_axis], x1.shape[col_axis]\n",
        "    transform_matrix = image.transform_matrix_offset_center(rotation_matrix, h, w)\n",
        "    x1 = image.apply_transform(x1, transform_matrix, channel_axis, fill_mode, cval)\n",
        "    x2 = image.apply_transform(x2, transform_matrix, channel_axis, fill_mode, cval)\n",
        "    return x1,x2\n",
        "\n",
        "# image shift\n",
        "def shift(x1,x2, wshift, hshift, row_axis=0, col_axis=1, channel_axis=2, fill_mode='wrap', cval=0.):\n",
        "    h, w = x1.shape[row_axis], x1.shape[col_axis] #读取图片的高和宽\n",
        "    tx = hshift * h #高偏移大小，若不偏移可设为0，若向上偏移设为正数\n",
        "    ty = wshift * w #宽偏移大小，若不偏移可设为0，若向左偏移设为正数\n",
        "    translation_matrix = np.array([[1, 0, tx],\n",
        "                                  [0, 1, ty],\n",
        "                                  [0, 0, 1]])\n",
        "    transform_matrix = translation_matrix  \n",
        "    x1 = image.apply_transform(x1, transform_matrix, channel_axis, fill_mode, cval)\n",
        "    x2 = image.apply_transform(x1, transform_matrix, channel_axis, fill_mode, cval)\n",
        "    return x1,x2\n",
        "\n",
        "#左右或者上下翻转\n",
        "def flip(frame1,frame2,tar):\n",
        "  frame1 = cv2.flip(frame1,tar)\n",
        "  frame2 = cv2.flip(frame2,tar)\n",
        "  return frame1,frame2\n",
        "#水平翻转90°\n",
        "def transpose(frame1,frame2,tar):\n",
        "  if(tar==1):\n",
        "      frame1 = cv2.transpose(frame1)\n",
        "      frame2 = cv2.transpose(frame2)\n",
        "  return frame1,frame2\n",
        "\n",
        "def get_mffs_aug(path1,path2):\n",
        "  frame1 = cv2.imread(path1)\n",
        "  frame1 = cv2.resize(frame1, (299, 299))\n",
        "  prvs = cv2.cvtColor(frame1,cv2.COLOR_BGR2GRAY)\n",
        "  hsv = np.zeros_like(frame1)\n",
        "  hsv[...,1] = 255\n",
        "  frame2 = cv2.imread(path2)\n",
        "  frame2 = cv2.resize(frame2, (299, 299))\n",
        "  #random rotate\n",
        "  deg = random.uniform(-10, 10) #random rotate limit\n",
        "  frame1,frame2 = rotate(frame1,frame2, deg)\n",
        "  #random shift\n",
        "  wshift = random.uniform(-0.1, 0.1)\n",
        "  hshift = random.uniform(-0.1, 0.1)\n",
        "  frame1,frame2 = shift(frame1,frame2, wshift, hshift)\n",
        "  #random flip\n",
        "  foo = [0,-1,1]\n",
        "  tar = choice(foo)\n",
        "  frame1,frame2 = flip(frame1,frame2,tar)\n",
        "  #水平翻转90°\n",
        "  #random transpose\n",
        "  foo = [0,1]\n",
        "  tar = choice(foo)\n",
        "  frame1,frame2 = transpose(frame1,frame2,tar)\n",
        "  next = cv2.cvtColor(frame2,cv2.COLOR_BGR2GRAY)\n",
        "  flow = cv2.calcOpticalFlowFarneback(prvs,next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
        "  # mag, ang = cv2.cartToPolar(flow[...,0], flow[...,1])\n",
        "  # hsv[...,0] = ang*180/np.pi/2\n",
        "  # hsv[...,2] = cv2.normalize(mag,None,0,255,cv2.NORM_MINMAX)\n",
        "  hsv[...,0] = cv2.normalize(flow[...,0],None,0,255,cv2.NORM_MINMAX)\n",
        "  hsv[...,2] = cv2.normalize(flow[...,1],None,0,255,cv2.NORM_MINMAX)\n",
        "  # rgb = cv2.cvtColor(hsv,cv2.COLOR_HSV2BGR)\n",
        "  frame1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2RGB)\n",
        "  data = np.zeros((299, 299,5))\n",
        "  data[:, :, 0] = frame1[:, :, 0]\n",
        "  data[:, :, 1] = frame1[:, :, 1]\n",
        "  data[:, :, 2] = frame1[:, :, 2]\n",
        "  data[:, :, 3] = hsv[:, :, 0]\n",
        "  data[:, :, 4] = hsv[:, :, 2]\n",
        "  # normalization\n",
        "  data = np.array(data, dtype=np.float32)  \n",
        "  data /= 127.5\n",
        "  data -= 1.\n",
        "  return data\n",
        "\n",
        "def get_mffs(path1,path2):\n",
        "  frame1 = cv2.imread(path1)\n",
        "  frame1 = cv2.resize(frame1, (299, 299))\n",
        "  prvs = cv2.cvtColor(frame1,cv2.COLOR_BGR2GRAY)\n",
        "  hsv = np.zeros_like(frame1)\n",
        "  hsv[...,1] = 255\n",
        "  frame2 = cv2.imread(path2)\n",
        "  frame2 = cv2.resize(frame2, (299, 299))\n",
        "  next = cv2.cvtColor(frame2,cv2.COLOR_BGR2GRAY)\n",
        "  flow = cv2.calcOpticalFlowFarneback(prvs,next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
        "  # mag, ang = cv2.cartToPolar(flow[...,0], flow[...,1])\n",
        "  # hsv[...,0] = ang*180/np.pi/2\n",
        "  # hsv[...,2] = cv2.normalize(mag,None,0,255,cv2.NORM_MINMAX)\n",
        "  hsv[...,0] = cv2.normalize(flow[...,0],None,0,255,cv2.NORM_MINMAX)\n",
        "  hsv[...,2] = cv2.normalize(flow[...,1],None,0,255,cv2.NORM_MINMAX)\n",
        "  # rgb = cv2.cvtColor(hsv,cv2.COLOR_HSV2BGR)\n",
        "  frame1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2RGB)\n",
        "  data = np.zeros((299, 299,5))\n",
        "  data[:, :, 0] = frame1[:, :, 0]\n",
        "  data[:, :, 1] = frame1[:, :, 1]\n",
        "  data[:, :, 2] = frame1[:, :, 2]\n",
        "  data[:, :, 3] = hsv[:, :, 0]\n",
        "  data[:, :, 4] = hsv[:, :, 2]\n",
        "  # normalization\n",
        "  data = np.array(data, dtype=np.float32)  \n",
        "  data /= 127.5\n",
        "  data -= 1.\n",
        "  return data\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3DahZUHBNeI",
        "colab_type": "text"
      },
      "source": [
        "### 训练图片生成器\n",
        "\n",
        "从训练列表中遍历。yield一个batch的训练图片及其标签。图片经过了实时增强。另外还有50%的概率随机选取另一张同类里的图片，将两张的左右各半边拼接在一起。这也是为了训练模型对分类的关键部位进行学习，而不是记住司机的样子"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbJeF3pDBNeJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define my train data generator\n",
        "\n",
        "def train_gen(batch_size):\n",
        "    #random.shuffle(train_list) # 每一代都随机shuffle训练集\n",
        "    current = 0\n",
        "    while 1:\n",
        "        x = []\n",
        "        y = []\n",
        "        while len(y) < batch_size:\n",
        "            line = train_list[current]\n",
        "            arr = line.strip().split(',')\n",
        "            path1 = os.path.join('.', 'train', str(arr[1]), str(arr[2]))\n",
        "            path3 = os.path.join('.', 'train', str(arr[4]), str(arr[5]))\n",
        "            # img = get_im_cv2_aug(path1, 299)\n",
        "            # img3 = get_im_cv2_aug(path3, 299)\n",
        "            mffs = get_mffs_aug(path1,path3)\n",
        "            # if random.random()>0.5:\n",
        "            #     line2 = random.choice(class_dict[arr[1]])\n",
        "            #     bname = line2.strip().split(',')[2]\n",
        "            #     path2 = os.path.join('.', 'train', str(arr[1]), str(bname))\n",
        "            #     img2 = get_im_cv2_aug(path2, 299)\n",
        "            #     left = img[:, :150, :]\n",
        "            #     right = img2[:, 150:, :]\n",
        "            #     img = np.concatenate((left, right), axis=1)\n",
        "            x.append(mffs)\n",
        "            label = one_hot_encode([str(arr[1])])[0]\n",
        "            y.append(label)\n",
        "            current += 1\n",
        "            if current >= len(train_list):\n",
        "                current = 0\n",
        "        x = np.array(x)\n",
        "        img_size = 299\n",
        "        x = x.reshape(batch_size, img_size, img_size, 5) \n",
        "        y = np.array(y, dtype = np.uint8)\n",
        "        y = y.reshape(batch_size, 10)\n",
        "        yield (x, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOcMcHHUBNeN",
        "colab_type": "text"
      },
      "source": [
        "### 验证图片生成器\n",
        "\n",
        "从验证列表中遍历。yield一个batch的验证图片及其标签。为了体现模型训练后的拟合能力，图片没有进行实时增强。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tp4U8pKTBNeO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define my validation data generator\n",
        "\n",
        "def valid_gen(batch_size):\n",
        "    current = 0\n",
        "    while 1:\n",
        "        x = []\n",
        "        y = []\n",
        "        while len(y) < batch_size:\n",
        "            line = valid_list[current]\n",
        "            arr = line.strip().split(',')\n",
        "            path1 = os.path.join('.', 'train', str(arr[1]), str(arr[2]))\n",
        "            path3 = os.path.join('.', 'train', str(arr[4]), str(arr[5]))\n",
        "            #print (path)\n",
        "            mffs = get_mffs(path1,path3)\n",
        "            x.append(mffs)\n",
        "            label = one_hot_encode([str(arr[1])])[0]\n",
        "            y.append(label)\n",
        "            current += 1\n",
        "            if current >= len(valid_list):\n",
        "                current = 0\n",
        "        x = np.array(x)\n",
        "        img_size = 299\n",
        "        x = x.reshape(batch_size, img_size, img_size, 5) \n",
        "        y = np.array(y, dtype = np.uint8)\n",
        "        y = y.reshape(batch_size, 10)\n",
        "        yield (x, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MClUdfVnGvPz",
        "colab_type": "text"
      },
      "source": [
        "###验证数据类型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5x8HDZLIL2oT",
        "colab_type": "code",
        "outputId": "fb03d77a-95d8-41ec-9690-ff3d3143c27b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "current = 0\n",
        "path = []\n",
        "num_frames=16\n",
        "print(train_list[0])\n",
        "line=train_list[current]\n",
        "arr=line.strip().split(',')\n",
        "path1=os.path.join('.', 'train', str(arr[1]), str(arr[2]))\n",
        "print(path1)\n",
        "path2=os.path.join('.', 'train', str(arr[4]), str(arr[5]))\n",
        "\n",
        "mffs_aug = get_mffs_aug(path1,path2)\n",
        "mffs = get_mffs(path1,path2)\n",
        "print(mffs_aug.shape)\n",
        "print(mffs.shape)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "p061,c5,img_80030.jpg,p061,c5,img_5941.jpg\n",
            "\n",
            "./train/c5/img_80030.jpg\n",
            "(299, 299, 5)\n",
            "(299, 299, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZO3cku2BNeR",
        "colab_type": "text"
      },
      "source": [
        "### 构建模型\n",
        "\n",
        "用keras构建模型。使用在ImageNet上预训练好的Xception模型，接上一个global average pooling层，dropout防止过拟合，最后一个全连接层输出10个类别的概率。在全连接层的权重上采用了L2正则化。锁定模型的前70层不更新权重."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Odj6vyytBNeS",
        "colab_type": "code",
        "outputId": "afe7c577-94eb-41f8-ec82-234a72f688eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "from keras import backend as K\n",
        "K.clear_session()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:88: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:91: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:95: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IalNVLcnBNeX",
        "colab_type": "code",
        "outputId": "a2f8d777-c52a-495d-d64f-d056ee063a70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 835
        }
      },
      "source": [
        "# new model\n",
        "\n",
        "from keras.models import *\n",
        "from keras.layers import *\n",
        "from keras.applications import *\n",
        "from keras.preprocessing.image import *\n",
        "\n",
        "# img_size = 297\n",
        "# x = Input((img_size, img_size, 3))\n",
        "# base_model1 = Xception(input_tensor = x, weights='imagenet', include_top=False)\n",
        "# base_model2 = Model(x,base_model1.output)\n",
        "y = Input((299, 299, 5))\n",
        "# y = Conv2D(3,(3,3), strides=(1, 1))(y)\n",
        "# y = BatchNormalization()(y)\n",
        "# m = Activation('relu')(y)\n",
        "base_model = Xception(input_tensor = y, weights='imagenet', include_top=False)\n",
        "m = GlobalAveragePooling2D()(base_model.output)\n",
        "m = Dropout(0.5)(m)\n",
        "m = Dense(10, activation='softmax', kernel_regularizer=regularizers.l2(0.01))(m)\n",
        "model = Model(base_model.input,m)\n",
        "# for i in range(70):\n",
        "#     model.layers[i].trainable = False\n",
        "model.summary()\n",
        "len(model.layers)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:507: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3831: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:167: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:179: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:183: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:192: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:199: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1797: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3655: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.4/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "83689472/83683744 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1606\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1607\u001b[0;31m     \u001b[0mc_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1608\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Dimension 0 in both shapes must be equal, but are 3 and 32. Shapes are [3,3,5,32] and [32,3,3,3]. for 'Assign' (op: 'Assign') with input shapes: [3,3,5,32], [32,3,3,3].",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-cfa5dd1e60f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# y = BatchNormalization()(y)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# m = Activation('relu')(y)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mbase_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'imagenet'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_top\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGlobalAveragePooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/applications/xception.py\u001b[0m in \u001b[0;36mXception\u001b[0;34m(include_top, weights, input_tensor, input_shape, pooling, classes)\u001b[0m\n\u001b[1;32m    261\u001b[0m                                     \u001b[0mcache_subdir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'models'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m                                     file_hash='b0042744bf5b25fce3cb969f33bebb97')\n\u001b[0;32m--> 263\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch, reshape)\u001b[0m\n\u001b[1;32m   2654\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2655\u001b[0m                 load_weights_from_hdf5_group(\n\u001b[0;32m-> 2656\u001b[0;31m                     f, self.layers, reshape=reshape)\n\u001b[0m\u001b[1;32m   2657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2658\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_updated_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group\u001b[0;34m(f, layers, reshape)\u001b[0m\n\u001b[1;32m   3380\u001b[0m                              ' elements.')\n\u001b[1;32m   3381\u001b[0m         \u001b[0mweight_value_tuples\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbolic_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3382\u001b[0;31m     \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_value_tuples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mbatch_set_value\u001b[0;34m(tuples)\u001b[0m\n\u001b[1;32m   2366\u001b[0m                 assign_placeholder = tf.placeholder(tf_dtype,\n\u001b[1;32m   2367\u001b[0m                                                     shape=value.shape)\n\u001b[0;32m-> 2368\u001b[0;31m                 \u001b[0massign_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_placeholder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2369\u001b[0m                 \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assign_placeholder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0massign_placeholder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2370\u001b[0m                 \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assign_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0massign_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/variables.py\u001b[0m in \u001b[0;36massign\u001b[0;34m(self, value, use_locking, name, read_value)\u001b[0m\n\u001b[1;32m   2065\u001b[0m     \"\"\"\n\u001b[1;32m   2066\u001b[0m     assign = state_ops.assign(\n\u001b[0;32m-> 2067\u001b[0;31m         self._variable, value, use_locking=use_locking, name=name)\n\u001b[0m\u001b[1;32m   2068\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mread_value\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2069\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0massign\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/state_ops.py\u001b[0m in \u001b[0;36massign\u001b[0;34m(ref, value, validate_shape, use_locking, name)\u001b[0m\n\u001b[1;32m    225\u001b[0m     return gen_state_ops.assign(\n\u001b[1;32m    226\u001b[0m         \u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_locking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_locking\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m         validate_shape=validate_shape)\n\u001b[0m\u001b[1;32m    228\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_state_ops.py\u001b[0m in \u001b[0;36massign\u001b[0;34m(ref, value, validate_shape, use_locking, name)\u001b[0m\n\u001b[1;32m     64\u001b[0m   _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[1;32m     65\u001b[0m         \u001b[0;34m\"Assign\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                   use_locking=use_locking, name=name)\n\u001b[0m\u001b[1;32m     67\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m   \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    792\u001b[0m         op = g.create_op(op_type_name, inputs, dtypes=None, name=scope,\n\u001b[1;32m    793\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 794\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    795\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m       \u001b[0;31m# Conditionally invoke tfdbg v2's op callback(s).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m                 instructions)\n\u001b[0;32m--> 507\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m     doc = _add_deprecated_arg_notice_to_docstring(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3355\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Input #%d is not a tensor: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3356\u001b[0m     return self._create_op_internal(op_type, inputs, dtypes, input_types, name,\n\u001b[0;32m-> 3357\u001b[0;31m                                     attrs, op_def, compute_device)\n\u001b[0m\u001b[1;32m   3358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3359\u001b[0m   def _create_op_internal(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   3424\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3425\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3426\u001b[0;31m           op_def=op_def)\n\u001b[0m\u001b[1;32m   3427\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3428\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   1768\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[1;32m   1769\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[0;32m-> 1770\u001b[0;31m                                 control_input_ops)\n\u001b[0m\u001b[1;32m   1771\u001b[0m     \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1608\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1609\u001b[0m     \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1610\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1612\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Dimension 0 in both shapes must be equal, but are 3 and 32. Shapes are [3,3,5,32] and [32,3,3,3]. for 'Assign' (op: 'Assign') with input shapes: [3,3,5,32], [32,3,3,3]."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kmgpn5uLeBxg",
        "colab_type": "text"
      },
      "source": [
        "###构建视频预测模型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KG4ZSc50q21B",
        "colab_type": "code",
        "outputId": "221f586c-b7d0-4437-d1ad-9520e31d92a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.models import Model\n",
        "from keras import layers\n",
        "from keras.layers import Dense, Input, BatchNormalization, Activation\n",
        "from keras.layers import Conv2D, SeparableConv2D, MaxPooling2D, GlobalAveragePooling2D, GlobalMaxPooling2D, Dropout\n",
        "from keras.applications.imagenet_utils import _obtain_input_shape\n",
        "from keras.utils.data_utils import get_file\n",
        "\n",
        "# from keras.models import *\n",
        "# from keras.layers import *\n",
        "# from keras.applications import *\n",
        "# from keras.preprocessing.image import *\n",
        "from keras import regularizers\n",
        "\n",
        "WEIGHTS_PATH = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.4/xception_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "\n",
        "def Xception():\n",
        "\n",
        "\t# Determine proper input shape\n",
        "\t# input_shape = _obtain_input_shape(None, default_size=299, min_size=71, data_format='channels_last', include_top=False)\n",
        "  img_size =299\n",
        "  img_input = Input((img_size, img_size, 5))\n",
        "\t# img_input = Input(shape=input_shape)\n",
        "  # x = Conv2D(3,(3,3), strides=(1, 1))(img_input)\n",
        "  # x = BatchNormalization()(x)\n",
        "  # x = Activation('relu')(x)\n",
        "\t# Block 1\n",
        "  x = Conv2D(32, (3, 3), strides=(2, 2), use_bias=False)(img_input)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation('relu')(x)\n",
        "  x = Conv2D(64, (3, 3), use_bias=False)(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation('relu')(x)\n",
        "\n",
        "  residual = Conv2D(128, (1, 1), strides=(2, 2), padding='same', use_bias=False)(x)\n",
        "  residual = BatchNormalization()(residual)\n",
        "\n",
        "  # Block 2\n",
        "  x = SeparableConv2D(128, (3, 3), padding='same', use_bias=False)(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation('relu')(x)\n",
        "  x = SeparableConv2D(128, (3, 3), padding='same', use_bias=False)(x)\n",
        "  x = BatchNormalization()(x)\n",
        "\n",
        "\t# Block 2 Pool\n",
        "  x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
        "  x = layers.add([x, residual])\n",
        "\n",
        "  residual = Conv2D(256, (1, 1), strides=(2, 2), padding='same', use_bias=False)(x)\n",
        "  residual = BatchNormalization()(residual)\n",
        "\n",
        "\t# Block 3\n",
        "  x = Activation('relu')(x)\n",
        "  x = SeparableConv2D(256, (3, 3), padding='same', use_bias=False)(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation('relu')(x)\n",
        "  x = SeparableConv2D(256, (3, 3), padding='same', use_bias=False)(x)\n",
        "  x = BatchNormalization()(x)\n",
        "\n",
        "\t# Block 3 Pool\n",
        "  x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
        "  x = layers.add([x, residual])\n",
        "\n",
        "  residual = Conv2D(728, (1, 1), strides=(2, 2), padding='same', use_bias=False)(x)\n",
        "  residual = BatchNormalization()(residual)\n",
        "\n",
        "\t# Block 4\n",
        "  x = Activation('relu')(x)\n",
        "  x = SeparableConv2D(728, (3, 3), padding='same', use_bias=False)(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation('relu')(x)\n",
        "  x = SeparableConv2D(728, (3, 3), padding='same', use_bias=False)(x)\n",
        "  x = BatchNormalization()(x)\n",
        "\n",
        "  x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
        "  x = layers.add([x, residual])\n",
        "\n",
        "\t# Block 5 - 12\n",
        "  for i in range(8):\n",
        "    residual = x\n",
        "\n",
        "    x = Activation('relu')(x)\n",
        "    x = SeparableConv2D(728, (3, 3), padding='same', use_bias=False)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = SeparableConv2D(728, (3, 3), padding='same', use_bias=False)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = SeparableConv2D(728, (3, 3), padding='same', use_bias=False)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    x = layers.add([x, residual])\n",
        "\n",
        "  residual = Conv2D(1024, (1, 1), strides=(2, 2), padding='same', use_bias=False)(x)\n",
        "  residual = BatchNormalization()(residual)\n",
        "\n",
        "\t# Block 13\n",
        "  x = Activation('relu')(x)\n",
        "  x = SeparableConv2D(728, (3, 3), padding='same', use_bias=False)(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation('relu')(x)\n",
        "  x = SeparableConv2D(1024, (3, 3), padding='same', use_bias=False)(x)\n",
        "  x = BatchNormalization()(x)\n",
        "\n",
        "\t# Block 13 Pool\n",
        "  x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
        "  x = layers.add([x, residual])\n",
        "\n",
        "  # Block 14\n",
        "  x = SeparableConv2D(1536, (3, 3), padding='same', use_bias=False)(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation('relu')(x)\n",
        "\n",
        "\t# Block 14 part 2\n",
        "  x = SeparableConv2D(2048, (3, 3), padding='same', use_bias=False)(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation('relu')(x)\n",
        "\n",
        "\t# Fully Connected Layer\n",
        "  # x = GlobalAveragePooling2D()(x)\n",
        "  # x = Dense(1000, activation='softmax')(x)\n",
        "  x = GlobalAveragePooling2D()(x)\n",
        "  x = Dropout(0.5)(x)\n",
        "  x = Dense(10, activation='softmax', kernel_regularizer=regularizers.l2(0.01))(x)\n",
        "  inputs = img_input\n",
        "\n",
        "\t# Create model\n",
        "  model = Model(inputs, x, name='xception')\n",
        "\n",
        "  # Download and cache the Xception weights file\n",
        "  weights_path = get_file('xception_weights.h5', WEIGHTS_PATH, cache_subdir='models')\n",
        "\n",
        "\t# load weights\n",
        "  # model.load_weights(weights_path, by_name=True)\n",
        "  # model.load_weights('my_model12.h5', by_name=True)\n",
        "  model.load_weights('mffs_model_nolock.h5')\n",
        "  return model\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\tInstantiate the model by using the following line of code\n",
        "\tmodel = Xception()\n",
        "\"\"\"\n",
        "video_model = Xception()\n",
        "# for i in range(42):\n",
        "#     video_model.layers[i].trainable = False\n",
        "video_model.summary()\n",
        "len(video_model.layers)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:507: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3831: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:167: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:179: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:183: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:192: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:199: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1797: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3655: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3138: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.4/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "83689472/83683744 [==============================] - 2s 0us/step\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 299, 299, 5)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 149, 149, 32) 1440        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 149, 149, 32) 128         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 149, 149, 32) 0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 147, 147, 64) 18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 147, 147, 64) 256         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 147, 147, 64) 0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_1 (SeparableCo (None, 147, 147, 128 8768        activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 147, 147, 128 512         separable_conv2d_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 147, 147, 128 0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_2 (SeparableCo (None, 147, 147, 128 17536       activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 147, 147, 128 512         separable_conv2d_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 74, 74, 128)  8192        activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 74, 74, 128)  0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 74, 74, 128)  512         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 74, 74, 128)  0           max_pooling2d_1[0][0]            \n",
            "                                                                 batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 74, 74, 128)  0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_3 (SeparableCo (None, 74, 74, 256)  33920       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 74, 74, 256)  1024        separable_conv2d_3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 74, 74, 256)  0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_4 (SeparableCo (None, 74, 74, 256)  67840       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 74, 74, 256)  1024        separable_conv2d_4[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 37, 37, 256)  32768       add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 37, 37, 256)  0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 37, 37, 256)  1024        conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 37, 37, 256)  0           max_pooling2d_2[0][0]            \n",
            "                                                                 batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 37, 37, 256)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_5 (SeparableCo (None, 37, 37, 728)  188672      activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 37, 37, 728)  2912        separable_conv2d_5[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 37, 37, 728)  0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_6 (SeparableCo (None, 37, 37, 728)  536536      activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 37, 37, 728)  2912        separable_conv2d_6[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 19, 19, 728)  186368      add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 19, 19, 728)  0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 19, 19, 728)  2912        conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 19, 19, 728)  0           max_pooling2d_3[0][0]            \n",
            "                                                                 batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 19, 19, 728)  0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_7 (SeparableCo (None, 19, 19, 728)  536536      activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_7[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 19, 19, 728)  0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_8 (SeparableCo (None, 19, 19, 728)  536536      activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_8[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 19, 19, 728)  0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_9 (SeparableCo (None, 19, 19, 728)  536536      activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_9[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 19, 19, 728)  0           batch_normalization_14[0][0]     \n",
            "                                                                 add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 19, 19, 728)  0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_10 (SeparableC (None, 19, 19, 728)  536536      activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_10[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 19, 19, 728)  0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_11 (SeparableC (None, 19, 19, 728)  536536      activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_11[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 19, 19, 728)  0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_12 (SeparableC (None, 19, 19, 728)  536536      activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_12[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 19, 19, 728)  0           batch_normalization_17[0][0]     \n",
            "                                                                 add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 19, 19, 728)  0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_13 (SeparableC (None, 19, 19, 728)  536536      activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_13[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 19, 19, 728)  0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_14 (SeparableC (None, 19, 19, 728)  536536      activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_14[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 19, 19, 728)  0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_15 (SeparableC (None, 19, 19, 728)  536536      activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_15[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 19, 19, 728)  0           batch_normalization_20[0][0]     \n",
            "                                                                 add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 19, 19, 728)  0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_16 (SeparableC (None, 19, 19, 728)  536536      activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_16[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 19, 19, 728)  0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_17 (SeparableC (None, 19, 19, 728)  536536      activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_17[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 19, 19, 728)  0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_18 (SeparableC (None, 19, 19, 728)  536536      activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_18[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 19, 19, 728)  0           batch_normalization_23[0][0]     \n",
            "                                                                 add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 19, 19, 728)  0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_19 (SeparableC (None, 19, 19, 728)  536536      activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_19[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 19, 19, 728)  0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_20 (SeparableC (None, 19, 19, 728)  536536      activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_20[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 19, 19, 728)  0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_21 (SeparableC (None, 19, 19, 728)  536536      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_21[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 19, 19, 728)  0           batch_normalization_26[0][0]     \n",
            "                                                                 add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 19, 19, 728)  0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_22 (SeparableC (None, 19, 19, 728)  536536      activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_22[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 19, 19, 728)  0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_23 (SeparableC (None, 19, 19, 728)  536536      activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_23[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 19, 19, 728)  0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_24 (SeparableC (None, 19, 19, 728)  536536      activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_24[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 19, 19, 728)  0           batch_normalization_29[0][0]     \n",
            "                                                                 add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 19, 19, 728)  0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_25 (SeparableC (None, 19, 19, 728)  536536      activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_25[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 19, 19, 728)  0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_26 (SeparableC (None, 19, 19, 728)  536536      activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_26[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 19, 19, 728)  0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_27 (SeparableC (None, 19, 19, 728)  536536      activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_27[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 19, 19, 728)  0           batch_normalization_32[0][0]     \n",
            "                                                                 add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 19, 19, 728)  0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_28 (SeparableC (None, 19, 19, 728)  536536      activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_28[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 19, 19, 728)  0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_29 (SeparableC (None, 19, 19, 728)  536536      activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_29[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 19, 19, 728)  0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_30 (SeparableC (None, 19, 19, 728)  536536      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_30[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 19, 19, 728)  0           batch_normalization_35[0][0]     \n",
            "                                                                 add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 19, 19, 728)  0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_31 (SeparableC (None, 19, 19, 728)  536536      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_31[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 19, 19, 728)  0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_32 (SeparableC (None, 19, 19, 1024) 752024      activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 19, 19, 1024) 4096        separable_conv2d_32[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 10, 10, 1024) 745472      add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 10, 10, 1024) 0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 10, 10, 1024) 4096        conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 10, 10, 1024) 0           max_pooling2d_4[0][0]            \n",
            "                                                                 batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_33 (SeparableC (None, 10, 10, 1536) 1582080     add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 10, 10, 1536) 6144        separable_conv2d_33[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 10, 10, 1536) 0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_34 (SeparableC (None, 10, 10, 2048) 3159552     activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 10, 10, 2048) 8192        separable_conv2d_34[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 10, 10, 2048) 0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_1 (Glo (None, 2048)         0           activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 2048)         0           global_average_pooling2d_1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           20490       dropout_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 20,882,546\n",
            "Trainable params: 20,828,018\n",
            "Non-trainable params: 54,528\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "135"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8eAFtLKcr4FO",
        "colab_type": "text"
      },
      "source": [
        "#构建视频预测模型2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "9949ff34-e2ab-41e4-f52e-f8b016bd7f7b",
        "id": "o4YTSf5zr9xn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.models import Model\n",
        "from keras import layers\n",
        "from keras.layers import Dense, Input, BatchNormalization, Activation\n",
        "from keras.layers import Conv2D, SeparableConv2D, MaxPooling2D, GlobalAveragePooling2D, GlobalMaxPooling2D, Dropout\n",
        "from keras.applications.imagenet_utils import _obtain_input_shape\n",
        "from keras.utils.data_utils import get_file\n",
        "\n",
        "# from keras.models import *\n",
        "# from keras.layers import *\n",
        "# from keras.applications import *\n",
        "# from keras.preprocessing.image import *\n",
        "from keras import regularizers\n",
        "\n",
        "WEIGHTS_PATH = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.4/xception_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "\n",
        "def Xception():\n",
        "\n",
        "\t# Determine proper input shape\n",
        "\t# input_shape = _obtain_input_shape(None, default_size=299, min_size=71, data_format='channels_last', include_top=False)\n",
        "  img_size =299\n",
        "  img_input = Input((img_size, img_size, 5))\n",
        "\t# img_input = Input(shape=input_shape)\n",
        "  # x = Conv2D(3,(3,3), strides=(1, 1))(img_input)\n",
        "  # x = BatchNormalization()(x)\n",
        "  # x = Activation('relu')(x)\n",
        "\t# Block 1\n",
        "  x = Conv2D(32, (3, 3), strides=(2, 2), use_bias=False, kernel_regularizer=regularizers.l2(0.01))(img_input)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation('relu')(x)\n",
        "  x = Conv2D(64, (3, 3), use_bias=False, kernel_regularizer=regularizers.l2(0.01))(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation('relu')(x)\n",
        "\n",
        "  residual = Conv2D(128, (1, 1), strides=(2, 2), padding='same', use_bias=False, kernel_regularizer=regularizers.l2(0.01))(x)\n",
        "  residual = BatchNormalization()(residual)\n",
        "\n",
        "  # Block 2\n",
        "  x = SeparableConv2D(128, (3, 3), padding='same', use_bias=False, kernel_regularizer=regularizers.l2(0.01))(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation('relu')(x)\n",
        "  x = SeparableConv2D(128, (3, 3), padding='same', use_bias=False, kernel_regularizer=regularizers.l2(0.01))(x)\n",
        "  x = BatchNormalization()(x)\n",
        "\n",
        "\t# Block 2 Pool\n",
        "  x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
        "  x = Dropout(0.7)(x)\n",
        "  x = layers.add([x, residual])\n",
        "\n",
        "  residual = Conv2D(256, (1, 1), strides=(2, 2), padding='same', use_bias=False, kernel_regularizer=regularizers.l2(0.01))(x)\n",
        "  residual = BatchNormalization()(residual)\n",
        "\n",
        "\t# Block 3\n",
        "  x = Activation('relu')(x)\n",
        "  x = SeparableConv2D(256, (3, 3), padding='same', use_bias=False, kernel_regularizer=regularizers.l2(0.01))(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation('relu')(x)\n",
        "  x = SeparableConv2D(256, (3, 3), padding='same', use_bias=False, kernel_regularizer=regularizers.l2(0.01))(x)\n",
        "  x = BatchNormalization()(x)\n",
        "\n",
        "\t# Block 3 Pool\n",
        "  x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
        "  x = Dropout(0.7)(x)\n",
        "  x = layers.add([x, residual])\n",
        "\n",
        "  residual = Conv2D(728, (1, 1), strides=(2, 2), padding='same', use_bias=False, kernel_regularizer=regularizers.l2(0.01))(x)\n",
        "  residual = BatchNormalization()(residual)\n",
        "\n",
        "\t# Block 4\n",
        "  x = Activation('relu')(x)\n",
        "  x = SeparableConv2D(728, (3, 3), padding='same', use_bias=False, kernel_regularizer=regularizers.l2(0.01))(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation('relu')(x)\n",
        "  x = SeparableConv2D(728, (3, 3), padding='same', use_bias=False, kernel_regularizer=regularizers.l2(0.01))(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
        "  x = Dropout(0.7)(x)\n",
        "  x = layers.add([x, residual])\n",
        "\n",
        "\t# Block 5 - 12\n",
        "  for i in range(8):\n",
        "    residual = x\n",
        "\n",
        "    x = Activation('relu')(x)\n",
        "    x = SeparableConv2D(728, (3, 3), padding='same', use_bias=False, kernel_regularizer=regularizers.l2(0.01))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = SeparableConv2D(728, (3, 3), padding='same', use_bias=False, kernel_regularizer=regularizers.l2(0.01))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = SeparableConv2D(728, (3, 3), padding='same', use_bias=False, kernel_regularizer=regularizers.l2(0.01))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = layers.add([x, residual])\n",
        "\n",
        "  residual = Conv2D(1024, (1, 1), strides=(2, 2), padding='same', use_bias=False, kernel_regularizer=regularizers.l2(0.01))(x)\n",
        "  residual = BatchNormalization()(residual)\n",
        "\n",
        "\t# Block 13\n",
        "  x = Activation('relu')(x)\n",
        "  x = SeparableConv2D(728, (3, 3), padding='same', use_bias=False, kernel_regularizer=regularizers.l2(0.01))(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation('relu')(x)\n",
        "  x = SeparableConv2D(1024, (3, 3), padding='same', use_bias=False, kernel_regularizer=regularizers.l2(0.01))(x)\n",
        "  x = BatchNormalization()(x)\n",
        "\n",
        "\t# Block 13 Pool\n",
        "  x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
        "  x = Dropout(0.7)(x)\n",
        "  x = layers.add([x, residual])\n",
        "\n",
        "  # Block 14\n",
        "  x = SeparableConv2D(1536, (3, 3), padding='same', use_bias=False, kernel_regularizer=regularizers.l2(0.01))(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation('relu')(x)\n",
        "\n",
        "\t# Block 14 part 2\n",
        "  x = SeparableConv2D(2048, (3, 3), padding='same', use_bias=False, kernel_regularizer=regularizers.l2(0.01))(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation('relu')(x)\n",
        "\n",
        "\t# Fully Connected Layer\n",
        "  # x = GlobalAveragePooling2D()(x)\n",
        "  # x = Dense(1000, activation='softmax')(x)\n",
        "  x = GlobalAveragePooling2D()(x)\n",
        "  x = Dropout(0.7)(x)\n",
        "  x = Dense(10, activation='softmax', kernel_regularizer=regularizers.l2(0.01))(x)\n",
        "  inputs = img_input\n",
        "\n",
        "\t# Create model\n",
        "  model = Model(inputs, x, name='xception')\n",
        "\n",
        "  # Download and cache the Xception weights file\n",
        "  # weights_path = get_file('xception_weights.h5', WEIGHTS_PATH, cache_subdir='models')\n",
        "\n",
        "\t# load weights\n",
        "  # model.load_weights(weights_path, by_name=True)\n",
        "  # model.load_weights('my_model12.h5', by_name=True)\n",
        "  model.load_weights('mffs_model_nolock_dropout_more_nostopping.h5')\n",
        "  return model\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\tInstantiate the model by using the following line of code\n",
        "\tmodel = Xception()\n",
        "\"\"\"\n",
        "video_model = Xception()\n",
        "# for i in range(42):\n",
        "#     video_model.layers[i].trainable = False\n",
        "video_model.summary()\n",
        "len(video_model.layers)\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            (None, 299, 299, 5)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 149, 149, 32) 1440        input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 149, 149, 32) 128         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 149, 149, 32) 0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 147, 147, 64) 18432       activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 147, 147, 64) 256         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 147, 147, 64) 0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_35 (SeparableC (None, 147, 147, 128 8768        activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 147, 147, 128 512         separable_conv2d_35[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 147, 147, 128 0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_36 (SeparableC (None, 147, 147, 128 17536       activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 147, 147, 128 512         separable_conv2d_36[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2D)  (None, 74, 74, 128)  0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 74, 74, 128)  8192        activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 74, 74, 128)  0           max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 74, 74, 128)  512         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 74, 74, 128)  0           dropout_6[0][0]                  \n",
            "                                                                 batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 74, 74, 128)  0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_37 (SeparableC (None, 74, 74, 256)  33920       activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 74, 74, 256)  1024        separable_conv2d_37[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 74, 74, 256)  0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_38 (SeparableC (None, 74, 74, 256)  67840       activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 74, 74, 256)  1024        separable_conv2d_38[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2D)  (None, 37, 37, 256)  0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 37, 37, 256)  32768       add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 37, 37, 256)  0           max_pooling2d_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 37, 37, 256)  1024        conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 37, 37, 256)  0           dropout_7[0][0]                  \n",
            "                                                                 batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 37, 37, 256)  0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_39 (SeparableC (None, 37, 37, 728)  188672      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 37, 37, 728)  2912        separable_conv2d_39[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 37, 37, 728)  0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_40 (SeparableC (None, 37, 37, 728)  536536      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 37, 37, 728)  2912        separable_conv2d_40[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2D)  (None, 19, 19, 728)  0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 19, 19, 728)  186368      add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_8 (Dropout)             (None, 19, 19, 728)  0           max_pooling2d_7[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 19, 19, 728)  2912        conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 19, 19, 728)  0           dropout_8[0][0]                  \n",
            "                                                                 batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 19, 19, 728)  0           add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_41 (SeparableC (None, 19, 19, 728)  536536      activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_41[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 19, 19, 728)  0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_42 (SeparableC (None, 19, 19, 728)  536536      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_42[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 19, 19, 728)  0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_43 (SeparableC (None, 19, 19, 728)  536536      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_43[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, 19, 19, 728)  0           batch_normalization_54[0][0]     \n",
            "                                                                 add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 19, 19, 728)  0           add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_44 (SeparableC (None, 19, 19, 728)  536536      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_44[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 19, 19, 728)  0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_45 (SeparableC (None, 19, 19, 728)  536536      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_45[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 19, 19, 728)  0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_46 (SeparableC (None, 19, 19, 728)  536536      activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_46[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "add_17 (Add)                    (None, 19, 19, 728)  0           batch_normalization_57[0][0]     \n",
            "                                                                 add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 19, 19, 728)  0           add_17[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_47 (SeparableC (None, 19, 19, 728)  536536      activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_47[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 19, 19, 728)  0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_48 (SeparableC (None, 19, 19, 728)  536536      activation_50[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_48[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 19, 19, 728)  0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_49 (SeparableC (None, 19, 19, 728)  536536      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_49[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "add_18 (Add)                    (None, 19, 19, 728)  0           batch_normalization_60[0][0]     \n",
            "                                                                 add_17[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 19, 19, 728)  0           add_18[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_50 (SeparableC (None, 19, 19, 728)  536536      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_50[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 19, 19, 728)  0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_51 (SeparableC (None, 19, 19, 728)  536536      activation_53[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_51[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 19, 19, 728)  0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_52 (SeparableC (None, 19, 19, 728)  536536      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_52[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "add_19 (Add)                    (None, 19, 19, 728)  0           batch_normalization_63[0][0]     \n",
            "                                                                 add_18[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 19, 19, 728)  0           add_19[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_53 (SeparableC (None, 19, 19, 728)  536536      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_53[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 19, 19, 728)  0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_54 (SeparableC (None, 19, 19, 728)  536536      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_54[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 19, 19, 728)  0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_55 (SeparableC (None, 19, 19, 728)  536536      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_55[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "add_20 (Add)                    (None, 19, 19, 728)  0           batch_normalization_66[0][0]     \n",
            "                                                                 add_19[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 19, 19, 728)  0           add_20[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_56 (SeparableC (None, 19, 19, 728)  536536      activation_58[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_56[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 19, 19, 728)  0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_57 (SeparableC (None, 19, 19, 728)  536536      activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_57[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 19, 19, 728)  0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_58 (SeparableC (None, 19, 19, 728)  536536      activation_60[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_58[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "add_21 (Add)                    (None, 19, 19, 728)  0           batch_normalization_69[0][0]     \n",
            "                                                                 add_20[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 19, 19, 728)  0           add_21[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_59 (SeparableC (None, 19, 19, 728)  536536      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_59[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 19, 19, 728)  0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_60 (SeparableC (None, 19, 19, 728)  536536      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_60[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 19, 19, 728)  0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_61 (SeparableC (None, 19, 19, 728)  536536      activation_63[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_61[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "add_22 (Add)                    (None, 19, 19, 728)  0           batch_normalization_72[0][0]     \n",
            "                                                                 add_21[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 19, 19, 728)  0           add_22[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_62 (SeparableC (None, 19, 19, 728)  536536      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_62[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 19, 19, 728)  0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_63 (SeparableC (None, 19, 19, 728)  536536      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_63[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 19, 19, 728)  0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_64 (SeparableC (None, 19, 19, 728)  536536      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_64[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "add_23 (Add)                    (None, 19, 19, 728)  0           batch_normalization_75[0][0]     \n",
            "                                                                 add_22[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 19, 19, 728)  0           add_23[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_65 (SeparableC (None, 19, 19, 728)  536536      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_65[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 19, 19, 728)  0           batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_66 (SeparableC (None, 19, 19, 1024) 752024      activation_68[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 19, 19, 1024) 4096        separable_conv2d_66[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2D)  (None, 10, 10, 1024) 0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 10, 10, 1024) 745472      add_23[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_9 (Dropout)             (None, 10, 10, 1024) 0           max_pooling2d_8[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 10, 10, 1024) 4096        conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_24 (Add)                    (None, 10, 10, 1024) 0           dropout_9[0][0]                  \n",
            "                                                                 batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_67 (SeparableC (None, 10, 10, 1536) 1582080     add_24[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 10, 10, 1536) 6144        separable_conv2d_67[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 10, 10, 1536) 0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_68 (SeparableC (None, 10, 10, 2048) 3159552     activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 10, 10, 2048) 8192        separable_conv2d_68[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 10, 10, 2048) 0           batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_2 (Glo (None, 2048)         0           activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_10 (Dropout)            (None, 2048)         0           global_average_pooling2d_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 10)           20490       dropout_10[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 20,882,546\n",
            "Trainable params: 20,828,018\n",
            "Non-trainable params: 54,528\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "139"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_oPa9HyBNeb",
        "colab_type": "text"
      },
      "source": [
        "### 训练\n",
        "进行模型训练。这里batch size为64。用了自适应优化器Nadam，使用schedule learning rate自动调整学习率的方法并在验证loss不下降时early stopping。一共训练5代，最后的验证集loss仍然有下降空间。steps per epoch设定为在一个epoch内所有训练图片被遍历1次."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cw7pUr7tBNec",
        "colab_type": "code",
        "outputId": "025c2db9-b718-416a-d8d0-eafce960795b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        }
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler\n",
        "video_model.compile(optimizer=Nadam(),loss='categorical_crossentropy',metrics=['categorical_accuracy'])\n",
        "\n",
        "def learning_rate(epoch):\n",
        "    ini_lr = 0.002* pow(10, -5)\n",
        "    lr = ini_lr * pow(10, -epoch)\n",
        "    return lr\n",
        "\n",
        "cp = ModelCheckpoint(filepath=\"mffs_model_nolock_dropout_more_nostopping.h5\", save_best_only=True)\n",
        "# es = EarlyStopping()\n",
        "lrs = LearningRateScheduler(learning_rate)\n",
        "# hist = video_model.fit_generator(train_gen(32), steps_per_epoch = 572, epochs = 5, workers=4, max_q_size=20, use_multiprocessing=True, validation_data = valid_gen(32), validation_steps = 104, callbacks=[cp, es, lrs])\n",
        "hist = video_model.fit_generator(train_gen(24), steps_per_epoch = 615, epochs = 5, workers=4, max_q_size=20, use_multiprocessing=True, validation_data = valid_gen(32), validation_steps = 214, callbacks=[cp, lrs])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:757: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3008: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., steps_per_epoch=615, epochs=5, workers=4, use_multiprocessing=True, validation_data=<generator..., validation_steps=214, callbacks=[<keras.ca..., max_queue_size=20)`\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:976: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:963: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:2087: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
            "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "614/615 [============================>.] - ETA: 5s - loss: 0.3049 - categorical_accuracy: 0.9537 "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:2330: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
            "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r615/615 [==============================] - 4579s 7s/step - loss: 0.3048 - categorical_accuracy: 0.9537 - val_loss: 1.8016 - val_categorical_accuracy: 0.5219\n",
            "Epoch 2/5\n",
            "615/615 [==============================] - 3037s 5s/step - loss: 0.3195 - categorical_accuracy: 0.9478 - val_loss: 1.7672 - val_categorical_accuracy: 0.5222\n",
            "Epoch 3/5\n",
            "615/615 [==============================] - 2572s 4s/step - loss: 0.3224 - categorical_accuracy: 0.9467 - val_loss: 1.8111 - val_categorical_accuracy: 0.5169\n",
            "Epoch 4/5\n",
            "615/615 [==============================] - 2215s 4s/step - loss: 0.3117 - categorical_accuracy: 0.9487 - val_loss: 1.7837 - val_categorical_accuracy: 0.5263\n",
            "Epoch 5/5\n",
            "615/615 [==============================] - 2026s 3s/step - loss: 0.3115 - categorical_accuracy: 0.9508 - val_loss: 1.7981 - val_categorical_accuracy: 0.5231\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VAHzyngJBNeg",
        "colab_type": "text"
      },
      "source": [
        "### 模型结果\n",
        "\n",
        "保存模型。输出history数据，观察loss曲线。 这里忘记设置inline，没有显示曲线。从数据来看验证集loss明显降低，分类精度提高。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ninxLSeRbGz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "outputId": "84367a11-950e-4991-ee33-a91aa19cd2d0"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "print (hist.history)\n",
        "plt.figure(1)\n",
        "plt.plot (hist.history['loss'],label='loss')\n",
        "plt.plot (hist.history['val_loss'], label='val_loss')\n",
        "plt.legend(bbox_to_anchor=(1,1),#图例边界框起始位置\n",
        "                 loc=\"upper right\",#图例的位置\n",
        "                 ncol=1,#列数\n",
        "                 mode=\"None\",#当值设置为“expend”时，图例会水平扩展至整个坐标轴区域\n",
        "                 borderaxespad=0,#坐标轴和图例边界之间的间距\n",
        "                 shadow=False,#是否为线框添加阴影\n",
        "                 fancybox=True)#线框圆角处理参数\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'val_loss': [1.8016369019713356, 1.767208275393905, 1.8110782810460742, 1.7836665862074523, 1.7981319928837713], 'val_categorical_accuracy': [0.5219042056074766, 0.522196261682243, 0.5169392523364486, 0.5262850467289719, 0.523072429906542], 'loss': [0.30483281840153825, 0.3195265209771753, 0.3224278960770708, 0.31170478169995597, 0.3114632583488294], 'categorical_accuracy': [0.9537262832246176, 0.9478319753476274, 0.9466802137654002, 0.9487127333152585, 0.9508130041564383]}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAa2ElEQVR4nO3dfZRU9Z3n8fe3HroBeRChFQUUnYOi\n0uNDWqPHFcmTIirkySA+DWYi5xijJnpcjXnQMcnZmc0ek52NkXUchuj4xFFPhigumxxJiDujQ+uA\niCjLomKjSTeN4gNCd1d99497q6kuqrpuQXVVcf28zqlTt373V/f37dtdn3vr3ltd5u6IiMiBL1Hv\nAkREpDoU6CIiMaFAFxGJCQW6iEhMKNBFRGIiVa+Bx48f71OmTKnX8CLSQEaNGsWCBQuYNGkSZlbv\nchqSu9PR0cGNN97Y3d3dPb5Yn7oF+pQpU2hvb6/X8CLSQF5//XVGjRrFuHHjFOgluDvd3d309PSU\nzG0dchGRutu1a5fCvAwzY9y4cUyZMmV4qT4KdBFpCArz8sxs0PWkQBcRiQkFuogIMHLkyHqXsN8U\n6CIiMaFAFxHJ4+7cfPPNTJ8+ndbWVh599FEA3nnnHWbMmMHJJ5/M9OnT+eMf/0gmk2HBggX9fX/2\ns5/Vtfa6XbYoIlLM3/xmPa+8/X5Vl3nCEaO5/aITI/V94oknWLNmDWvXrmXbtm2cdtppzJgxg4ce\neojzzjuP733ve2QyGXbu3MmaNWvYunUrL7/8MgDvvfdeVeuuVNlAN7PFwIVAp7tPLzJ/DPDPwJHh\n8v6bu/9TtQsVqSp36PkQdm6Hnd3w8XbY+W4wvWsHpJqgaSQ0HZR3G5l3H06nh4OuzoiVZ599lvnz\n55NMJjnssMM455xzWL16Naeddhpf//rX6e3t5Ytf/CInn3wyxxxzDJs3b+a6667jggsu4Nxzz61r\n7VH20JcAvwDuLzH/WuAVd7/IzFqA18zsQXfvqVKNA33YCX9eD8NGQ/MYGDYmmE41D8lwcgDIZmH3\njjCct4fhnB/U3WH7u3nT2yFTjT9RKx38zSMLNgTlpnMbiRGQ+OQeDY26J11rM2bMYNWqVTz11FMs\nWLCAG2+8kSuvvJK1a9eyYsUKFi1axNKlS1m8eHHdaiwb6O6+ysymDNYFGGXBxZEjge1AX1WqK+aN\nZ+Gxq/ZuTzaHIT96T8g3j947+Pvb8vuF98n0kJUtEWX6YNd7JQI5N/3u3kHtmeLLsySMOASGHxLc\nH3IMTPwUjBiX114wPWwMZHuh5yPY/UFw3/NRsEdfdDr3OK9t5zZ4780983Z/WLrGYtLF3hnkNhKl\n3jmUeBeRuyWS1fkdHejcAQ/u3YFseA/0fszZZ57G//yHxfzVJV9me/d2Vv3h9/z0zu/x5qtrmTTx\ncK6+9Evsfn8bLz7/LLNnfIqmVJqvfOFMjjviYC5feD28t2XvZfePmQ3uhx8CIw+t+o9WjWPovwCW\nAW8Do4B57p4t1tHMFgILAY488sh9G+2YmXDV07Dr/eCt8e78+4LpD/60p633o/LLTg2PFvxFNxrh\nLanTEv36ekoEcqk96e1BmJeSbAoCNxfOhx5fPJBHHLLncfPofdvbTaaCwykHFf2XGZVzD94R5Af8\noBuJwvkfBuvm/a0D2yt5l5EaHnEjUWr6IGgaNXBesb/3bDaoK7MbMr3BdF9uenc4rzevrQd6Dwt+\n/wMCtkjoDmjPFvQJ2/L7lGor+jvKQterfOmsafzbyiM46dQ2zIz/+t1rmdD8Mb/6l9/w00X3k06l\nGHnQcO7/7z9i6/99matuvINsNoi8/3LbDUHmmAEW3JsBieA+kQzah2jjalG+gi7cQ3+yxDH0rwJn\nATcCfwH8FjjJ3Qc9q9HW1uY1/V8umb4g6IsFf3/be0Xa8vr1fVx+nKaRJTYGhW1jivdrGtWYb7d7\ndhYEcnd4CKMgkPOnez4svbz0QWHojs0L4bywHjEunJfX3nSQjlcX6usJdlZ6PqpgI1HkHUX+dN+u\n6OMnm6FpRBCGuZCu5J1IaMN5Szn+qMH2WHPhmNgzXaytZHuxPiXayi67xHg18rvf/a7n85//fNFj\nzNXYnbwK+FsPtgybzOx1YBrw71VYdvUkU3v23PZVX0/wFrxc8O/esadt5zbYvnnPO4mye1QGzaPK\nbAzypov1axpZ+g/MPfgZCk8Elju0MdiLvHkMjAiD+aAWaDkuL5zH5k3n7Umnh+3zr0HypJqC2/Cx\n1Vtmpq9gI1HuUNNHwR5nMh28i0o275lO5aZLtTUF09sTcOix9O/J1jEwD2TVCPQtwOeAP5rZYcBx\nwOYqLLfxpJogNQ4OGrfvy+jdVTz4S24gdsCHf4JtG/e0ZcucorBEsFEYNiYI26YRwTJze9XZ3lJP\nHLhXPGYSHH5SEMqlDm0MH6tzD3GTTEEyfBdZKzs2QEob+f0V5bLFh4GZwHgz6wBuB9IA7r4I+BGw\nxMzWAQbc4u7bhqziA116WHDb1xMi7tD7cUHw7xjk3cL7wV7UuL+AyacXOdacd5hj2BidOBM5gEW5\nymV+mflvA/W9+PKTxCzY424aAaMm1LsaEWkgDXj2TURE9oUCXUQkJhToIiIxoUAXEanQYP87/Y03\n3mD69L0+slMTCnQRkZjQ59RFpLE8fSv8aV11lzmhFc7/25Kzb731ViZPnsy1114LwB133EEqlWLl\nypW8++679Pb28uMf/5i5c+dWNOyuXbu45ppraG9vJ5VKcdddd/GZz3yG9evXc9VVV9HT00M2m+Xx\nxx/niCOO4Gtf+xodHR1kMhl+8IMfMG/evIrGU6CLyCfevHnz+Pa3v90f6EuXLmXFihVcf/31jB49\nmm3btnHGGWcwZ86cir7M+u6778bMWLduHa+++irnnnsuGzduZNGiRdxwww1cdtll9PT0kMlkWL58\nOUcccQRPPfUUADt27Kj451Cgi0hjGWRPeqiccsopdHZ28vbbb9PV1cXYsWOZMGEC3/nOd1i1ahWJ\nRIKtW7fy5z//mQkTon/+49lnn+W6664DYNq0aRx11FFs3LiRM888k5/85Cd0dHTw5S9/malTp9La\n2spNN93ELbfcwoUXXsjZZ59d8c+hY+giIsDFF1/MY489xqOPPsq8efN48MEH6erq4oUXXmDNmjUc\ndthh7NpVwT8uG8Sll17KsmXLGD58OLNnz+aZZ57h2GOP5cUXX6S1tZXvf//73HnnnRUvV3voIiIE\nh12uvvpqtm3bxh/+8AeWLl3KoYceSjqdZuXKlbz55psVL/Pss8/mwQcf5LOf/SwbN25ky5YtHHfc\ncWzevJljjjmG66+/ni1btvDSSy8xbdo0DjnkEC6//HIOPvhg7rvvvorHU6CLiAAnnngiH3zwARMn\nTuTwww/nsssu46KLLqK1tZW2tjamTZtW8TK/+c1vcs0119Da2koqlWLJkiU0NzezdOlSHnjgAdLp\nNBMmTOC2225j9erV3HzzzSQSCdLpNPfcc0/F40X6f+hDoeb/D11EGtaGDRs4/vjj613GAWGw/4eu\nY+giIjGhQy4iIvtg3bp1XHHFFQPampubef755+tUkQJdRBqEu1d0jXe9tba2smbNmpqO6e4Mdphc\nh1xEpO6GDRtGd3f3oGH1SefudHd388Ybb5T8cmOdFBWRuuvt7aWjo6Nq13nH1bBhw/j0pz+9trOz\n8+Ri86N8Bd1i4EKg092L/gsxM5sJ/Jzgq+m2ufs5+16yiHzSpNNpjj766HqXcUDo6uoq+aXCUQ65\nLAFmlZppZgcDvwTmuPuJwMWVFigiIvuvbKC7+ypg+yBdLgWecPctYf/OKtUmIiIVqMZJ0WOBsWb2\nezN7wcyuLNXRzBaaWbuZtXd1dVVhaBERyalGoKeATwEXAOcBPzCzY4t1dPd73b3N3dtaWlqqMLSI\niORU4zr0DqDb3T8CPjKzVcBJwMYqLFtERCKqxh76vwD/ycxSZjYC+DSwoQrLFRGRCkS5bPFhYCYw\n3sw6gNsJLk/E3Re5+wYz+1/AS0AWuM/dXx66kkVEpJiyge7u8yP0+Snw06pUJCIi+0Qf/RcRiQkF\nuohITCjQRURiQoEuIhITCnQRkZhQoIuIxIQCXUQkJhToIiIxoUAXEYkJBbqISEwo0EVEYkKBLiIS\nEwp0EZGYUKCLiMSEAl1EJCYU6CIiMaFAFxGJibKBbmaLzazTzAb9WjkzO83M+szsq9UrT0REooqy\nh74EmDVYBzNLAn8H/O8q1CQiIvugbKC7+ypge5lu1wGPA53VKEpERCq338fQzWwi8CXgngh9F5pZ\nu5m1d3V17e/QIiKSpxonRX8O3OLu2XId3f1ed29z97aWlpYqDC0iIjmpKiyjDXjEzADGA7PNrM/d\nf12FZYuISET7HejufnRu2syWAE8qzEVEaq9soJvZw8BMYLyZdQC3A2kAd180pNWJiEhkZQPd3edH\nXZi7L9ivakREZJ/pk6IiIjGhQBcRiQkFuohITCjQRURiQoEuIhITCnQRkZhQoIuIxIQCXUQkJhTo\nIiIxoUAXEYkJBbqISEwo0EVEYkKBLiISEwp0EZGYUKCLiMSEAl1EJCYU6CIiMVE20M1ssZl1mtnL\nJeZfZmYvmdk6M/tXMzup+mWKiEg5UfbQlwCzBpn/OnCOu7cCPwLurUJdIiJSoSjfKbrKzKYMMv9f\n8x4+B0za/7JERKRS1T6G/tfA06VmmtlCM2s3s/aurq4qDy0i8slWtUA3s88QBPotpfq4+73u3ubu\nbS0tLdUaWkREiHDIJQoz+0vgPuB8d++uxjJFRKQy+72HbmZHAk8AV7j7xv0vSURE9kXZPXQzexiY\nCYw3sw7gdiAN4O6LgB8C44BfmhlAn7u3DVXBIiJSXJSrXOaXmf8N4BtVq0hERPaJPikqIhITCnQR\nkZhQoIuIxIQCXUQkJhToIiIxoUAXEYkJBbqISEwo0EVEYkKBLiISEwp0EZGYUKCLiMSEAl1EJCYU\n6CIiMaFAFxGJCQW6iEhMKNBFRGJCgS4iEhMKdBGRmCgb6Ga22Mw6zezlEvPNzP7ezDaZ2Utmdmr1\nyxQRkXKi7KEvAWYNMv98YGp4Wwjcs/9liYhIpcoGuruvArYP0mUucL8HngMONrPDq1WgiIhEU41j\n6BOBt/Ied4RtezGzhWbWbmbtXV1dVRhaRERyanpS1N3vdfc2d29raWmp5dAiIrFXjUDfCkzOezwp\nbBMRkRqqRqAvA64Mr3Y5A9jh7u9UYbkiIlKBVLkOZvYwMBMYb2YdwO1AGsDdFwHLgdnAJmAncNVQ\nFSsiIqWVDXR3n19mvgPXVq0iERHZJ/qkqIhITCjQRURiQoEuIhITCnQRkZhQoIuIxIQCXUQkJhTo\nIiIxoUAXEYkJBbqISEwo0EVEYkKBLiISEwp0EZGYUKCLiMSEAl1EJCYU6CIiMaFAFxGJCQW6iEhM\nRAp0M5tlZq+Z2SYzu7XI/CPNbKWZ/YeZvWRms6tfqoiIDKZsoJtZErgbOB84AZhvZicUdPs+sNTd\nTwEuAX5Z7UJFRGRwUfbQTwc2uftmd+8BHgHmFvRxYHQ4PQZ4u3oliohIFFECfSLwVt7jjrAt3x3A\n5WbWASwHriu2IDNbaGbtZtbe1dW1D+WKiEgp1TopOh9Y4u6TgNnAA2a217Ld/V53b3P3tpaWlioN\nLSIiEC3QtwKT8x5PCtvy/TWwFMDd/w0YBoyvRoEiIhJNlEBfDUw1s6PNrIngpOeygj5bgM8BmNnx\nBIGuYyoiIjVUNtDdvQ/4FrAC2EBwNct6M7vTzOaE3W4CrjaztcDDwAJ396EqWkRE9paK0sndlxOc\n7Mxv+2He9CvAWdUtTUREKqFPioqIxIQCXUQkJhToIiIxoUAXEYkJBbqISEwo0EVEYkKBLiISEwp0\nEZGYUKCLiMSEAl1EJCYU6CIiMaFAFxGJCQW6iEhMKNBFRGJCgS4iEhMKdBGRmFCgi4jERKRAN7NZ\nZvaamW0ys1tL9Pmamb1iZuvN7KHqlikiIuWU/Qo6M0sCdwNfADqA1Wa2LPzauVyfqcB3gbPc/V0z\nO3SoChYRkeKi7KGfDmxy983u3gM8Aswt6HM1cLe7vwvg7p3VLVNERMqJEugTgbfyHneEbfmOBY41\ns/9jZs+Z2axiCzKzhWbWbmbtXV1d+1axiIgUVa2ToilgKjATmA/8g5kdXNjJ3e919zZ3b2tpaanS\n0CIiAtECfSswOe/xpLAtXwewzN173f11YCNBwIuISI1ECfTVwFQzO9rMmoBLgGUFfX5NsHeOmY0n\nOASzuYp1iohIGWUD3d37gG8BK4ANwFJ3X29md5rZnLDbCqDbzF4BVgI3u3v3UBUtIiJ7M3evy8Bt\nbW3e3t5el7FFRA5UZvaCu7cVm6dPioqIxIQCXUQkJhToIiIxoUAXEYkJBbqISEwo0EVEYkKBLiIS\nEwp0EZGYUKCLiMSEAl1EJCYU6CIiMaFAFxGJCQW6iEhMKNBFRGJCgS4iEhMKdBGRmFCgi4jERKRA\nN7NZZvaamW0ys1sH6fcVM3MzK/ptGiIiMnTKBrqZJYG7gfOBE4D5ZnZCkX6jgBuA56tdpIiIlBdl\nD/10YJO7b3b3HuARYG6Rfj8C/g7YVcX6REQkoiiBPhF4K+9xR9jWz8xOBSa7+1ODLcjMFppZu5m1\nd3V1VVysiIiUtt8nRc0sAdwF3FSur7vf6+5t7t7W0tKyv0OLiEieKIG+FZic93hS2JYzCpgO/N7M\n3gDOAJbpxKiISG1FCfTVwFQzO9rMmoBLgGW5me6+w93Hu/sUd58CPAfMcff2IalYRESKKhvo7t4H\nfAtYAWwAlrr7ejO708zmDHWBIiISTSpKJ3dfDiwvaPthib4z978sERGplD4pKiISEwp0EZGYUKCL\niMREpGPoIvXi7riDh9NZBydoA8jmzc9NE/bJevj8cB79ywn75i8/b7kOJM1IJYNbOpEgGd6nkkYq\nYZhZndaISGkK9BrKZp3ebJaeviy9GQ/vs+wO73vy7nsyef0yGXr7nN2ZLL3hvNx9T8HzcsvNb+/N\nZPvDLRsGFgXhmAu5cNbAwAvb8sMx9xzyH/eHKBAuN5v3/PxQzX9OYaDmP6dRJRNBsKeTe0I+FQZ+\nOpkYdH4qYaSSCdLJsC2R23gkSCeMZCKcN2B+rr+RDPvl2pLhstPhMlKJgWMkc3Uk8mobsIHShiou\nYhfofZmCUMsPv4Iw3BOeXhCKpUJ2734DllskVHsHBGt1E8oMmpKJ4JZKkO6/N5pSSZqSRlMqQSqR\nIJGARPhiNTMSBhZO99+HbYnctIGRm7Zw3p5pLOwb1pJ7HuFzEnnP3zN20JbILb9/3L2fM7Cugc8h\nv07yx97750uEBQ6oEwb8XP0/X3gQMpMN/5ayTiaTpS/r9GacvnC6L5ulLxO0ZbJBv75M0JabP6B/\nJmj7uNfJZJ3e/vaB84Pl7ZmfydZ2q5ZK5G0AKthQJSIevA3/cgbvU+VtSpSNVNQho9QWZVmzWw/n\n4rbJ5TtW6IAL9N+/1smPn9pQYm822BOtpnT4h9wfmANCc0/byOYUTcnEwL6pRH+o5rc3p8r0SyZI\np4oHdXMySTplNIUvLu1RxZu79wd+bzZLJrzvy+zZCPTlNgC5jUlmT1smtyHKDpyf2wBl8jZUvdlg\n45TbUOWWndtQ5eYX21B5JsLPEvHnjbReIvWK9i4vcmREWFjUZX20uy/qqBU54AJ99PA0x00YFYan\nFYTiwDBMpxI0JxNhACb7++8dlIUhGy43kSCRUGBK/ZhZuFMBw0nWuxxpcAdcoJ965FhOvXRsvcsQ\nEWk4umxRRCQmFOgiIjGhQBcRiQkFuohITCjQRURiQoEuIhITCnQRkZhQoIuIxIRF/aht1Qc26wLe\n3Menjwe2VbGcamnUuqBxa1NdlVFdlYljXUe5e0uxGXUL9P1hZu3u3lbvOgo1al3QuLWprsqorsp8\n0urSIRcRkZhQoIuIxMSBGuj31ruAEhq1Lmjc2lRXZVRXZT5RdR2Qx9BFRGRvB+oeuoiIFFCgi4jE\nREMHupnNMrPXzGyTmd1aZH6zmT0azn/ezKY0SF0LzKzLzNaEt2/UqK7FZtZpZi+XmG9m9vdh3S+Z\n2akNUtdMM9uRt75+WIOaJpvZSjN7xczWm9kNRfrUfH1FrKvm6yscd5iZ/buZrQ1r+5sifWr+moxY\nV71ek0kz+w8ze7LIvOqvK3dvyBuQBP4fcAzQBKwFTijo801gUTh9CfBog9S1APhFHdbZDOBU4OUS\n82cDTxN8j+0ZwPMNUtdM4Mkar6vDgVPD6VHAxiK/x5qvr4h11Xx9heMaMDKcTgPPA2cU9KnHazJK\nXfV6Td4IPFTs9zUU66qR99BPBza5+2Z37wEeAeYW9JkL/Cqcfgz4nA39tyZHqasu3H0VsH2QLnOB\n+z3wHHCwmR3eAHXVnLu/4+4vhtMfABuAiQXdar6+ItZVF+F6+DB8mA5vhVdV1Pw1GbGumjOzScAF\nwH0lulR9XTVyoE8E3sp73MHef9j9fdy9D9gBjGuAugC+Er5Nf8zMJg9xTVFFrb0ezgzfMj9tZifW\ncuDwre4pBHt2+eq6vgapC+q0vsJDCGuATuC37l5yndXwNRmlLqj9a/LnwH8GsiXmV31dNXKgH8h+\nA0xx978EfsuerbAU9yLB/6c4CfgfwK9rNbCZjQQeB77t7u/XatxyytRVt/Xl7hl3PxmYBJxuZtNr\nNfZgItRV09ekmV0IdLr7C0M5TqFGDvStQP5WdFLYVrSPmaWAMUB3vety92533x0+vA/41BDXFFWU\ndVpz7v5+7i2zuy8H0mY2fqjHNbM0QWg+6O5PFOlSl/VVrq56ra+CGt4DVgKzCmbV4zVZtq46vCbP\nAuaY2RsEh2U/a2b/XNCn6uuqkQN9NTDVzI42syaCkwbLCvosA/4qnP4q8IyHZxjqWVfBcdY5BMdB\nG8Ey4Mrw6o0zgB3u/k69izKzCbljh2Z2OsHf5ZCGQDjePwIb3P2uEt1qvr6i1FWP9RWO1WJmB4fT\nw4EvAK8WdKv5azJKXbV+Tbr7d919krtPIciIZ9z98oJuVV9Xqf158lBy9z4z+xawguDKksXuvt7M\n7gTa3X0ZwR/+A2a2ieCk2yUNUtf1ZjYH6AvrWjDUdQGY2cMEV0CMN7MO4HaCE0S4+yJgOcGVG5uA\nncBVDVLXV4FrzKwP+Bi4pAYb5rOAK4B14bFXgNuAI/Pqqsf6ilJXPdYXBFfg/MrMkgQbkaXu/mS9\nX5MR66rLa7LQUK8rffRfRCQmGvmQi4iIVECBLiISEwp0EZGYUKCLiMSEAl1EJCYU6CIiMaFAFxGJ\nif8PU40c5cOJ15QAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BEbJHCwLpxg9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "320bd6ca-eee2-4d10-ac46-675e65b01bbb"
      },
      "source": [
        "plt.figure(2)\n",
        "plt.plot (hist.history['categorical_accuracy'], label='categorical_accuracy')\n",
        "plt.plot (hist.history['val_categorical_accuracy'], label='val_categorical_accuracy')\n",
        "plt.legend(bbox_to_anchor=(1,0),#图例边界框起始位置\n",
        "                 loc=\"lower right\",#图例的位置\n",
        "                 ncol=1,#列数\n",
        "                 mode=\"expend\",#当值设置为“expend”时，图例会水平扩展至整个坐标轴区域\n",
        "                 borderaxespad=0,#坐标轴和图例边界之间的间距\n",
        "                 shadow=False,#是否为线框添加阴影\n",
        "                 fancybox=True)#线框圆角处理参数\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.4"
    },
    "colab": {
      "name": "mffs_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/perfectism13/learning_colab/blob/master/MFFs_model/mffs_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5npKCNyvhnF",
        "colab_type": "code",
        "outputId": "cb6acd39-1268-47ae-c4b6-be9a10fa3b68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os\n",
        "os.chdir(r'/content/drive/My Drive/colab/mlnd_distracted_driver_detection/state-farm-distracted-driver-detection/imgs/')\n",
        "# os.chdir(r'/content/drive/My Drive/data/imgs/')\n",
        "print(os.getcwd())\n",
        "!ls\n",
        "!pip install keras==2.1.5\n",
        "import keras\n",
        "print(keras.__version__)\n",
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/My Drive/colab/mlnd_distracted_driver_detection/state-farm-distracted-driver-detection/imgs\n",
            "'(1-726)clean.mp4'\n",
            "'(1-726).mp4'\n",
            " 5-0.15993-0.15993.zip\n",
            "'（726-800)clean.mp4'\n",
            " （726-800）.mp4\n",
            "'(726-966)clean.mp4'\n",
            "'(726-966).mp4'\n",
            " C3D_Sport1M_weights_keras_2.2.4.h5\n",
            " driver_imgs_list_class_2.csv\n",
            " driver_imgs_list_class.csv\n",
            " driver_imgs_list_class.gsheet\n",
            " driver_imgs_list.csv\n",
            " driver_imgs_list_right.csv\n",
            " flow_xception_lock50.h5\n",
            " flow_xception_lock70.h5\n",
            " get-docker.sh\n",
            " I3D_rgbs_model.h5\n",
            " mffs_model_nolock.h5\n",
            " motion.h5\n",
            " motion.log\n",
            " motion.preds\n",
            " my_model10.h5\n",
            " my_model11.h5\n",
            " my_model12.h5\n",
            " my_model13.h5\n",
            " my_model1.h5\n",
            " my_model9.h5\n",
            " sample_submission.csv\n",
            " test\n",
            " train\n",
            " valid\n",
            " vect\n",
            " video_model_change_vd_data_aug.h5\n",
            " video_model_change_vd_data_aug_modified.h5\n",
            " video_model_change_vd.h5\n",
            " video_model.h5\n",
            "Requirement already satisfied: keras==2.1.5 in /usr/local/lib/python3.6/dist-packages (2.1.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.1.5) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.1.5) (1.4.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.1.5) (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.1.5) (1.17.5)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "2.1.5\n",
            "Wed Feb 12 08:57:57 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.48.02    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   32C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwdUnNY5BNc_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.environ['KERAS_BACKEND']='tensorflow'\n",
        "import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHt6FC_zBNdG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "np.random.seed(2017)\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import cv2\n",
        "import math\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.pooling import MaxPooling2D\n",
        "from keras.optimizers import SGD, Adam, Nadam\n",
        "from keras.utils import np_utils\n",
        "from keras.models import model_from_json\n",
        "from sklearn.metrics import log_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUSMqWoRBNd4",
        "colab_type": "text"
      },
      "source": [
        "### 切分数据\n",
        "按照司机的id来切分训练数据集。把driver_imgs_list分成两个列表。一个是训练列表，里面是所有训练集司机的图片文件名。另一个是验证列表，里面是所有验证集司机的图片文件名。然后把两个列表都随机打乱。 这里列表里面保存的都只是excel文件里的一行行数据（包括文件名，分类，司机id），而不是图片本身。等训练时通过生成器读取图片，这样节约内存。 另外还保存了一个类别字典，便于以后从同一类中抽取图片进行拼接。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYofeN2LBNd5",
        "colab_type": "code",
        "outputId": "d41d2e3d-ee73-4a9c-d350-9bad7077c295",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# divide drivers\n",
        "# unique_list_train = ['p002', 'p012', 'p014', 'p015', 'p026', 'p035', 'p039', 'p041', 'p042', 'p045', 'p047', 'p049', 'p050', 'p051', 'p052', 'p056', 'p061', 'p064', 'p066', 'p072', 'p075']\n",
        "# unique_list_valid = ['p016', 'p021', 'p022', 'p024']\n",
        "unique_list_train = ['p016', 'p021', 'p022', 'p024', 'p026', 'p035', 'p039', 'p041', 'p042', 'p045', 'p047', 'p049', 'p050', 'p051', 'p052', 'p056', 'p061', 'p064', 'p066', 'p072', 'p075']\n",
        "unique_list_valid = ['p002', 'p012', 'p014', 'p015']\n",
        "#print (unique_list_train, unique_list_valid)\n",
        "\n",
        "# get index: driver_id, class, image name\n",
        "index = os.path.join('.', 'driver_imgs_list_class_2.csv')\n",
        "\n",
        "# build the driver id dictionary and class dictionary\n",
        "f = open(index, 'r')\n",
        "id_dict = dict()\n",
        "class_dict = dict()\n",
        "lines = f.readlines()\n",
        "\n",
        "\n",
        "# split the train list and valid list by id\n",
        "train_list = []\n",
        "valid_list = []\n",
        "\n",
        "for line in lines[1:]:\n",
        "    arr = line.strip().split(',')\n",
        "    if arr[0]  in unique_list_train:\n",
        "        train_list.append(line)\n",
        "    elif arr[0]  in unique_list_valid:\n",
        "      valid_list.append(line)\n",
        "f.close()\n",
        "\n",
        "random.shuffle(train_list)\n",
        "random.shuffle(valid_list)\n",
        "\n",
        "print (len(train_list), len(valid_list))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18302 3299\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsnPujySBNd8",
        "colab_type": "text"
      },
      "source": [
        "### 获取test set图片的列表\n",
        "获取sample_submission.csv中所有测试图片的文件名，预测test set时使用。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzUKzBnjBNd9",
        "colab_type": "code",
        "outputId": "822af96b-a1d2-4f7b-c102-ecee07aaf092",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "test_index = os.path.join('.', 'sample_submission.csv')\n",
        "f = open(test_index, 'r')\n",
        "lines = f.readlines()\n",
        "test_list = []\n",
        "for line in lines[1:]:\n",
        "    arr = line.strip().split(',')\n",
        "    test_list.append(arr[0])\n",
        "f.close()\n",
        "print (test_list[:5])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['img_1.jpg', 'img_10.jpg', 'img_100.jpg', 'img_1000.jpg', 'img_100000.jpg']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nl_N2noABNeB",
        "colab_type": "text"
      },
      "source": [
        "### 转换为One Hot Encode标签\n",
        "\n",
        "对分类标签进行One Hot Encode的函数如下。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18IjONecBNeC",
        "colab_type": "code",
        "outputId": "d0dd054c-1722-4d97-eb86-b58d1642648c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# one hot encode the class label\n",
        "\n",
        "from sklearn import preprocessing\n",
        "lb = preprocessing.LabelBinarizer()\n",
        "lb.fit(['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9'])   \n",
        "def one_hot_encode(x):\n",
        "    return lb.transform(x)\n",
        "t = one_hot_encode(['c1', 'c2'])\n",
        "print(t)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 1 0 0 0 0 0 0 0 0]\n",
            " [0 0 1 0 0 0 0 0 0 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsQaZPCZa-Xx",
        "colab_type": "text"
      },
      "source": [
        "###获取两帧图片之间的光流"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8PFfA43bJs1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import cv2\n",
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "from random import choice\n",
        "# image rotation\n",
        "def rotate(x1,x2, degree, row_axis=0, col_axis=1, channel_axis=2, fill_mode='wrap', cval=0.):\n",
        "    theta = np.pi / 180 * degree\n",
        "    rotation_matrix = np.array([[np.cos(theta), -np.sin(theta), 0],\n",
        "    [np.sin(theta), np.cos(theta), 0],\n",
        "    [0, 0, 1]])\n",
        "    h, w = x1.shape[row_axis], x1.shape[col_axis]\n",
        "    transform_matrix = image.transform_matrix_offset_center(rotation_matrix, h, w)\n",
        "    x1 = image.apply_transform(x1, transform_matrix, channel_axis, fill_mode, cval)\n",
        "    x2 = image.apply_transform(x2, transform_matrix, channel_axis, fill_mode, cval)\n",
        "    return x1,x2\n",
        "\n",
        "# image shift\n",
        "def shift(x1,x2, wshift, hshift, row_axis=0, col_axis=1, channel_axis=2, fill_mode='wrap', cval=0.):\n",
        "    h, w = x1.shape[row_axis], x1.shape[col_axis] #读取图片的高和宽\n",
        "    tx = hshift * h #高偏移大小，若不偏移可设为0，若向上偏移设为正数\n",
        "    ty = wshift * w #宽偏移大小，若不偏移可设为0，若向左偏移设为正数\n",
        "    translation_matrix = np.array([[1, 0, tx],\n",
        "                                  [0, 1, ty],\n",
        "                                  [0, 0, 1]])\n",
        "    transform_matrix = translation_matrix  \n",
        "    x1 = image.apply_transform(x1, transform_matrix, channel_axis, fill_mode, cval)\n",
        "    x2 = image.apply_transform(x1, transform_matrix, channel_axis, fill_mode, cval)\n",
        "    return x1,x2\n",
        "\n",
        "#左右或者上下翻转\n",
        "def flip(frame1,frame2,tar):\n",
        "  frame1 = cv2.flip(frame1,tar)\n",
        "  frame2 = cv2.flip(frame2,tar)\n",
        "  return frame1,frame2\n",
        "#水平翻转90°\n",
        "def transpose(frame1,frame2,tar):\n",
        "  if(tar==1):\n",
        "      frame1 = cv2.transpose(frame1)\n",
        "      frame2 = cv2.transpose(frame2)\n",
        "  return frame1,frame2\n",
        "\n",
        "def get_mffs_aug(path1,path2):\n",
        "  frame1 = cv2.imread(path1)\n",
        "  frame1 = cv2.resize(frame1, (299, 299))\n",
        "  prvs = cv2.cvtColor(frame1,cv2.COLOR_BGR2GRAY)\n",
        "  hsv = np.zeros_like(frame1)\n",
        "  hsv[...,1] = 255\n",
        "  frame2 = cv2.imread(path2)\n",
        "  frame2 = cv2.resize(frame2, (299, 299))\n",
        "  #random rotate\n",
        "  deg = random.uniform(-10, 10) #random rotate limit\n",
        "  frame1,frame2 = rotate(frame1,frame2, deg)\n",
        "  #random shift\n",
        "  wshift = random.uniform(-0.1, 0.1)\n",
        "  hshift = random.uniform(-0.1, 0.1)\n",
        "  frame1,frame2 = shift(frame1,frame2, wshift, hshift)\n",
        "  #random flip\n",
        "  foo = [0,-1,1]\n",
        "  tar = choice(foo)\n",
        "  frame1,frame2 = flip(frame1,frame2,tar)\n",
        "  #水平翻转90°\n",
        "  #random transpose\n",
        "  foo = [0,1]\n",
        "  tar = choice(foo)\n",
        "  frame1,frame2 = transpose(frame1,frame2,tar)\n",
        "  next = cv2.cvtColor(frame2,cv2.COLOR_BGR2GRAY)\n",
        "  flow = cv2.calcOpticalFlowFarneback(prvs,next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
        "  mag, ang = cv2.cartToPolar(flow[...,0], flow[...,1])\n",
        "  hsv[...,0] = ang*180/np.pi/2\n",
        "  hsv[...,2] = cv2.normalize(mag,None,0,255,cv2.NORM_MINMAX)\n",
        "  rgb = cv2.cvtColor(hsv,cv2.COLOR_HSV2BGR)\n",
        "  frame1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2RGB)\n",
        "  data = np.zeros((299, 299,5))\n",
        "  data[:, :, 0] = frame1[:, :, 0]\n",
        "  data[:, :, 1] = frame1[:, :, 1]\n",
        "  data[:, :, 2] = frame1[:, :, 2]\n",
        "  data[:, :, 3] = hsv[:, :, 0]\n",
        "  data[:, :, 4] = hsv[:, :, 2]\n",
        "  # normalization\n",
        "  data = np.array(data, dtype=np.float32)  \n",
        "  data /= 127.5\n",
        "  data -= 1.\n",
        "  return data\n",
        "\n",
        "def get_mffs(path1,path2):\n",
        "  frame1 = cv2.imread(path1)\n",
        "  frame1 = cv2.resize(frame1, (299, 299))\n",
        "  prvs = cv2.cvtColor(frame1,cv2.COLOR_BGR2GRAY)\n",
        "  hsv = np.zeros_like(frame1)\n",
        "  hsv[...,1] = 255\n",
        "  frame2 = cv2.imread(path2)\n",
        "  frame2 = cv2.resize(frame2, (299, 299))\n",
        "  next = cv2.cvtColor(frame2,cv2.COLOR_BGR2GRAY)\n",
        "  flow = cv2.calcOpticalFlowFarneback(prvs,next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
        "  mag, ang = cv2.cartToPolar(flow[...,0], flow[...,1])\n",
        "  hsv[...,0] = ang*180/np.pi/2\n",
        "  hsv[...,2] = cv2.normalize(mag,None,0,255,cv2.NORM_MINMAX)\n",
        "  rgb = cv2.cvtColor(hsv,cv2.COLOR_HSV2BGR)\n",
        "  frame1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2RGB)\n",
        "  data = np.zeros((299, 299,5))\n",
        "  data[:, :, 0] = frame1[:, :, 0]\n",
        "  data[:, :, 1] = frame1[:, :, 1]\n",
        "  data[:, :, 2] = frame1[:, :, 2]\n",
        "  data[:, :, 3] = hsv[:, :, 0]\n",
        "  data[:, :, 4] = hsv[:, :, 2]\n",
        "  # normalization\n",
        "  data = np.array(data, dtype=np.float32)  \n",
        "  data /= 127.5\n",
        "  data -= 1.\n",
        "  return data\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vk6Q43cxNnXz",
        "colab_type": "text"
      },
      "source": [
        "###获取光流2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "O2y03D8dNlrG",
        "colab": {}
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import cv2\n",
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "from random import choice\n",
        "# image rotation\n",
        "def rotate(x1,x2, degree, row_axis=0, col_axis=1, channel_axis=2, fill_mode='wrap', cval=0.):\n",
        "    theta = np.pi / 180 * degree\n",
        "    rotation_matrix = np.array([[np.cos(theta), -np.sin(theta), 0],\n",
        "    [np.sin(theta), np.cos(theta), 0],\n",
        "    [0, 0, 1]])\n",
        "    h, w = x1.shape[row_axis], x1.shape[col_axis]\n",
        "    transform_matrix = image.transform_matrix_offset_center(rotation_matrix, h, w)\n",
        "    x1 = image.apply_transform(x1, transform_matrix, channel_axis, fill_mode, cval)\n",
        "    x2 = image.apply_transform(x2, transform_matrix, channel_axis, fill_mode, cval)\n",
        "    return x1,x2\n",
        "\n",
        "# image shift\n",
        "def shift(x1,x2, wshift, hshift, row_axis=0, col_axis=1, channel_axis=2, fill_mode='wrap', cval=0.):\n",
        "    h, w = x1.shape[row_axis], x1.shape[col_axis] #读取图片的高和宽\n",
        "    tx = hshift * h #高偏移大小，若不偏移可设为0，若向上偏移设为正数\n",
        "    ty = wshift * w #宽偏移大小，若不偏移可设为0，若向左偏移设为正数\n",
        "    translation_matrix = np.array([[1, 0, tx],\n",
        "                                  [0, 1, ty],\n",
        "                                  [0, 0, 1]])\n",
        "    transform_matrix = translation_matrix  \n",
        "    x1 = image.apply_transform(x1, transform_matrix, channel_axis, fill_mode, cval)\n",
        "    x2 = image.apply_transform(x1, transform_matrix, channel_axis, fill_mode, cval)\n",
        "    return x1,x2\n",
        "\n",
        "#左右或者上下翻转\n",
        "def flip(frame1,frame2,tar):\n",
        "  frame1 = cv2.flip(frame1,tar)\n",
        "  frame2 = cv2.flip(frame2,tar)\n",
        "  return frame1,frame2\n",
        "#水平翻转90°\n",
        "def transpose(frame1,frame2,tar):\n",
        "  if(tar==1):\n",
        "      frame1 = cv2.transpose(frame1)\n",
        "      frame2 = cv2.transpose(frame2)\n",
        "  return frame1,frame2\n",
        "\n",
        "def get_mffs_aug(path1,path2):\n",
        "  frame1 = cv2.imread(path1)\n",
        "  frame1 = cv2.resize(frame1, (299, 299))\n",
        "  prvs = cv2.cvtColor(frame1,cv2.COLOR_BGR2GRAY)\n",
        "  hsv = np.zeros_like(frame1)\n",
        "  hsv[...,1] = 255\n",
        "  frame2 = cv2.imread(path2)\n",
        "  frame2 = cv2.resize(frame2, (299, 299))\n",
        "  #random rotate\n",
        "  deg = random.uniform(-10, 10) #random rotate limit\n",
        "  frame1,frame2 = rotate(frame1,frame2, deg)\n",
        "  #random shift\n",
        "  wshift = random.uniform(-0.1, 0.1)\n",
        "  hshift = random.uniform(-0.1, 0.1)\n",
        "  frame1,frame2 = shift(frame1,frame2, wshift, hshift)\n",
        "  #random flip\n",
        "  foo = [0,-1,1]\n",
        "  tar = choice(foo)\n",
        "  frame1,frame2 = flip(frame1,frame2,tar)\n",
        "  #水平翻转90°\n",
        "  #random transpose\n",
        "  foo = [0,1]\n",
        "  tar = choice(foo)\n",
        "  frame1,frame2 = transpose(frame1,frame2,tar)\n",
        "  next = cv2.cvtColor(frame2,cv2.COLOR_BGR2GRAY)\n",
        "  flow = cv2.calcOpticalFlowFarneback(prvs,next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
        "  # mag, ang = cv2.cartToPolar(flow[...,0], flow[...,1])\n",
        "  # hsv[...,0] = ang*180/np.pi/2\n",
        "  # hsv[...,2] = cv2.normalize(mag,None,0,255,cv2.NORM_MINMAX)\n",
        "  hsv[...,0] = cv2.normalize(flow[...,0],None,0,255,cv2.NORM_MINMAX)\n",
        "  hsv[...,2] = cv2.normalize(flow[...,1],None,0,255,cv2.NORM_MINMAX)\n",
        "  # rgb = cv2.cvtColor(hsv,cv2.COLOR_HSV2BGR)\n",
        "  frame1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2RGB)\n",
        "  data = np.zeros((299, 299,5))\n",
        "  data[:, :, 0] = frame1[:, :, 0]\n",
        "  data[:, :, 1] = frame1[:, :, 1]\n",
        "  data[:, :, 2] = frame1[:, :, 2]\n",
        "  data[:, :, 3] = hsv[:, :, 0]\n",
        "  data[:, :, 4] = hsv[:, :, 2]\n",
        "  # normalization\n",
        "  data = np.array(data, dtype=np.float32)  \n",
        "  data /= 127.5\n",
        "  data -= 1.\n",
        "  return data\n",
        "\n",
        "def get_mffs(path1,path2):\n",
        "  frame1 = cv2.imread(path1)\n",
        "  frame1 = cv2.resize(frame1, (299, 299))\n",
        "  prvs = cv2.cvtColor(frame1,cv2.COLOR_BGR2GRAY)\n",
        "  hsv = np.zeros_like(frame1)\n",
        "  hsv[...,1] = 255\n",
        "  frame2 = cv2.imread(path2)\n",
        "  frame2 = cv2.resize(frame2, (299, 299))\n",
        "  next = cv2.cvtColor(frame2,cv2.COLOR_BGR2GRAY)\n",
        "  flow = cv2.calcOpticalFlowFarneback(prvs,next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
        "  # mag, ang = cv2.cartToPolar(flow[...,0], flow[...,1])\n",
        "  # hsv[...,0] = ang*180/np.pi/2\n",
        "  # hsv[...,2] = cv2.normalize(mag,None,0,255,cv2.NORM_MINMAX)\n",
        "  hsv[...,0] = cv2.normalize(flow[...,0],None,0,255,cv2.NORM_MINMAX)\n",
        "  hsv[...,2] = cv2.normalize(flow[...,1],None,0,255,cv2.NORM_MINMAX)\n",
        "  # rgb = cv2.cvtColor(hsv,cv2.COLOR_HSV2BGR)\n",
        "  frame1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2RGB)\n",
        "  data = np.zeros((299, 299,5))\n",
        "  data[:, :, 0] = frame1[:, :, 0]\n",
        "  data[:, :, 1] = frame1[:, :, 1]\n",
        "  data[:, :, 2] = frame1[:, :, 2]\n",
        "  data[:, :, 3] = hsv[:, :, 0]\n",
        "  data[:, :, 4] = hsv[:, :, 2]\n",
        "  # normalization\n",
        "  data = np.array(data, dtype=np.float32)  \n",
        "  data /= 127.5\n",
        "  data -= 1.\n",
        "  return data\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3DahZUHBNeI",
        "colab_type": "text"
      },
      "source": [
        "### 训练图片生成器\n",
        "\n",
        "从训练列表中遍历。yield一个batch的训练图片及其标签。图片经过了实时增强。另外还有50%的概率随机选取另一张同类里的图片，将两张的左右各半边拼接在一起。这也是为了训练模型对分类的关键部位进行学习，而不是记住司机的样子"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbJeF3pDBNeJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define my train data generator\n",
        "\n",
        "def train_gen(batch_size):\n",
        "    #random.shuffle(train_list) # 每一代都随机shuffle训练集\n",
        "    current = 0\n",
        "    while 1:\n",
        "        x = []\n",
        "        y = []\n",
        "        while len(y) < batch_size:\n",
        "            line = train_list[current]\n",
        "            arr = line.strip().split(',')\n",
        "            path1 = os.path.join('.', 'train', str(arr[1]), str(arr[2]))\n",
        "            path3 = os.path.join('.', 'train', str(arr[4]), str(arr[5]))\n",
        "            # img = get_im_cv2_aug(path1, 299)\n",
        "            # img3 = get_im_cv2_aug(path3, 299)\n",
        "            mffs = get_mffs_aug(path1,path3)\n",
        "            # if random.random()>0.5:\n",
        "            #     line2 = random.choice(class_dict[arr[1]])\n",
        "            #     bname = line2.strip().split(',')[2]\n",
        "            #     path2 = os.path.join('.', 'train', str(arr[1]), str(bname))\n",
        "            #     img2 = get_im_cv2_aug(path2, 299)\n",
        "            #     left = img[:, :150, :]\n",
        "            #     right = img2[:, 150:, :]\n",
        "            #     img = np.concatenate((left, right), axis=1)\n",
        "            x.append(mffs)\n",
        "            label = one_hot_encode([str(arr[1])])[0]\n",
        "            y.append(label)\n",
        "            current += 1\n",
        "            if current >= len(train_list):\n",
        "                current = 0\n",
        "        x = np.array(x)\n",
        "        img_size = 299\n",
        "        x = x.reshape(batch_size, img_size, img_size, 5) \n",
        "        y = np.array(y, dtype = np.uint8)\n",
        "        y = y.reshape(batch_size, 10)\n",
        "        yield (x, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOcMcHHUBNeN",
        "colab_type": "text"
      },
      "source": [
        "### 验证图片生成器\n",
        "\n",
        "从验证列表中遍历。yield一个batch的验证图片及其标签。为了体现模型训练后的拟合能力，图片没有进行实时增强。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tp4U8pKTBNeO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define my validation data generator\n",
        "\n",
        "def valid_gen(batch_size):\n",
        "    current = 0\n",
        "    while 1:\n",
        "        x = []\n",
        "        y = []\n",
        "        while len(y) < batch_size:\n",
        "            line = valid_list[current]\n",
        "            arr = line.strip().split(',')\n",
        "            path1 = os.path.join('.', 'train', str(arr[1]), str(arr[2]))\n",
        "            path3 = os.path.join('.', 'train', str(arr[4]), str(arr[5]))\n",
        "            #print (path)\n",
        "            mffs = get_mffs(path1,path3)\n",
        "            x.append(mffs)\n",
        "            label = one_hot_encode([str(arr[1])])[0]\n",
        "            y.append(label)\n",
        "            current += 1\n",
        "            if current >= len(valid_list):\n",
        "                current = 0\n",
        "        x = np.array(x)\n",
        "        img_size = 299\n",
        "        x = x.reshape(batch_size, img_size, img_size, 5) \n",
        "        y = np.array(y, dtype = np.uint8)\n",
        "        y = y.reshape(batch_size, 10)\n",
        "        yield (x, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MClUdfVnGvPz",
        "colab_type": "text"
      },
      "source": [
        "###验证数据类型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5x8HDZLIL2oT",
        "colab_type": "code",
        "outputId": "fb03d77a-95d8-41ec-9690-ff3d3143c27b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "current = 0\n",
        "path = []\n",
        "num_frames=16\n",
        "print(train_list[0])\n",
        "line=train_list[current]\n",
        "arr=line.strip().split(',')\n",
        "path1=os.path.join('.', 'train', str(arr[1]), str(arr[2]))\n",
        "print(path1)\n",
        "path2=os.path.join('.', 'train', str(arr[4]), str(arr[5]))\n",
        "\n",
        "mffs_aug = get_mffs_aug(path1,path2)\n",
        "mffs = get_mffs(path1,path2)\n",
        "print(mffs_aug.shape)\n",
        "print(mffs.shape)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "p061,c5,img_80030.jpg,p061,c5,img_5941.jpg\n",
            "\n",
            "./train/c5/img_80030.jpg\n",
            "(299, 299, 5)\n",
            "(299, 299, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZO3cku2BNeR",
        "colab_type": "text"
      },
      "source": [
        "### 构建模型\n",
        "\n",
        "用keras构建模型。使用在ImageNet上预训练好的Xception模型，接上一个global average pooling层，dropout防止过拟合，最后一个全连接层输出10个类别的概率。在全连接层的权重上采用了L2正则化。锁定模型的前70层不更新权重."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Odj6vyytBNeS",
        "colab_type": "code",
        "outputId": "a0d9b747-af21-4acd-a368-ec45fa785fdb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "from keras import backend as K\n",
        "K.clear_session()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:88: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:91: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:95: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IalNVLcnBNeX",
        "colab_type": "code",
        "outputId": "a2f8d777-c52a-495d-d64f-d056ee063a70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 835
        }
      },
      "source": [
        "# new model\n",
        "\n",
        "from keras.models import *\n",
        "from keras.layers import *\n",
        "from keras.applications import *\n",
        "from keras.preprocessing.image import *\n",
        "\n",
        "# img_size = 297\n",
        "# x = Input((img_size, img_size, 3))\n",
        "# base_model1 = Xception(input_tensor = x, weights='imagenet', include_top=False)\n",
        "# base_model2 = Model(x,base_model1.output)\n",
        "y = Input((299, 299, 5))\n",
        "# y = Conv2D(3,(3,3), strides=(1, 1))(y)\n",
        "# y = BatchNormalization()(y)\n",
        "# m = Activation('relu')(y)\n",
        "base_model = Xception(input_tensor = y, weights='imagenet', include_top=False)\n",
        "m = GlobalAveragePooling2D()(base_model.output)\n",
        "m = Dropout(0.5)(m)\n",
        "m = Dense(10, activation='softmax', kernel_regularizer=regularizers.l2(0.01))(m)\n",
        "model = Model(base_model.input,m)\n",
        "# for i in range(70):\n",
        "#     model.layers[i].trainable = False\n",
        "model.summary()\n",
        "len(model.layers)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:507: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3831: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:167: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:179: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:183: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:192: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:199: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1797: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3655: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.4/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "83689472/83683744 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1606\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1607\u001b[0;31m     \u001b[0mc_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1608\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Dimension 0 in both shapes must be equal, but are 3 and 32. Shapes are [3,3,5,32] and [32,3,3,3]. for 'Assign' (op: 'Assign') with input shapes: [3,3,5,32], [32,3,3,3].",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-cfa5dd1e60f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# y = BatchNormalization()(y)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# m = Activation('relu')(y)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mbase_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'imagenet'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_top\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGlobalAveragePooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/applications/xception.py\u001b[0m in \u001b[0;36mXception\u001b[0;34m(include_top, weights, input_tensor, input_shape, pooling, classes)\u001b[0m\n\u001b[1;32m    261\u001b[0m                                     \u001b[0mcache_subdir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'models'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m                                     file_hash='b0042744bf5b25fce3cb969f33bebb97')\n\u001b[0;32m--> 263\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch, reshape)\u001b[0m\n\u001b[1;32m   2654\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2655\u001b[0m                 load_weights_from_hdf5_group(\n\u001b[0;32m-> 2656\u001b[0;31m                     f, self.layers, reshape=reshape)\n\u001b[0m\u001b[1;32m   2657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2658\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_updated_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group\u001b[0;34m(f, layers, reshape)\u001b[0m\n\u001b[1;32m   3380\u001b[0m                              ' elements.')\n\u001b[1;32m   3381\u001b[0m         \u001b[0mweight_value_tuples\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbolic_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3382\u001b[0;31m     \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_value_tuples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mbatch_set_value\u001b[0;34m(tuples)\u001b[0m\n\u001b[1;32m   2366\u001b[0m                 assign_placeholder = tf.placeholder(tf_dtype,\n\u001b[1;32m   2367\u001b[0m                                                     shape=value.shape)\n\u001b[0;32m-> 2368\u001b[0;31m                 \u001b[0massign_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_placeholder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2369\u001b[0m                 \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assign_placeholder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0massign_placeholder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2370\u001b[0m                 \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assign_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0massign_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/variables.py\u001b[0m in \u001b[0;36massign\u001b[0;34m(self, value, use_locking, name, read_value)\u001b[0m\n\u001b[1;32m   2065\u001b[0m     \"\"\"\n\u001b[1;32m   2066\u001b[0m     assign = state_ops.assign(\n\u001b[0;32m-> 2067\u001b[0;31m         self._variable, value, use_locking=use_locking, name=name)\n\u001b[0m\u001b[1;32m   2068\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mread_value\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2069\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0massign\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/state_ops.py\u001b[0m in \u001b[0;36massign\u001b[0;34m(ref, value, validate_shape, use_locking, name)\u001b[0m\n\u001b[1;32m    225\u001b[0m     return gen_state_ops.assign(\n\u001b[1;32m    226\u001b[0m         \u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_locking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_locking\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m         validate_shape=validate_shape)\n\u001b[0m\u001b[1;32m    228\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_state_ops.py\u001b[0m in \u001b[0;36massign\u001b[0;34m(ref, value, validate_shape, use_locking, name)\u001b[0m\n\u001b[1;32m     64\u001b[0m   _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[1;32m     65\u001b[0m         \u001b[0;34m\"Assign\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                   use_locking=use_locking, name=name)\n\u001b[0m\u001b[1;32m     67\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m   \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    792\u001b[0m         op = g.create_op(op_type_name, inputs, dtypes=None, name=scope,\n\u001b[1;32m    793\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 794\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    795\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m       \u001b[0;31m# Conditionally invoke tfdbg v2's op callback(s).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m                 instructions)\n\u001b[0;32m--> 507\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m     doc = _add_deprecated_arg_notice_to_docstring(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3355\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Input #%d is not a tensor: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3356\u001b[0m     return self._create_op_internal(op_type, inputs, dtypes, input_types, name,\n\u001b[0;32m-> 3357\u001b[0;31m                                     attrs, op_def, compute_device)\n\u001b[0m\u001b[1;32m   3358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3359\u001b[0m   def _create_op_internal(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   3424\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3425\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3426\u001b[0;31m           op_def=op_def)\n\u001b[0m\u001b[1;32m   3427\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3428\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   1768\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[1;32m   1769\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[0;32m-> 1770\u001b[0;31m                                 control_input_ops)\n\u001b[0m\u001b[1;32m   1771\u001b[0m     \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1608\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1609\u001b[0m     \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1610\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1612\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Dimension 0 in both shapes must be equal, but are 3 and 32. Shapes are [3,3,5,32] and [32,3,3,3]. for 'Assign' (op: 'Assign') with input shapes: [3,3,5,32], [32,3,3,3]."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kmgpn5uLeBxg",
        "colab_type": "text"
      },
      "source": [
        "###构建视频预测模型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KG4ZSc50q21B",
        "colab_type": "code",
        "outputId": "221f586c-b7d0-4437-d1ad-9520e31d92a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.models import Model\n",
        "from keras import layers\n",
        "from keras.layers import Dense, Input, BatchNormalization, Activation\n",
        "from keras.layers import Conv2D, SeparableConv2D, MaxPooling2D, GlobalAveragePooling2D, GlobalMaxPooling2D, Dropout\n",
        "from keras.applications.imagenet_utils import _obtain_input_shape\n",
        "from keras.utils.data_utils import get_file\n",
        "\n",
        "# from keras.models import *\n",
        "# from keras.layers import *\n",
        "# from keras.applications import *\n",
        "# from keras.preprocessing.image import *\n",
        "from keras import regularizers\n",
        "\n",
        "WEIGHTS_PATH = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.4/xception_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "\n",
        "def Xception():\n",
        "\n",
        "\t# Determine proper input shape\n",
        "\t# input_shape = _obtain_input_shape(None, default_size=299, min_size=71, data_format='channels_last', include_top=False)\n",
        "  img_size =299\n",
        "  img_input = Input((img_size, img_size, 5))\n",
        "\t# img_input = Input(shape=input_shape)\n",
        "  # x = Conv2D(3,(3,3), strides=(1, 1))(img_input)\n",
        "  # x = BatchNormalization()(x)\n",
        "  # x = Activation('relu')(x)\n",
        "\t# Block 1\n",
        "  x = Conv2D(32, (3, 3), strides=(2, 2), use_bias=False)(img_input)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation('relu')(x)\n",
        "  x = Conv2D(64, (3, 3), use_bias=False)(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation('relu')(x)\n",
        "\n",
        "  residual = Conv2D(128, (1, 1), strides=(2, 2), padding='same', use_bias=False)(x)\n",
        "  residual = BatchNormalization()(residual)\n",
        "\n",
        "  # Block 2\n",
        "  x = SeparableConv2D(128, (3, 3), padding='same', use_bias=False)(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation('relu')(x)\n",
        "  x = SeparableConv2D(128, (3, 3), padding='same', use_bias=False)(x)\n",
        "  x = BatchNormalization()(x)\n",
        "\n",
        "\t# Block 2 Pool\n",
        "  x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
        "  x = layers.add([x, residual])\n",
        "\n",
        "  residual = Conv2D(256, (1, 1), strides=(2, 2), padding='same', use_bias=False)(x)\n",
        "  residual = BatchNormalization()(residual)\n",
        "\n",
        "\t# Block 3\n",
        "  x = Activation('relu')(x)\n",
        "  x = SeparableConv2D(256, (3, 3), padding='same', use_bias=False)(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation('relu')(x)\n",
        "  x = SeparableConv2D(256, (3, 3), padding='same', use_bias=False)(x)\n",
        "  x = BatchNormalization()(x)\n",
        "\n",
        "\t# Block 3 Pool\n",
        "  x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
        "  x = layers.add([x, residual])\n",
        "\n",
        "  residual = Conv2D(728, (1, 1), strides=(2, 2), padding='same', use_bias=False)(x)\n",
        "  residual = BatchNormalization()(residual)\n",
        "\n",
        "\t# Block 4\n",
        "  x = Activation('relu')(x)\n",
        "  x = SeparableConv2D(728, (3, 3), padding='same', use_bias=False)(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation('relu')(x)\n",
        "  x = SeparableConv2D(728, (3, 3), padding='same', use_bias=False)(x)\n",
        "  x = BatchNormalization()(x)\n",
        "\n",
        "  x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
        "  x = layers.add([x, residual])\n",
        "\n",
        "\t# Block 5 - 12\n",
        "  for i in range(8):\n",
        "    residual = x\n",
        "\n",
        "    x = Activation('relu')(x)\n",
        "    x = SeparableConv2D(728, (3, 3), padding='same', use_bias=False)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = SeparableConv2D(728, (3, 3), padding='same', use_bias=False)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = SeparableConv2D(728, (3, 3), padding='same', use_bias=False)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    x = layers.add([x, residual])\n",
        "\n",
        "  residual = Conv2D(1024, (1, 1), strides=(2, 2), padding='same', use_bias=False)(x)\n",
        "  residual = BatchNormalization()(residual)\n",
        "\n",
        "\t# Block 13\n",
        "  x = Activation('relu')(x)\n",
        "  x = SeparableConv2D(728, (3, 3), padding='same', use_bias=False)(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation('relu')(x)\n",
        "  x = SeparableConv2D(1024, (3, 3), padding='same', use_bias=False)(x)\n",
        "  x = BatchNormalization()(x)\n",
        "\n",
        "\t# Block 13 Pool\n",
        "  x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
        "  x = layers.add([x, residual])\n",
        "\n",
        "  # Block 14\n",
        "  x = SeparableConv2D(1536, (3, 3), padding='same', use_bias=False)(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation('relu')(x)\n",
        "\n",
        "\t# Block 14 part 2\n",
        "  x = SeparableConv2D(2048, (3, 3), padding='same', use_bias=False)(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation('relu')(x)\n",
        "\n",
        "\t# Fully Connected Layer\n",
        "  # x = GlobalAveragePooling2D()(x)\n",
        "  # x = Dense(1000, activation='softmax')(x)\n",
        "  x = GlobalAveragePooling2D()(x)\n",
        "  x = Dropout(0.5)(x)\n",
        "  x = Dense(10, activation='softmax', kernel_regularizer=regularizers.l2(0.01))(x)\n",
        "  inputs = img_input\n",
        "\n",
        "\t# Create model\n",
        "  model = Model(inputs, x, name='xception')\n",
        "\n",
        "  # Download and cache the Xception weights file\n",
        "  weights_path = get_file('xception_weights.h5', WEIGHTS_PATH, cache_subdir='models')\n",
        "\n",
        "\t# load weights\n",
        "  # model.load_weights(weights_path, by_name=True)\n",
        "  # model.load_weights('my_model12.h5', by_name=True)\n",
        "  model.load_weights('mffs_model_nolock.h5')\n",
        "  return model\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\tInstantiate the model by using the following line of code\n",
        "\tmodel = Xception()\n",
        "\"\"\"\n",
        "video_model = Xception()\n",
        "# for i in range(42):\n",
        "#     video_model.layers[i].trainable = False\n",
        "video_model.summary()\n",
        "len(video_model.layers)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:507: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3831: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:167: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:179: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:183: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:192: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:199: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1797: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3655: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3138: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.4/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "83689472/83683744 [==============================] - 2s 0us/step\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 299, 299, 5)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 149, 149, 32) 1440        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 149, 149, 32) 128         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 149, 149, 32) 0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 147, 147, 64) 18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 147, 147, 64) 256         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 147, 147, 64) 0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_1 (SeparableCo (None, 147, 147, 128 8768        activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 147, 147, 128 512         separable_conv2d_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 147, 147, 128 0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_2 (SeparableCo (None, 147, 147, 128 17536       activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 147, 147, 128 512         separable_conv2d_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 74, 74, 128)  8192        activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 74, 74, 128)  0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 74, 74, 128)  512         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 74, 74, 128)  0           max_pooling2d_1[0][0]            \n",
            "                                                                 batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 74, 74, 128)  0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_3 (SeparableCo (None, 74, 74, 256)  33920       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 74, 74, 256)  1024        separable_conv2d_3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 74, 74, 256)  0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_4 (SeparableCo (None, 74, 74, 256)  67840       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 74, 74, 256)  1024        separable_conv2d_4[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 37, 37, 256)  32768       add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 37, 37, 256)  0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 37, 37, 256)  1024        conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 37, 37, 256)  0           max_pooling2d_2[0][0]            \n",
            "                                                                 batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 37, 37, 256)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_5 (SeparableCo (None, 37, 37, 728)  188672      activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 37, 37, 728)  2912        separable_conv2d_5[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 37, 37, 728)  0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_6 (SeparableCo (None, 37, 37, 728)  536536      activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 37, 37, 728)  2912        separable_conv2d_6[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 19, 19, 728)  186368      add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 19, 19, 728)  0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 19, 19, 728)  2912        conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 19, 19, 728)  0           max_pooling2d_3[0][0]            \n",
            "                                                                 batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 19, 19, 728)  0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_7 (SeparableCo (None, 19, 19, 728)  536536      activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_7[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 19, 19, 728)  0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_8 (SeparableCo (None, 19, 19, 728)  536536      activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_8[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 19, 19, 728)  0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_9 (SeparableCo (None, 19, 19, 728)  536536      activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_9[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 19, 19, 728)  0           batch_normalization_14[0][0]     \n",
            "                                                                 add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 19, 19, 728)  0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_10 (SeparableC (None, 19, 19, 728)  536536      activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_10[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 19, 19, 728)  0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_11 (SeparableC (None, 19, 19, 728)  536536      activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_11[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 19, 19, 728)  0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_12 (SeparableC (None, 19, 19, 728)  536536      activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_12[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 19, 19, 728)  0           batch_normalization_17[0][0]     \n",
            "                                                                 add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 19, 19, 728)  0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_13 (SeparableC (None, 19, 19, 728)  536536      activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_13[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 19, 19, 728)  0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_14 (SeparableC (None, 19, 19, 728)  536536      activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_14[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 19, 19, 728)  0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_15 (SeparableC (None, 19, 19, 728)  536536      activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_15[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 19, 19, 728)  0           batch_normalization_20[0][0]     \n",
            "                                                                 add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 19, 19, 728)  0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_16 (SeparableC (None, 19, 19, 728)  536536      activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_16[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 19, 19, 728)  0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_17 (SeparableC (None, 19, 19, 728)  536536      activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_17[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 19, 19, 728)  0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_18 (SeparableC (None, 19, 19, 728)  536536      activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_18[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 19, 19, 728)  0           batch_normalization_23[0][0]     \n",
            "                                                                 add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 19, 19, 728)  0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_19 (SeparableC (None, 19, 19, 728)  536536      activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_19[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 19, 19, 728)  0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_20 (SeparableC (None, 19, 19, 728)  536536      activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_20[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 19, 19, 728)  0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_21 (SeparableC (None, 19, 19, 728)  536536      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_21[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 19, 19, 728)  0           batch_normalization_26[0][0]     \n",
            "                                                                 add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 19, 19, 728)  0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_22 (SeparableC (None, 19, 19, 728)  536536      activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_22[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 19, 19, 728)  0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_23 (SeparableC (None, 19, 19, 728)  536536      activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_23[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 19, 19, 728)  0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_24 (SeparableC (None, 19, 19, 728)  536536      activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_24[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 19, 19, 728)  0           batch_normalization_29[0][0]     \n",
            "                                                                 add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 19, 19, 728)  0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_25 (SeparableC (None, 19, 19, 728)  536536      activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_25[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 19, 19, 728)  0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_26 (SeparableC (None, 19, 19, 728)  536536      activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_26[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 19, 19, 728)  0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_27 (SeparableC (None, 19, 19, 728)  536536      activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_27[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 19, 19, 728)  0           batch_normalization_32[0][0]     \n",
            "                                                                 add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 19, 19, 728)  0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_28 (SeparableC (None, 19, 19, 728)  536536      activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_28[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 19, 19, 728)  0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_29 (SeparableC (None, 19, 19, 728)  536536      activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_29[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 19, 19, 728)  0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_30 (SeparableC (None, 19, 19, 728)  536536      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_30[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 19, 19, 728)  0           batch_normalization_35[0][0]     \n",
            "                                                                 add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 19, 19, 728)  0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_31 (SeparableC (None, 19, 19, 728)  536536      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_31[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 19, 19, 728)  0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_32 (SeparableC (None, 19, 19, 1024) 752024      activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 19, 19, 1024) 4096        separable_conv2d_32[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 10, 10, 1024) 745472      add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 10, 10, 1024) 0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 10, 10, 1024) 4096        conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 10, 10, 1024) 0           max_pooling2d_4[0][0]            \n",
            "                                                                 batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_33 (SeparableC (None, 10, 10, 1536) 1582080     add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 10, 10, 1536) 6144        separable_conv2d_33[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 10, 10, 1536) 0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_34 (SeparableC (None, 10, 10, 2048) 3159552     activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 10, 10, 2048) 8192        separable_conv2d_34[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 10, 10, 2048) 0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_1 (Glo (None, 2048)         0           activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 2048)         0           global_average_pooling2d_1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           20490       dropout_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 20,882,546\n",
            "Trainable params: 20,828,018\n",
            "Non-trainable params: 54,528\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "135"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8eAFtLKcr4FO",
        "colab_type": "text"
      },
      "source": [
        "#构建视频预测模型2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "32127e6b-3a68-46c1-c765-361cbaf9b0b5",
        "id": "o4YTSf5zr9xn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.models import Model\n",
        "from keras import layers\n",
        "from keras.layers import Dense, Input, BatchNormalization, Activation\n",
        "from keras.layers import Conv2D, SeparableConv2D, MaxPooling2D, GlobalAveragePooling2D, GlobalMaxPooling2D, Dropout\n",
        "from keras.applications.imagenet_utils import _obtain_input_shape\n",
        "from keras.utils.data_utils import get_file\n",
        "\n",
        "# from keras.models import *\n",
        "# from keras.layers import *\n",
        "# from keras.applications import *\n",
        "# from keras.preprocessing.image import *\n",
        "from keras import regularizers\n",
        "\n",
        "WEIGHTS_PATH = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.4/xception_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "\n",
        "def Xception():\n",
        "\n",
        "\t# Determine proper input shape\n",
        "\t# input_shape = _obtain_input_shape(None, default_size=299, min_size=71, data_format='channels_last', include_top=False)\n",
        "  img_size =299\n",
        "  img_input = Input((img_size, img_size, 5))\n",
        "\t# img_input = Input(shape=input_shape)\n",
        "  # x = Conv2D(3,(3,3), strides=(1, 1))(img_input)\n",
        "  # x = BatchNormalization()(x)\n",
        "  # x = Activation('relu')(x)\n",
        "\t# Block 1\n",
        "  x = Conv2D(32, (3, 3), strides=(2, 2), use_bias=False, kernel_regularizer=regularizers.l2(0.01))(img_input)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation('relu')(x)\n",
        "  x = Conv2D(64, (3, 3), use_bias=False, kernel_regularizer=regularizers.l2(0.01))(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation('relu')(x)\n",
        "\n",
        "  residual = Conv2D(128, (1, 1), strides=(2, 2), padding='same', use_bias=False, kernel_regularizer=regularizers.l2(0.01))(x)\n",
        "  residual = BatchNormalization()(residual)\n",
        "\n",
        "  # Block 2\n",
        "  x = SeparableConv2D(128, (3, 3), padding='same', use_bias=False, kernel_regularizer=regularizers.l2(0.01))(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation('relu')(x)\n",
        "  x = SeparableConv2D(128, (3, 3), padding='same', use_bias=False, kernel_regularizer=regularizers.l2(0.01))(x)\n",
        "  x = BatchNormalization()(x)\n",
        "\n",
        "\t# Block 2 Pool\n",
        "  x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
        "  x = Dropout(0.5)(x)\n",
        "  x = layers.add([x, residual])\n",
        "\n",
        "  residual = Conv2D(256, (1, 1), strides=(2, 2), padding='same', use_bias=False, kernel_regularizer=regularizers.l2(0.01))(x)\n",
        "  residual = BatchNormalization()(residual)\n",
        "\n",
        "\t# Block 3\n",
        "  x = Activation('relu')(x)\n",
        "  x = SeparableConv2D(256, (3, 3), padding='same', use_bias=False, kernel_regularizer=regularizers.l2(0.01))(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation('relu')(x)\n",
        "  x = SeparableConv2D(256, (3, 3), padding='same', use_bias=False, kernel_regularizer=regularizers.l2(0.01))(x)\n",
        "  x = BatchNormalization()(x)\n",
        "\n",
        "\t# Block 3 Pool\n",
        "  x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
        "  x = Dropout(0.5)(x)\n",
        "  x = layers.add([x, residual])\n",
        "\n",
        "  residual = Conv2D(728, (1, 1), strides=(2, 2), padding='same', use_bias=False, kernel_regularizer=regularizers.l2(0.01))(x)\n",
        "  residual = BatchNormalization()(residual)\n",
        "\n",
        "\t# Block 4\n",
        "  x = Activation('relu')(x)\n",
        "  x = SeparableConv2D(728, (3, 3), padding='same', use_bias=False, kernel_regularizer=regularizers.l2(0.01))(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation('relu')(x)\n",
        "  x = SeparableConv2D(728, (3, 3), padding='same', use_bias=False, kernel_regularizer=regularizers.l2(0.01))(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
        "  x = Dropout(0.5)(x)\n",
        "  x = layers.add([x, residual])\n",
        "\n",
        "\t# Block 5 - 12\n",
        "  for i in range(8):\n",
        "    residual = x\n",
        "\n",
        "    x = Activation('relu')(x)\n",
        "    x = SeparableConv2D(728, (3, 3), padding='same', use_bias=False, kernel_regularizer=regularizers.l2(0.01))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = SeparableConv2D(728, (3, 3), padding='same', use_bias=False, kernel_regularizer=regularizers.l2(0.01))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = SeparableConv2D(728, (3, 3), padding='same', use_bias=False, kernel_regularizer=regularizers.l2(0.01))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = layers.add([x, residual])\n",
        "\n",
        "  residual = Conv2D(1024, (1, 1), strides=(2, 2), padding='same', use_bias=False, kernel_regularizer=regularizers.l2(0.01))(x)\n",
        "  residual = BatchNormalization()(residual)\n",
        "\n",
        "\t# Block 13\n",
        "  x = Activation('relu')(x)\n",
        "  x = SeparableConv2D(728, (3, 3), padding='same', use_bias=False, kernel_regularizer=regularizers.l2(0.01))(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation('relu')(x)\n",
        "  x = SeparableConv2D(1024, (3, 3), padding='same', use_bias=False, kernel_regularizer=regularizers.l2(0.01))(x)\n",
        "  x = BatchNormalization()(x)\n",
        "\n",
        "\t# Block 13 Pool\n",
        "  x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
        "  x = Dropout(0.5)(x)\n",
        "  x = layers.add([x, residual])\n",
        "\n",
        "  # Block 14\n",
        "  x = SeparableConv2D(1536, (3, 3), padding='same', use_bias=False, kernel_regularizer=regularizers.l2(0.01))(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation('relu')(x)\n",
        "\n",
        "\t# Block 14 part 2\n",
        "  x = SeparableConv2D(2048, (3, 3), padding='same', use_bias=False, kernel_regularizer=regularizers.l2(0.01))(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation('relu')(x)\n",
        "\n",
        "\t# Fully Connected Layer\n",
        "  # x = GlobalAveragePooling2D()(x)\n",
        "  # x = Dense(1000, activation='softmax')(x)\n",
        "  x = GlobalAveragePooling2D()(x)\n",
        "  x = Dropout(0.5)(x)\n",
        "  x = Dense(10, activation='softmax', kernel_regularizer=regularizers.l2(0.01))(x)\n",
        "  inputs = img_input\n",
        "\n",
        "\t# Create model\n",
        "  model = Model(inputs, x, name='xception')\n",
        "\n",
        "  # Download and cache the Xception weights file\n",
        "  # weights_path = get_file('xception_weights.h5', WEIGHTS_PATH, cache_subdir='models')\n",
        "\n",
        "\t# load weights\n",
        "  # model.load_weights(weights_path, by_name=True)\n",
        "  # model.load_weights('my_model12.h5', by_name=True)\n",
        "  model.load_weights('mffs_model_nolock.h5')\n",
        "  return model\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\tInstantiate the model by using the following line of code\n",
        "\tmodel = Xception()\n",
        "\"\"\"\n",
        "video_model = Xception()\n",
        "# for i in range(42):\n",
        "#     video_model.layers[i].trainable = False\n",
        "video_model.summary()\n",
        "len(video_model.layers)\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            (None, 299, 299, 5)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 149, 149, 32) 1440        input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 149, 149, 32) 128         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 149, 149, 32) 0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 147, 147, 64) 18432       activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 147, 147, 64) 256         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 147, 147, 64) 0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_35 (SeparableC (None, 147, 147, 128 8768        activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 147, 147, 128 512         separable_conv2d_35[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 147, 147, 128 0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_36 (SeparableC (None, 147, 147, 128 17536       activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 147, 147, 128 512         separable_conv2d_36[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2D)  (None, 74, 74, 128)  0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 74, 74, 128)  8192        activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 74, 74, 128)  0           max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 74, 74, 128)  512         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 74, 74, 128)  0           dropout_6[0][0]                  \n",
            "                                                                 batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 74, 74, 128)  0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_37 (SeparableC (None, 74, 74, 256)  33920       activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 74, 74, 256)  1024        separable_conv2d_37[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 74, 74, 256)  0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_38 (SeparableC (None, 74, 74, 256)  67840       activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 74, 74, 256)  1024        separable_conv2d_38[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2D)  (None, 37, 37, 256)  0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 37, 37, 256)  32768       add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 37, 37, 256)  0           max_pooling2d_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 37, 37, 256)  1024        conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 37, 37, 256)  0           dropout_7[0][0]                  \n",
            "                                                                 batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 37, 37, 256)  0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_39 (SeparableC (None, 37, 37, 728)  188672      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 37, 37, 728)  2912        separable_conv2d_39[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 37, 37, 728)  0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_40 (SeparableC (None, 37, 37, 728)  536536      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 37, 37, 728)  2912        separable_conv2d_40[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2D)  (None, 19, 19, 728)  0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 19, 19, 728)  186368      add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_8 (Dropout)             (None, 19, 19, 728)  0           max_pooling2d_7[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 19, 19, 728)  2912        conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 19, 19, 728)  0           dropout_8[0][0]                  \n",
            "                                                                 batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 19, 19, 728)  0           add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_41 (SeparableC (None, 19, 19, 728)  536536      activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_41[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 19, 19, 728)  0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_42 (SeparableC (None, 19, 19, 728)  536536      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_42[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 19, 19, 728)  0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_43 (SeparableC (None, 19, 19, 728)  536536      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_43[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, 19, 19, 728)  0           batch_normalization_54[0][0]     \n",
            "                                                                 add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 19, 19, 728)  0           add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_44 (SeparableC (None, 19, 19, 728)  536536      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_44[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 19, 19, 728)  0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_45 (SeparableC (None, 19, 19, 728)  536536      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_45[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 19, 19, 728)  0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_46 (SeparableC (None, 19, 19, 728)  536536      activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_46[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "add_17 (Add)                    (None, 19, 19, 728)  0           batch_normalization_57[0][0]     \n",
            "                                                                 add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 19, 19, 728)  0           add_17[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_47 (SeparableC (None, 19, 19, 728)  536536      activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_47[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 19, 19, 728)  0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_48 (SeparableC (None, 19, 19, 728)  536536      activation_50[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_48[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 19, 19, 728)  0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_49 (SeparableC (None, 19, 19, 728)  536536      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_49[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "add_18 (Add)                    (None, 19, 19, 728)  0           batch_normalization_60[0][0]     \n",
            "                                                                 add_17[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 19, 19, 728)  0           add_18[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_50 (SeparableC (None, 19, 19, 728)  536536      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_50[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 19, 19, 728)  0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_51 (SeparableC (None, 19, 19, 728)  536536      activation_53[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_51[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 19, 19, 728)  0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_52 (SeparableC (None, 19, 19, 728)  536536      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_52[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "add_19 (Add)                    (None, 19, 19, 728)  0           batch_normalization_63[0][0]     \n",
            "                                                                 add_18[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 19, 19, 728)  0           add_19[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_53 (SeparableC (None, 19, 19, 728)  536536      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_53[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 19, 19, 728)  0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_54 (SeparableC (None, 19, 19, 728)  536536      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_54[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 19, 19, 728)  0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_55 (SeparableC (None, 19, 19, 728)  536536      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_55[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "add_20 (Add)                    (None, 19, 19, 728)  0           batch_normalization_66[0][0]     \n",
            "                                                                 add_19[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 19, 19, 728)  0           add_20[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_56 (SeparableC (None, 19, 19, 728)  536536      activation_58[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_56[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 19, 19, 728)  0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_57 (SeparableC (None, 19, 19, 728)  536536      activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_57[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 19, 19, 728)  0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_58 (SeparableC (None, 19, 19, 728)  536536      activation_60[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_58[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "add_21 (Add)                    (None, 19, 19, 728)  0           batch_normalization_69[0][0]     \n",
            "                                                                 add_20[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 19, 19, 728)  0           add_21[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_59 (SeparableC (None, 19, 19, 728)  536536      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_59[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 19, 19, 728)  0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_60 (SeparableC (None, 19, 19, 728)  536536      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_60[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 19, 19, 728)  0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_61 (SeparableC (None, 19, 19, 728)  536536      activation_63[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_61[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "add_22 (Add)                    (None, 19, 19, 728)  0           batch_normalization_72[0][0]     \n",
            "                                                                 add_21[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 19, 19, 728)  0           add_22[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_62 (SeparableC (None, 19, 19, 728)  536536      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_62[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 19, 19, 728)  0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_63 (SeparableC (None, 19, 19, 728)  536536      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_63[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 19, 19, 728)  0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_64 (SeparableC (None, 19, 19, 728)  536536      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_64[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "add_23 (Add)                    (None, 19, 19, 728)  0           batch_normalization_75[0][0]     \n",
            "                                                                 add_22[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 19, 19, 728)  0           add_23[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_65 (SeparableC (None, 19, 19, 728)  536536      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_65[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 19, 19, 728)  0           batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_66 (SeparableC (None, 19, 19, 1024) 752024      activation_68[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 19, 19, 1024) 4096        separable_conv2d_66[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2D)  (None, 10, 10, 1024) 0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 10, 10, 1024) 745472      add_23[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_9 (Dropout)             (None, 10, 10, 1024) 0           max_pooling2d_8[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 10, 10, 1024) 4096        conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_24 (Add)                    (None, 10, 10, 1024) 0           dropout_9[0][0]                  \n",
            "                                                                 batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_67 (SeparableC (None, 10, 10, 1536) 1582080     add_24[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 10, 10, 1536) 6144        separable_conv2d_67[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 10, 10, 1536) 0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_68 (SeparableC (None, 10, 10, 2048) 3159552     activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 10, 10, 2048) 8192        separable_conv2d_68[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 10, 10, 2048) 0           batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_2 (Glo (None, 2048)         0           activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_10 (Dropout)            (None, 2048)         0           global_average_pooling2d_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 10)           20490       dropout_10[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 20,882,546\n",
            "Trainable params: 20,828,018\n",
            "Non-trainable params: 54,528\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "139"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_oPa9HyBNeb",
        "colab_type": "text"
      },
      "source": [
        "### 训练\n",
        "进行模型训练。这里batch size为64。用了自适应优化器Nadam，使用schedule learning rate自动调整学习率的方法并在验证loss不下降时early stopping。一共训练5代，最后的验证集loss仍然有下降空间。steps per epoch设定为在一个epoch内所有训练图片被遍历1次."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cw7pUr7tBNec",
        "colab_type": "code",
        "outputId": "f02d1431-8e86-4be7-e222-e12aa87943f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        }
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler\n",
        "video_model.compile(optimizer=Nadam(),loss='categorical_crossentropy',metrics=['categorical_accuracy'])\n",
        "\n",
        "def learning_rate(epoch):\n",
        "    ini_lr = 0.002\n",
        "    lr = ini_lr * pow(10, -epoch)\n",
        "    return lr\n",
        "\n",
        "cp = ModelCheckpoint(filepath=\"mffs_model_nolock.h5\", save_best_only=True)\n",
        "es = EarlyStopping()\n",
        "lrs = LearningRateScheduler(learning_rate)\n",
        "# hist = video_model.fit_generator(train_gen(32), steps_per_epoch = 572, epochs = 5, workers=4, max_q_size=20, use_multiprocessing=True, validation_data = valid_gen(32), validation_steps = 104, callbacks=[cp, es, lrs])\n",
        "hist = video_model.fit_generator(train_gen(32), steps_per_epoch = 572, epochs = 5, workers=4, max_q_size=20, use_multiprocessing=True, validation_data = valid_gen(32), validation_steps = 104, callbacks=[cp, es, lrs])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:757: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3008: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., steps_per_epoch=572, epochs=5, workers=4, use_multiprocessing=True, validation_data=<generator..., validation_steps=104, callbacks=[<keras.ca..., max_queue_size=20)`\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:976: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:963: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:2087: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
            "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "571/572 [============================>.] - ETA: 3s - loss: 3.7535 - categorical_accuracy: 0.8611"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:2330: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
            "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r572/572 [==============================] - 2505s 4s/step - loss: 3.7480 - categorical_accuracy: 0.8612 - val_loss: 5.1856 - val_categorical_accuracy: 0.2885\n",
            "Epoch 2/5\n",
            "572/572 [==============================] - 2210s 4s/step - loss: 0.5464 - categorical_accuracy: 0.8991 - val_loss: 2.8466 - val_categorical_accuracy: 0.3462\n",
            "Epoch 3/5\n",
            "572/572 [==============================] - 2158s 4s/step - loss: 0.4445 - categorical_accuracy: 0.9144 - val_loss: 2.8989 - val_categorical_accuracy: 0.3498\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VAHzyngJBNeg",
        "colab_type": "text"
      },
      "source": [
        "### 模型结果\n",
        "\n",
        "保存模型。输出history数据，观察loss曲线。 这里忘记设置inline，没有显示曲线。从数据来看验证集loss明显降低，分类精度提高。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ninxLSeRbGz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "print (hist.history)\n",
        "plt.figure(1)\n",
        "plt.plot (hist.history['loss'],label='loss')\n",
        "plt.plot (hist.history['val_loss'], label='val_loss')\n",
        "plt.legend(bbox_to_anchor=(1,1),#图例边界框起始位置\n",
        "                 loc=\"upper right\",#图例的位置\n",
        "                 ncol=1,#列数\n",
        "                 mode=\"None\",#当值设置为“expend”时，图例会水平扩展至整个坐标轴区域\n",
        "                 borderaxespad=0,#坐标轴和图例边界之间的间距\n",
        "                 shadow=False,#是否为线框添加阴影\n",
        "                 fancybox=True)#线框圆角处理参数\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BEbJHCwLpxg9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(2)\n",
        "plt.plot (hist.history['categorical_accuracy'], label='categorical_accuracy')\n",
        "plt.plot (hist.history['val_categorical_accuracy'], label='val_categorical_accuracy')\n",
        "plt.legend(bbox_to_anchor=(1,0),#图例边界框起始位置\n",
        "                 loc=\"lower right\",#图例的位置\n",
        "                 ncol=1,#列数\n",
        "                 mode=\"expend\",#当值设置为“expend”时，图例会水平扩展至整个坐标轴区域\n",
        "                 borderaxespad=0,#坐标轴和图例边界之间的间距\n",
        "                 shadow=False,#是否为线框添加阴影\n",
        "                 fancybox=True)#线框圆角处理参数\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
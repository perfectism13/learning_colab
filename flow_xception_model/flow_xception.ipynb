{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.4"
    },
    "colab": {
      "name": "flow_xception.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/perfectism13/learning_colab/blob/master/flow_xception_model/flow_xception.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXEPJB3tNRfJ",
        "colab_type": "text"
      },
      "source": [
        "###挂载google drive和导入库"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5npKCNyvhnF",
        "colab_type": "code",
        "outputId": "e612792e-b1cd-4ec3-930f-09b1715f4fad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 777
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os\n",
        "os.chdir(r'/content/drive/My Drive/data/imgs/')\n",
        "print(os.getcwd())\n",
        "!ls\n",
        "!pip install keras==2.1.5\n",
        "import keras\n",
        "print(keras.__version__)\n",
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/My Drive/data/imgs\n",
            "'(1-726)clean.mp4'\t        my_model12.h5\n",
            "'(1-726).mp4'\t\t        my_model13.h5\n",
            "'（726-800)clean.mp4'\t        my_model1.h5\n",
            " （726-800）.mp4\t        my_model9.h5\n",
            "'(726-966)clean.mp4'\t        sample_submission.csv\n",
            "'(726-966).mp4'\t\t        test\n",
            " driver_imgs_list_class_2.csv   train\n",
            " driver_imgs_list_class.csv     valid\n",
            " driver_imgs_list.csv\t        vect\n",
            " driver_imgs_list_right.csv     video_model_change_vd_data_aug.h5\n",
            " flow_xception.h5\t        video_model_change_vd_data_aug_modified.h5\n",
            " my_model10.h5\t\t        video_model_change_vd.h5\n",
            " my_model11.h5\t\t        video_model.h5\n",
            "Requirement already satisfied: keras==2.1.5 in /usr/local/lib/python3.6/dist-packages (2.1.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.1.5) (3.13)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.1.5) (1.12.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.1.5) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.1.5) (1.17.5)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "2.1.5\n",
            "Sat Feb  8 08:40:38 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.48.02    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   55C    P8    10W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwdUnNY5BNc_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.environ['KERAS_BACKEND']='tensorflow'\n",
        "import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHt6FC_zBNdG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "np.random.seed(2017)\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import cv2\n",
        "import math\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.pooling import MaxPooling2D\n",
        "from keras.optimizers import SGD, Adam, Nadam\n",
        "from keras.utils import np_utils\n",
        "from keras.models import model_from_json\n",
        "from sklearn.metrics import log_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUSMqWoRBNd4",
        "colab_type": "text"
      },
      "source": [
        "### 切分数据\n",
        "按照司机的id来切分训练数据集。把driver_imgs_list分成两个列表。一个是训练列表，里面是所有训练集司机的图片文件名。另一个是验证列表，里面是所有验证集司机的图片文件名。然后把两个列表都随机打乱。 这里列表里面保存的都只是excel文件里的一行行数据（包括文件名，分类，司机id），而不是图片本身。等训练时通过生成器读取图片，这样节约内存。 另外还保存了一个类别字典，便于以后从同一类中抽取图片进行拼接。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYofeN2LBNd5",
        "colab_type": "code",
        "outputId": "685e7538-215e-4fe3-d688-cbd72eb2d03a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# divide drivers\n",
        "# unique_list_train = ['p002', 'p012', 'p014', 'p015', 'p026', 'p035', 'p039', 'p041', 'p042', 'p045', 'p047', 'p049', 'p050', 'p051', 'p052', 'p056', 'p061', 'p064', 'p066', 'p072', 'p075']\n",
        "# unique_list_valid = ['p016', 'p021', 'p022', 'p024']\n",
        "unique_list_train = ['p016', 'p021', 'p022', 'p024', 'p026', 'p035', 'p039', 'p041', 'p042', 'p045', 'p047', 'p049', 'p050', 'p051', 'p052', 'p056', 'p061', 'p064', 'p066', 'p072', 'p075']\n",
        "unique_list_valid = ['p002', 'p012', 'p014', 'p015']\n",
        "#print (unique_list_train, unique_list_valid)\n",
        "\n",
        "# get index: driver_id, class, image name\n",
        "index = os.path.join('.', 'driver_imgs_list_class_2.csv')\n",
        "\n",
        "# build the driver id dictionary and class dictionary\n",
        "f = open(index, 'r')\n",
        "id_dict = dict()\n",
        "class_dict = dict()\n",
        "lines = f.readlines()\n",
        "# for line in lines[1:]:\n",
        "#     arr = line.strip().split(',')\n",
        "#     if arr[0] not in id_dict.keys():\n",
        "#         id_dict[arr[0]] = [line]\n",
        "#     else:\n",
        "#         id_dict[arr[0]].append(line)\n",
        "#     if arr[1] not in class_dict.keys():\n",
        "#         class_dict[arr[1]] = [line]\n",
        "#     else:\n",
        "#         class_dict[arr[1]].append(line)\n",
        "# f.close()\n",
        "\n",
        "# split the train list and valid list by id\n",
        "train_list = []\n",
        "valid_list = []\n",
        "# for id in id_dict.keys():\n",
        "#     if id in unique_list_train:\n",
        "#         train_list.extend(id_dict[id])\n",
        "#     elif id in unique_list_valid:\n",
        "#         valid_list.extend(id_dict[id])\n",
        "\n",
        "# for cla in class_dict.keys():\n",
        "#   for id in id_dict.keys():\n",
        "#     if id in unique_list_train:\n",
        "#         train_list.extend(class_dict[cla])\n",
        "#     elif id in unique_list_valid:\n",
        "#         valid_list.extend(class_dict[cla])\n",
        "for line in lines[1:]:\n",
        "    arr = line.strip().split(',')\n",
        "    if arr[0]  in unique_list_train:\n",
        "        train_list.append(line)\n",
        "    elif arr[0]  in unique_list_valid:\n",
        "      valid_list.append(line)\n",
        "f.close()\n",
        "\n",
        "random.shuffle(train_list)\n",
        "random.shuffle(valid_list)\n",
        "\n",
        "print (len(train_list), len(valid_list))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18302 3299\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsnPujySBNd8",
        "colab_type": "text"
      },
      "source": [
        "### 获取test set图片的列表\n",
        "获取sample_submission.csv中所有测试图片的文件名，预测test set时使用。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzUKzBnjBNd9",
        "colab_type": "code",
        "outputId": "dd1060c0-6cb3-4659-9bd4-a1e1cac91970",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "test_index = os.path.join('.', 'sample_submission.csv')\n",
        "f = open(test_index, 'r')\n",
        "lines = f.readlines()\n",
        "test_list = []\n",
        "for line in lines[1:]:\n",
        "    arr = line.strip().split(',')\n",
        "    test_list.append(arr[0])\n",
        "f.close()\n",
        "print (test_list[:5])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['img_1.jpg', 'img_10.jpg', 'img_100.jpg', 'img_1000.jpg', 'img_100000.jpg']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nl_N2noABNeB",
        "colab_type": "text"
      },
      "source": [
        "### 转换为One Hot Encode标签\n",
        "\n",
        "对分类标签进行One Hot Encode的函数如下。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18IjONecBNeC",
        "colab_type": "code",
        "outputId": "dd8f44b8-6138-486e-c5bf-54b4c20ee08b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# one hot encode the class label\n",
        "\n",
        "from sklearn import preprocessing\n",
        "lb = preprocessing.LabelBinarizer()\n",
        "lb.fit(['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9'])   \n",
        "def one_hot_encode(x):\n",
        "    return lb.transform(x)\n",
        "t = one_hot_encode(['c1', 'c2'])\n",
        "print(t)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 1 0 0 0 0 0 0 0 0]\n",
            " [0 0 1 0 0 0 0 0 0 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ibx_qljQNDUj",
        "colab_type": "text"
      },
      "source": [
        "###获取光流"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8PFfA43bJs1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import cv2\n",
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "\n",
        "# image rotation\n",
        "def rotate(x1,x2, degree, row_axis=0, col_axis=1, channel_axis=2, fill_mode='wrap', cval=0.):\n",
        "    theta = np.pi / 180 * degree\n",
        "    rotation_matrix = np.array([[np.cos(theta), -np.sin(theta), 0],\n",
        "    [np.sin(theta), np.cos(theta), 0],\n",
        "    [0, 0, 1]])\n",
        "    h, w = x1.shape[row_axis], x1.shape[col_axis]\n",
        "    transform_matrix = image.transform_matrix_offset_center(rotation_matrix, h, w)\n",
        "    x1 = image.apply_transform(x1, transform_matrix, channel_axis, fill_mode, cval)\n",
        "    x2 = image.apply_transform(x2, transform_matrix, channel_axis, fill_mode, cval)\n",
        "    return x1,x2\n",
        "\n",
        "# image shift\n",
        "def shift(x1,x2, wshift, hshift, row_axis=0, col_axis=1, channel_axis=2, fill_mode='wrap', cval=0.):\n",
        "    h, w = x1.shape[row_axis], x1.shape[col_axis] #读取图片的高和宽\n",
        "    tx = hshift * h #高偏移大小，若不偏移可设为0，若向上偏移设为正数\n",
        "    ty = wshift * w #宽偏移大小，若不偏移可设为0，若向左偏移设为正数\n",
        "    translation_matrix = np.array([[1, 0, tx],\n",
        "                                  [0, 1, ty],\n",
        "                                  [0, 0, 1]])\n",
        "    transform_matrix = translation_matrix  \n",
        "    x1 = image.apply_transform(x1, transform_matrix, channel_axis, fill_mode, cval)\n",
        "    x2 = image.apply_transform(x1, transform_matrix, channel_axis, fill_mode, cval)\n",
        "    return x1,x2\n",
        "\n",
        "def get_flow_aug(path1,path2):\n",
        "  frame1 = cv2.imread(path1)\n",
        "  frame1 = cv2.resize(frame1, (299, 299))\n",
        "  prvs = cv2.cvtColor(frame1,cv2.COLOR_BGR2GRAY)\n",
        "  hsv = np.zeros_like(frame1)\n",
        "  hsv[...,2] = 255\n",
        "  frame2 = cv2.imread(path2)\n",
        "  frame2 = cv2.resize(frame2, (299, 299))\n",
        "  #random rotate\n",
        "  deg = random.uniform(-10, 10) #random rotate limit\n",
        "  frame1,frame2 = rotate(frame1,frame2, deg)\n",
        "  #random shift\n",
        "  wshift = random.uniform(-0.1, 0.1)\n",
        "  hshift = random.uniform(-0.1, 0.1)\n",
        "  frame1,frame2 = shift(frame1,frame2, wshift, hshift)\n",
        "  next = cv2.cvtColor(frame2,cv2.COLOR_BGR2GRAY)\n",
        "  flow = cv2.calcOpticalFlowFarneback(prvs,next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
        "  mag, ang = cv2.cartToPolar(flow[...,0], flow[...,1])\n",
        "  hsv[...,0] = ang*180/np.pi/2\n",
        "  hsv[...,1] = cv2.normalize(mag,None,0,255,cv2.NORM_MINMAX)\n",
        "  flow = cv2.cvtColor(hsv,cv2.COLOR_HSV2RGB)\n",
        "  # normalization\n",
        "  flow = np.array(hsv, dtype=np.float32)  \n",
        "  flow /= 127.5\n",
        "  flow -= 1.\n",
        "  return flow\n",
        "\n",
        "def get_flow(path1,path2):\n",
        "  frame1 = cv2.imread(path1)\n",
        "  frame1 = cv2.resize(frame1, (299, 299))\n",
        "  prvs = cv2.cvtColor(frame1,cv2.COLOR_BGR2GRAY)\n",
        "  hsv = np.zeros_like(frame1)\n",
        "  hsv[...,2] = 255\n",
        "  frame2 = cv2.imread(path2)\n",
        "  frame2 = cv2.resize(frame2, (299, 299))\n",
        "  next = cv2.cvtColor(frame2,cv2.COLOR_BGR2GRAY)\n",
        "  flow = cv2.calcOpticalFlowFarneback(prvs,next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
        "  mag, ang = cv2.cartToPolar(flow[...,0], flow[...,1])\n",
        "  hsv[...,0] = ang*180/np.pi/2\n",
        "  hsv[...,1] = cv2.normalize(mag,None,0,255,cv2.NORM_MINMAX)\n",
        "  flow = cv2.cvtColor(hsv,cv2.COLOR_HSV2RGB)\n",
        "  # normalization\n",
        "  flow = np.array(flow, dtype=np.float32)  \n",
        "  flow /= 127.5\n",
        "  flow -= 1.\n",
        "  return flow\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3DahZUHBNeI",
        "colab_type": "text"
      },
      "source": [
        "### 训练图片生成器\n",
        "\n",
        "从训练列表中遍历。yield一个batch的训练图片及其标签。图片经过了实时增强。另外还有50%的概率随机选取另一张同类里的图片，将两张的左右各半边拼接在一起。这也是为了训练模型对分类的关键部位进行学习，而不是记住司机的样子"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbJeF3pDBNeJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define my train data generator\n",
        "\n",
        "def train_gen(batch_size):\n",
        "    #random.shuffle(train_list) # 每一代都随机shuffle训练集\n",
        "    current = 0\n",
        "    while 1:\n",
        "        x = []\n",
        "        y = []\n",
        "        while len(y) < batch_size:\n",
        "            line = train_list[current]\n",
        "            arr = line.strip().split(',')\n",
        "            path1 = os.path.join('.', 'train', str(arr[1]), str(arr[2]))\n",
        "            path3 = os.path.join('.', 'train', str(arr[4]), str(arr[5]))\n",
        "            # img = get_im_cv2_aug(path1, 299)\n",
        "            # img3 = get_im_cv2_aug(path3, 299)\n",
        "            mffs = get_flow_aug(path1,path3)\n",
        "            # if random.random()>0.5:\n",
        "            #     line2 = random.choice(class_dict[arr[1]])\n",
        "            #     bname = line2.strip().split(',')[2]\n",
        "            #     path2 = os.path.join('.', 'train', str(arr[1]), str(bname))\n",
        "            #     img2 = get_im_cv2_aug(path2, 299)\n",
        "            #     left = img[:, :150, :]\n",
        "            #     right = img2[:, 150:, :]\n",
        "            #     img = np.concatenate((left, right), axis=1)\n",
        "            x.append(mffs)\n",
        "            label = one_hot_encode([str(arr[1])])[0]\n",
        "            y.append(label)\n",
        "            current += 1\n",
        "            if current+1 >= len(train_list):\n",
        "                current = 0\n",
        "        x = np.array(x)\n",
        "        img_size = 299\n",
        "        x = x.reshape(batch_size, img_size, img_size, 3) \n",
        "        y = np.array(y, dtype = np.uint8)\n",
        "        y = y.reshape(batch_size, 10)\n",
        "\n",
        "        yield (x, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOcMcHHUBNeN",
        "colab_type": "text"
      },
      "source": [
        "### 验证图片生成器\n",
        "\n",
        "从验证列表中遍历。yield一个batch的验证图片及其标签。为了体现模型训练后的拟合能力，图片没有进行实时增强。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tp4U8pKTBNeO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define my validation data generator\n",
        "\n",
        "def valid_gen(batch_size):\n",
        "    current = 0\n",
        "    while 1:\n",
        "        x = []\n",
        "        y = []\n",
        "        while len(y) < batch_size:\n",
        "            line = train_list[current]\n",
        "            arr = line.strip().split(',')\n",
        "            path1 = os.path.join('.', 'train', str(arr[1]), str(arr[2]))\n",
        "            path3 = os.path.join('.', 'train', str(arr[4]), str(arr[5]))\n",
        "            #print (path)\n",
        "            mffs = get_flow(path1,path3)\n",
        "            x.append(mffs)\n",
        "            label = one_hot_encode([str(arr[1])])[0]\n",
        "            y.append(label)\n",
        "            current += 1\n",
        "            if current+1 >= len(valid_list):\n",
        "                current = 0\n",
        "        x = np.array(x)\n",
        "        img_size = 299\n",
        "        x = x.reshape(batch_size, img_size, img_size, 3) \n",
        "        y = np.array(y, dtype = np.uint8)\n",
        "        y = y.reshape(batch_size, 10)\n",
        "        yield (x, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZO3cku2BNeR",
        "colab_type": "text"
      },
      "source": [
        "### 构建模型\n",
        "\n",
        "用keras构建模型。使用在ImageNet上预训练好的Xception模型，接上一个global average pooling层，dropout防止过拟合，最后一个全连接层输出10个类别的概率。在全连接层的权重上采用了L2正则化。锁定模型的前70层不更新权重."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Odj6vyytBNeS",
        "colab_type": "code",
        "outputId": "062a940a-e9e9-4a45-813a-610817f240c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "from keras import backend as K\n",
        "K.clear_session()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:88: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:91: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:95: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IalNVLcnBNeX",
        "colab_type": "code",
        "outputId": "6f4c1b8d-cdcd-4f99-a792-168f434f3f2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# new model\n",
        "\n",
        "from keras.models import *\n",
        "from keras.layers import *\n",
        "from keras.applications import *\n",
        "from keras.preprocessing.image import *\n",
        "\n",
        "img_size = 299\n",
        "x = Input((img_size, img_size, 3))\n",
        "base_model = Xception(input_tensor = x, weights='imagenet', include_top=False)\n",
        "\n",
        "\n",
        "x = GlobalAveragePooling2D()(base_model.output)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(10, activation='softmax', kernel_regularizer=regularizers.l2(0.01))(x)\n",
        "model = Model(base_model.input, x)\n",
        "\n",
        "model.load_weights('flow_xception.h5')\n",
        "for i in range(70):\n",
        "    model.layers[i].trainable = False\n",
        "    \n",
        "model.summary()\n",
        "len(model.layers)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:507: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3831: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:167: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:179: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:183: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:192: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:199: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1797: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3655: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3138: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 299, 299, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1 (Conv2D)           (None, 149, 149, 32) 864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1_bn (BatchNormaliza (None, 149, 149, 32) 128         block1_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1_act (Activation)   (None, 149, 149, 32) 0           block1_conv1_bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2 (Conv2D)           (None, 147, 147, 64) 18432       block1_conv1_act[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2_bn (BatchNormaliza (None, 147, 147, 64) 256         block1_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2_act (Activation)   (None, 147, 147, 64) 0           block1_conv2_bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv1 (SeparableConv2 (None, 147, 147, 128 8768        block1_conv2_act[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv1_bn (BatchNormal (None, 147, 147, 128 512         block2_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv2_act (Activation (None, 147, 147, 128 0           block2_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv2 (SeparableConv2 (None, 147, 147, 128 17536       block2_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv2_bn (BatchNormal (None, 147, 147, 128 512         block2_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 74, 74, 128)  8192        block1_conv2_act[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block2_pool (MaxPooling2D)      (None, 74, 74, 128)  0           block2_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 74, 74, 128)  512         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 74, 74, 128)  0           block2_pool[0][0]                \n",
            "                                                                 batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv1_act (Activation (None, 74, 74, 128)  0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv1 (SeparableConv2 (None, 74, 74, 256)  33920       block3_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv1_bn (BatchNormal (None, 74, 74, 256)  1024        block3_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv2_act (Activation (None, 74, 74, 256)  0           block3_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv2 (SeparableConv2 (None, 74, 74, 256)  67840       block3_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv2_bn (BatchNormal (None, 74, 74, 256)  1024        block3_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 37, 37, 256)  32768       add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block3_pool (MaxPooling2D)      (None, 37, 37, 256)  0           block3_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 37, 37, 256)  1024        conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 37, 37, 256)  0           block3_pool[0][0]                \n",
            "                                                                 batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv1_act (Activation (None, 37, 37, 256)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv1 (SeparableConv2 (None, 37, 37, 728)  188672      block4_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv1_bn (BatchNormal (None, 37, 37, 728)  2912        block4_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv2_act (Activation (None, 37, 37, 728)  0           block4_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv2 (SeparableConv2 (None, 37, 37, 728)  536536      block4_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv2_bn (BatchNormal (None, 37, 37, 728)  2912        block4_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 19, 19, 728)  186368      add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block4_pool (MaxPooling2D)      (None, 19, 19, 728)  0           block4_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 19, 19, 728)  2912        conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 19, 19, 728)  0           block4_pool[0][0]                \n",
            "                                                                 batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv1_act (Activation (None, 19, 19, 728)  0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block5_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block5_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv2_act (Activation (None, 19, 19, 728)  0           block5_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block5_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block5_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv3_act (Activation (None, 19, 19, 728)  0           block5_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block5_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block5_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 19, 19, 728)  0           block5_sepconv3_bn[0][0]         \n",
            "                                                                 add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv1_act (Activation (None, 19, 19, 728)  0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block6_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block6_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv2_act (Activation (None, 19, 19, 728)  0           block6_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block6_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block6_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv3_act (Activation (None, 19, 19, 728)  0           block6_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block6_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block6_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 19, 19, 728)  0           block6_sepconv3_bn[0][0]         \n",
            "                                                                 add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv1_act (Activation (None, 19, 19, 728)  0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block7_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block7_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv2_act (Activation (None, 19, 19, 728)  0           block7_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block7_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block7_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv3_act (Activation (None, 19, 19, 728)  0           block7_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block7_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block7_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 19, 19, 728)  0           block7_sepconv3_bn[0][0]         \n",
            "                                                                 add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv1_act (Activation (None, 19, 19, 728)  0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block8_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block8_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv2_act (Activation (None, 19, 19, 728)  0           block8_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block8_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block8_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv3_act (Activation (None, 19, 19, 728)  0           block8_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block8_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block8_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 19, 19, 728)  0           block8_sepconv3_bn[0][0]         \n",
            "                                                                 add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv1_act (Activation (None, 19, 19, 728)  0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block9_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block9_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv2_act (Activation (None, 19, 19, 728)  0           block9_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block9_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block9_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv3_act (Activation (None, 19, 19, 728)  0           block9_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block9_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block9_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 19, 19, 728)  0           block9_sepconv3_bn[0][0]         \n",
            "                                                                 add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block10_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block10_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv2_act (Activatio (None, 19, 19, 728)  0           block10_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv2 (SeparableConv (None, 19, 19, 728)  536536      block10_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv2_bn (BatchNorma (None, 19, 19, 728)  2912        block10_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv3_act (Activatio (None, 19, 19, 728)  0           block10_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv3 (SeparableConv (None, 19, 19, 728)  536536      block10_sepconv3_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv3_bn (BatchNorma (None, 19, 19, 728)  2912        block10_sepconv3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 19, 19, 728)  0           block10_sepconv3_bn[0][0]        \n",
            "                                                                 add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block11_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block11_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv2_act (Activatio (None, 19, 19, 728)  0           block11_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv2 (SeparableConv (None, 19, 19, 728)  536536      block11_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv2_bn (BatchNorma (None, 19, 19, 728)  2912        block11_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv3_act (Activatio (None, 19, 19, 728)  0           block11_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv3 (SeparableConv (None, 19, 19, 728)  536536      block11_sepconv3_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv3_bn (BatchNorma (None, 19, 19, 728)  2912        block11_sepconv3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 19, 19, 728)  0           block11_sepconv3_bn[0][0]        \n",
            "                                                                 add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block12_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block12_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv2_act (Activatio (None, 19, 19, 728)  0           block12_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv2 (SeparableConv (None, 19, 19, 728)  536536      block12_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv2_bn (BatchNorma (None, 19, 19, 728)  2912        block12_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv3_act (Activatio (None, 19, 19, 728)  0           block12_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv3 (SeparableConv (None, 19, 19, 728)  536536      block12_sepconv3_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv3_bn (BatchNorma (None, 19, 19, 728)  2912        block12_sepconv3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 19, 19, 728)  0           block12_sepconv3_bn[0][0]        \n",
            "                                                                 add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block13_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block13_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv2_act (Activatio (None, 19, 19, 728)  0           block13_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv2 (SeparableConv (None, 19, 19, 1024) 752024      block13_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv2_bn (BatchNorma (None, 19, 19, 1024) 4096        block13_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 10, 10, 1024) 745472      add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block13_pool (MaxPooling2D)     (None, 10, 10, 1024) 0           block13_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 10, 10, 1024) 4096        conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 10, 10, 1024) 0           block13_pool[0][0]               \n",
            "                                                                 batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv1 (SeparableConv (None, 10, 10, 1536) 1582080     add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv1_bn (BatchNorma (None, 10, 10, 1536) 6144        block14_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv1_act (Activatio (None, 10, 10, 1536) 0           block14_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv2 (SeparableConv (None, 10, 10, 2048) 3159552     block14_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv2_bn (BatchNorma (None, 10, 10, 2048) 8192        block14_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv2_act (Activatio (None, 10, 10, 2048) 0           block14_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_1 (Glo (None, 2048)         0           block14_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 2048)         0           global_average_pooling2d_1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           20490       dropout_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 20,881,970\n",
            "Trainable params: 14,340,762\n",
            "Non-trainable params: 6,541,208\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "135"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_oPa9HyBNeb",
        "colab_type": "text"
      },
      "source": [
        "### 训练\n",
        "进行模型训练。这里batch size为64。用了自适应优化器Nadam，使用schedule learning rate自动调整学习率的方法并在验证loss不下降时early stopping。一共训练5代，最后的验证集loss仍然有下降空间。steps per epoch设定为在一个epoch内所有训练图片被遍历1次."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cw7pUr7tBNec",
        "colab_type": "code",
        "outputId": "7c5a8e92-65ee-4db4-e815-79987d64206e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler\n",
        "model.compile(optimizer=Nadam(),loss='categorical_crossentropy',metrics=['categorical_accuracy'])\n",
        "\n",
        "def learning_rate(epoch): \n",
        "    ini_lr = 0.002\n",
        "    lr = ini_lr * pow(10, -epoch)\n",
        "    return lr\n",
        "\n",
        "cp = ModelCheckpoint(filepath=\"flow_xception.h5\", save_best_only=True)\n",
        "es = EarlyStopping()\n",
        "lrs = LearningRateScheduler(learning_rate)\n",
        "hist = model.fit_generator(train_gen(64), steps_per_epoch = 286, epochs = 5, workers=4, max_q_size=20, use_multiprocessing=True, validation_data = valid_gen(64), validation_steps = 52, callbacks=[cp, es, lrs])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., steps_per_epoch=286, epochs=5, workers=4, use_multiprocessing=True, validation_data=<generator..., validation_steps=52, callbacks=[<keras.ca..., max_queue_size=20)`\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:2087: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
            "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "285/286 [============================>.] - ETA: 6s - loss: 0.6646 - categorical_accuracy: 0.8048 "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:2330: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
            "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r286/286 [==============================] - 2152s 8s/step - loss: 0.6647 - categorical_accuracy: 0.8047 - val_loss: 2.4030 - val_categorical_accuracy: 0.3702\n",
            "Epoch 2/5\n",
            " 98/286 [=========>....................] - ETA: 28:47 - loss: 0.6044 - categorical_accuracy: 0.8284"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VAHzyngJBNeg",
        "colab_type": "text"
      },
      "source": [
        "### 模型结果\n",
        "\n",
        "保存模型。输出history数据，观察loss曲线。 这里忘记设置inline，没有显示曲线。从数据来看验证集loss明显降低，分类精度提高。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PpPDVnmjBNei",
        "colab_type": "text"
      },
      "source": [
        "### 对测试集进行预测\n",
        "\n",
        "载入模型。对test数据进行预测，将结果写入csv文件。这里使用了keras自带的图片生成器。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfyyLk0fBNej",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load the model 载入已经训练好的模型！！！\n",
        "from keras.models import load_model  \n",
        "model = load_model('my_model12.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cVBDjw1BNen",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define my test data generator\n",
        "from keras.preprocessing.image import *\n",
        "from keras.applications.xception import preprocess_input\n",
        "\n",
        "test_index = os.path.join('.', 'test')\n",
        "gen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "test_gen = gen.flow_from_directory(test_index, target_size=(299,299), shuffle=False, batch_size=64, class_mode=None)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_QS0KNOBNer",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "y_pred = model.predict_generator(test_gen, steps=test_gen.samples//64+1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5Iyu6uzBNew",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_id = []\n",
        "for f in test_gen.filenames:\n",
        "    test_id.append(f)\n",
        "    \n",
        "result = pd.DataFrame(y_pred, columns=['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9'])\n",
        "result.insert(0, 'img', pd.Series(test_id, index=result.index))\n",
        "result.to_csv(os.path.join('.' ,'my_submission12.csv'), index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "BgBWyX9xBNe0",
        "colab_type": "text"
      },
      "source": [
        "### 模型成绩\n",
        "提交kaggle成绩：public score 0.50 private score 0.36"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gp9zGIfrBNe1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}